
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Serverless APIs for MAX models - James Thomas</title>
  <meta name="author" content="James Thomas">

  
  <meta name="description" content="Converting IBM Model Asset Exchange (MAX) Machine Learning Models into Serverless APIs using IBM Cloud Functions (Apache OpenWhisk)">
  <meta name="keywords" content="serverless machine-learning models openwhisk ibm-cloud functions model-asset-exchange">

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://jamesthom.as/blog/2019/07/02/serverless-max-models/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="http://feeds.feedburner.com/JamesThomas" rel="alternate" title="James Thomas" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-26491341-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">James Thomas</a></h1>
  
    <h2>Notes on software.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="http://feeds.feedburner.com/JamesThomas" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:jamesthom.as" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="http://about.me/j_thomas">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Serverless APIs for MAX Models</h1>
    
    
      <p class="meta">
        








  


<time datetime="2019-07-02T10:25:00+01:00" pubdate data-updated="true">Jul 2<span>nd</span>, 2019</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>IBM&#8217;s <a href="https://developer.ibm.com/exchanges/models/">Model Asset eXchange</a> provides a <a href="https://developer.ibm.com/exchanges/models/all/">curated list</a> of free Machine Learning models for developers. Models currently published include detecting <a href="https://developer.ibm.com/exchanges/models/all/max-facial-emotion-classifier/">emotions</a> or <a href="https://developer.ibm.com/exchanges/models/all/max-facial-age-estimator/">ages</a> in faces from images, <a href="https://developer.ibm.com/exchanges/models/all/max-weather-forecaster/">forecasting the weather</a>, converting <a href="https://developer.ibm.com/exchanges/models/all/max-speech-to-text-converter/">speech to text</a> and more. Models are pre-trained and ready for use in the cloud.</p>

<p>Models are published as series of <a href="https://hub.docker.com/search?q=codait&amp;type=image">public Docker images</a>. Images automatically expose a HTTP API for model predictions. Documentation in the model repositories explains how to run images locally (using Docker) or deploy to the cloud (using Kubernetes). This got me thinking‚Ä¶</p>

<p><strong>Could MAX models be used from serverless functions?</strong> ü§î</p>

<p>Running machine learning models on serverless platforms can take advantage of the horizontal scalability to process large numbers of computationally intensive classification tasks in parallel. Coupled with the serverless pricing structure (&#8221;<em>no charge for idle</em>&#8221;), this can be an extremely cheap and effective way to perform model classifications in the cloud.</p>

<p><strong>CHALLENGE ACCEPTED!</strong> ü¶∏‚Äç‚ôÇÔ∏èü¶∏‚Äç‚ôÄÔ∏è</p>

<p>After a couple days of experimentation, I had worked out an easy way to <a href="https://github.com/jthomas/serverless-max-models">automatically expose MAX models as Serverless APIs</a> on <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a>.  üéâüéâüéâ</p>

<p><em>I&#8217;ve given instructions below on how to create those APIs from the models using a simple script. If you just want to use the models, follow those instructions. If you are interested in understanding how this works, keep reading as I explain afterwards what I did&#8230;</em></p>

<h2>Running MAX models on IBM Cloud Functions</h2>

<p><a href="https://github.com/jthomas/serverless-max-models">This repository</a> contains a <a href="https://github.com/jthomas/serverless-max-models/blob/master/build.sh">bash script</a> which builds custom Docker runtimes with MAX models for usage on <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a>. Pushing these images to Docker Hub allows IBM Cloud Functions to use them as <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">custom runtimes</a>. <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md">Web Actions</a> created from these custom runtime images expose the same Prediction API described in the model documentation. They can be used with no further changes or custom code needed.</p>

<h3>prerequisites</h3>

<p>Please follow the links below to set up the following tools before proceeding.</p>

<ul>
<li><a href="https://www.docker.com/">Docker</a></li>
<li><a href="https://hub.docker.com/">Docker Hub account</a></li>
<li><a href="https://cloud.ibm.com/registration">IBM Cloud account</a></li>
<li><a href="https://cloud.ibm.com/openwhisk/learn/cli">IBM Cloud Functions CLI installed</a></li>
</ul>


<p><strong>Check out the &#8221;<a href="https://github.com/jthomas/serverless-max-models">Serverless MAX Models</a> repository. Run all the following commands from that folder.</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/jthomas/serverless-max-models 
</span><span class='line'>cd serverless-max-models </span></code></pre></td></tr></table></div></figure>


<h3>build custom runtime images</h3>

<ul>
<li>Set the following environment variables (<code>MODELS</code>) with <a href="https://hub.docker.com/search?q=codait&amp;type=image">MAX model names</a> and run build script.

<ul>
<li><code>MODELS</code>: MAX model names, e.g. <code>max-facial-emotion-classifier</code></li>
<li><code>USERNAME</code>: Docker Hub username.</li>
</ul>
</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MODELS="..." USERNAME="..." ./build.sh</span></code></pre></td></tr></table></div></figure>


<p>This will create Docker images locally with the MAX model names and push to Docker Hub for usage in IBM Cloud Functions. <strong>IBM Cloud Functions only supports public Docker images as custom runtimes.</strong></p>

<h3>create actions using custom runtimes</h3>

<ul>
<li>Create a Web Action using the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">custom Docker runtime</a>.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud wsk action create &lt;MODEL_IMAGE&gt; --docker &lt;DOCKERHUB_NAME&gt;/&lt;MODEL_IMAGE&gt; --web true -m 512</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Retrieve the Web Action URL (<code>https://&lt;REGION&gt;.functions.cloud.ibm.com/api/v1/web/&lt;NS&gt;/default/&lt;ACTION&gt;</code>)</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud wsk action get &lt;MODEL_IMAGE&gt; --url</span></code></pre></td></tr></table></div></figure>


<h3>invoke web action url with prediction api parameters</h3>

<p>Use the same API request parameters as defined in the Prediction API specification with the Web Action URL. This will invoke model predictions and return the result as the HTTP response, e.g.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -F "image=@assets/happy-baby.jpeg" -XPOST &lt;WEB_ACTION_URL&gt;</span></code></pre></td></tr></table></div></figure>


<p><em>NOTE: The first invocation after creating an action may incur long cold-start delays due to the platform pulling the remote image into the local registry. Once the image is available in the platform, both further cold and warm invocations will be much faster.</em></p>

<h2>Example</h2>

<p>Here is an example of creating a serverless API using the <code>max-facial-emotion-classifier</code> <a href="https://developer.ibm.com/exchanges/models/all/max-facial-emotion-classifier/">MAX model</a>. Further examples of models which have been tested are available <a href="https://github.com/jthomas/serverless-max-models/blob/master/README.md#models">here</a>. If you encounter problems, please <a href="https://github.com/jthomas/serverless-max-models/issues">open an issue</a> on Github.</p>

<h3>max-facial-emotion-classifier</h3>

<ul>
<li><a href="https://developer.ibm.com/exchanges/models/all/max-facial-emotion-classifier/">Facial Emotion Classifier (<code>max-facial-emotion-classifier</code>)</a></li>
</ul>


<p>Start by creating the action using the custom runtime and then retrieve the Web Action URL.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ibmcloud wsk action create max-facial-emotion-classifier --docker &lt;DOCKERHUB_NAME&gt;/max-facial-emotion-classifier --web true -m 512
</span><span class='line'>ok: created action max-facial-emotion-classifier
</span><span class='line'>$ ibmcloud wsk action get max-facial-emotion-classifier --url
</span><span class='line'>ok: got action max-facial-emotion-classifier
</span><span class='line'>https://&lt;REGION&gt;.functions.cloud.ibm.com/api/v1/web/&lt;NS&gt;/default/max-facial-emotion-classifier</span></code></pre></td></tr></table></div></figure>


<p>According to the <a href="http://max-facial-emotion-classifier.max.us-south.containers.appdomain.cloud/">API definition</a> for this model, the prediction API expects a form submission with an image file to classify. Using a <a href="https://github.com/IBM/MAX-Facial-Emotion-Classifier/blob/master/assets/happy-baby.jpeg">sample image</a> from the model repo, the model can be tested using curl.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -F "image=@happy-baby.jpeg" -XPOST https://&lt;REGION&gt;.functions.cloud.ibm.com/api/v1/web/&lt;NS&gt;/default/max-facial-emotion-classifier</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;ok&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;predictions&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;detection_box&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>        <span class="mf">0.15102639296187684</span><span class="p">,</span>
</span><span class='line'>        <span class="mf">0.3828125</span><span class="p">,</span>
</span><span class='line'>        <span class="mf">0.5293255131964809</span><span class="p">,</span>
</span><span class='line'>        <span class="mf">0.5830078125</span>
</span><span class='line'>      <span class="p">],</span>
</span><span class='line'>      <span class="nt">&quot;emotion_predictions&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>        <span class="p">{</span>
</span><span class='line'>          <span class="nt">&quot;label_id&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;happiness&quot;</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;probability&quot;</span><span class="p">:</span> <span class="mf">0.9860254526138306</span>
</span><span class='line'>        <span class="p">},</span>
</span><span class='line'>        <span class="err">...</span>
</span><span class='line'>      <span class="p">]</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>performance</h4>

<p><em>Example Invocation Duration (Cold):</em> ~4.8 seconds</p>

<p><em>Example Invocation Duration (Warm):</em> ~ 800 ms</p>

<h2>How does this work?</h2>

<h3>background</h3>

<p>Running machine learning classifications using pre-trained models from serverless functions has historically been challenging due to the following reason‚Ä¶</p>

<blockquote><p>Developers do not control runtime environments in (most) serverless cloud platforms. Libraries and dependencies needed by the functions must be provided in the deployment package. Most platforms limit deployment package sizes (~50MB compressed &amp; ~250MB uncompressed).</p></blockquote>

<p>Machine Learning libraries and models can be much larger than those deployment size limits. This stops them being included in deployment packages. Loading files dynamically during invocations may be possible but incurs extremely long cold-start delays and additional costs.</p>

<p>Fortunately, <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a> is based on the open-source serverless project, <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>. This platform supports bespoke function runtimes using <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">custom Docker images</a>. Machine learning libraries and models can therefore be provided in custom runtimes. This removes the need to include them in deployment packages or be loaded at runtime.</p>

<p><em>Interested in reading other blog posts about using machine learning libraries and toolkits with IBM Cloud Functions? See <a href="http://jamesthom.as/blog/2017/08/04/large-applications-on-openwhisk/">these posts</a> for <a href="http://jamesthom.as/blog/2018/08/13/serverless-machine-learning-with-tensorflow-dot-js/">more details</a>.</em></p>

<h3>MAX model images</h3>

<p>IBM&#8217;s <a href="https://developer.ibm.com/exchanges/models/all/">Model Asset eXchange</a> publishes Docker images for each model, alongside the pre-trained model files. Images expose a <a href="https://github.com/IBM/MAX-Text-Sentiment-Classifier#3-use-the-model">HTTP API for predictions</a> using the model on port 5000, built using Python and Flask. <a href="http://max-text-sentiment-classifier.max.us-south.containers.appdomain.cloud/">Swagger files</a> for the APIs describe the available operations, input parameters and response bodies.</p>

<p>These images use a custom application framework (<a href="https://pypi.org/project/maxfw/">maxfw</a>), based on Flask, to standardise exposing MAX models as HTTP APIs. This framework handles input parameter validation, response marshalling, CORS support, etc. This allows model runtimes to just implement the prediction API handlers, rather than the entire HTTP application.</p>

<p>Since the framework already handles exposing the model as a HTTP API, I started looking for a way to simulate an external HTTP request coming into the framework. If this was possible, I could trigger this fake request from a Python Web Action to perform the model classification from input parameters. The Web Action would then covert the HTTP response returned into the valid Web Action response parameters.</p>

<h3>flask test client</h3>

<p>Reading through the Flask <a href="http://flask.pocoo.org/docs/1.0/testing/">documentation</a>, I came across the perfect solution! üëèüëèüëè</p>

<blockquote><p>Flask provides a way to test your application by exposing the Werkzeug test Client and handling the context locals for you. You can then use that with your favourite testing solution.</p></blockquote>

<p>This allows application routes to be executed with the <a href="https://werkzeug.palletsprojects.com/en/0.15.x/test/#werkzeug.test.Client">test client</a>, without actually running the HTTP server.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">max_app</span> <span class="o">=</span> <span class="n">MAXApp</span><span class="p">(</span><span class="n">API_TITLE</span><span class="p">,</span> <span class="n">API_DESC</span><span class="p">,</span> <span class="n">API_VERSION</span><span class="p">)</span>
</span><span class='line'><span class="n">max_app</span><span class="o">.</span><span class="n">add_api</span><span class="p">(</span><span class="n">ModelPredictAPI</span><span class="p">,</span> <span class="s">&#39;/predict&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">test_client</span> <span class="o">=</span> <span class="n">max_app</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">test_client</span><span class="p">()</span>
</span><span class='line'><span class="n">r</span> <span class="o">=</span> <span class="n">test_client</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">&#39;/model/predict&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">content</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using this code within a serverless Python function allows function invocations to trigger the prediction API.  The serverless function only has to convert input parameters to the fake HTTP request and then serialise the response back to JSON.</p>

<h3>python docker action</h3>

<p>The custom MAX model runtime image needs to implement the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-new.md#action-interface">HTTP API expected</a> by Apache OpenWhisk. This API is used to instantiate the runtime environment and then pass in invocation parameters on each request. Since the runtime image contains all files and code need to process requests, the <code>/init</code> handler becomes a <a href="https://english.stackexchange.com/questions/25993/what-does-no-op-mean">no-op</a>. The <code>/run</code> handler converts <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md#http-context">Web Action HTTP parameters</a> into the fake HTTP request.</p>

<p>Here is the Python script used to proxy incoming Web Actions requests to the framework model service.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">maxfw.core</span> <span class="kn">import</span> <span class="n">MAXApp</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">api</span> <span class="kn">import</span> <span class="n">ModelPredictAPI</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">config</span> <span class="kn">import</span> <span class="n">API_TITLE</span><span class="p">,</span> <span class="n">API_DESC</span><span class="p">,</span> <span class="n">API_VERSION</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">json</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">base64</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">Response</span>
</span><span class='line'>
</span><span class='line'><span class="n">max_app</span> <span class="o">=</span> <span class="n">MAXApp</span><span class="p">(</span><span class="n">API_TITLE</span><span class="p">,</span> <span class="n">API_DESC</span><span class="p">,</span> <span class="n">API_VERSION</span><span class="p">)</span>
</span><span class='line'><span class="n">max_app</span><span class="o">.</span><span class="n">add_api</span><span class="p">(</span><span class="n">ModelPredictAPI</span><span class="p">,</span> <span class="s">&#39;/predict&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Use flask test client to simulate HTTP requests for the prediction APIs</span>
</span><span class='line'><span class="c"># HTTP request data will come from action invocation parameters, neat huh? :)</span>
</span><span class='line'><span class="n">test_client</span> <span class="o">=</span> <span class="n">max_app</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">test_client</span><span class="p">()</span>
</span><span class='line'><span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># This implements the Docker runtime API used by Apache OpenWhisk</span>
</span><span class='line'><span class="c"># https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md</span>
</span><span class='line'><span class="c"># /init is a no-op as everything is provided in the image.</span>
</span><span class='line'><span class="nd">@app.route</span><span class="p">(</span><span class="s">&quot;/init&quot;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;POST&#39;</span><span class="p">])</span>
</span><span class='line'><span class="k">def</span> <span class="nf">init</span><span class="p">():</span>
</span><span class='line'>    <span class="k">return</span> <span class="s">&#39;&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Action invocation requests will be received as the `value` parameter in request body.</span>
</span><span class='line'><span class="c"># Web Actions provide HTTP request parameters as `__ow_headers` &amp; `__ow_body` parameters.</span>
</span><span class='line'><span class="nd">@app.route</span><span class="p">(</span><span class="s">&quot;/run&quot;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;POST&#39;</span><span class="p">])</span>
</span><span class='line'><span class="k">def</span> <span class="nf">run</span><span class="p">():</span>
</span><span class='line'>    <span class="n">body</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">json</span>
</span><span class='line'>    <span class="n">form_body</span> <span class="o">=</span> <span class="n">body</span><span class="p">[</span><span class="s">&#39;value&#39;</span><span class="p">][</span><span class="s">&#39;__ow_body&#39;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">headers</span> <span class="o">=</span> <span class="n">body</span><span class="p">[</span><span class="s">&#39;value&#39;</span><span class="p">][</span><span class="s">&#39;__ow_headers&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># binary image content provided as base64 strings</span>
</span><span class='line'>    <span class="n">content</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">form_body</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># send fake HTTP request to prediction API with invocation data</span>
</span><span class='line'>    <span class="n">r</span> <span class="o">=</span> <span class="n">test_client</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">&#39;/model/predict&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">content</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
</span><span class='line'>    <span class="n">r_headers</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># binary data must be encoded as base64 strings to return in JSON response</span>
</span><span class='line'>    <span class="n">is_image</span> <span class="o">=</span> <span class="n">r_headers</span><span class="p">[</span><span class="s">&#39;Content-Type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&#39;image&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">r_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_image</span> <span class="k">else</span> <span class="n">r</span><span class="o">.</span><span class="n">data</span>
</span><span class='line'>    <span class="n">body</span> <span class="o">=</span> <span class="n">r_data</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">&quot;utf-8&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">response</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;headers&#39;</span><span class="p">:</span> <span class="n">r_headers</span><span class="p">,</span> <span class="s">&#39;status&#39;</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="s">&#39;body&#39;</span><span class="p">:</span> <span class="n">body</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">print</span> <span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">status</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">Response</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">status</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">mimetype</span><span class="o">=</span><span class="s">&#39;application/json&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s">&#39;0.0.0.0&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8080</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>building into an image</h3>

<p>Since the MAX models already exist as public Docker images, those images can be used as base images when building custom runtimes. Those base images handle adding model files and all dependencies needed to execute them into the image.</p>

<p>This is the <code>Dockerfile</code> used by the build script to create the custom model image. The <code>model</code> parameter refers to the build argument containing the model name.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ARG model
</span><span class='line'>FROM codait/<span class="k">${</span><span class="nv">model</span><span class="k">}</span>:latest
</span><span class='line'>
</span><span class='line'>ADD openwhisk.py .
</span><span class='line'>
</span><span class='line'>EXPOSE 8080
</span><span class='line'>
</span><span class='line'>CMD python openwhisk.py
</span></code></pre></td></tr></table></div></figure>


<p>This is then used from the following build script to create a custom runtime image for the model.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'>
</span><span class='line'><span class="nb">set</span> -e -u
</span><span class='line'>
</span><span class='line'><span class="k">for </span>model in <span class="nv">$MODELS</span>; <span class="k">do</span>
</span><span class='line'><span class="k">  </span><span class="nb">echo</span> <span class="s2">&quot;Building $model runtime image&quot;</span>
</span><span class='line'>  docker build -t <span class="nv">$model</span> --build-arg <span class="nv">model</span><span class="o">=</span><span class="nv">$model</span> .
</span><span class='line'>  <span class="nb">echo</span> <span class="s2">&quot;Pushing $model to Docker Hub&quot;</span>
</span><span class='line'>  docker tag <span class="nv">$model</span> <span class="nv">$USERNAME</span>/<span class="nv">$model</span>
</span><span class='line'>  docker push <span class="nv">$USERNAME</span>/<span class="nv">$model</span>
</span><span class='line'><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure>


<p>Once the image is published to Docker Hub, it can be referenced when creating new Web Actions (using the <code>‚Äîdocker</code> parameter). üòé</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ibmcloud wsk action create &lt;MODEL_IMAGE&gt; --docker &lt;DOCKERHUB_NAME&gt;/&lt;MODEL_IMAGE&gt; --web <span class="nb">true</span> -m 512
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>IBM&#8217;s Model Asset eXchange is a curated collection of Machine Learning models, ready to deploy to the cloud for a variety of tasks. All models are available as a series of public Docker images. Models images automatically expose HTTP APIs for classifications.</p>

<p>Documentation in the model repositories explains how to run them locally and deploy using Kubernetes, but what about using on serverless cloud platforms? Serverless platforms are becoming a popular option for deploying Machine Learning models, due to horizontal scalability and cost advantages.</p>

<p>Looking through the source code for the model images, I discovered a mechanism to hook into the custom model framework used to export the model files as HTTP APIs. This allowed me write a simple wrapper script to proxy serverless function invocations to the model prediction APIs. API responses would be serialised back into the Web Action response format.</p>

<p>Building this script into a new Docker image, using the existing model image as the base image, created a new runtime which could be used on the platform. Web Actions created from this runtime image would automatically expose the same HTTP APIs as the existing image!</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">James Thomas</span></span>

      








  


<time datetime="2019-07-02T10:25:00+01:00" pubdate data-updated="true">Jul 2<span>nd</span>, 2019</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/machine-learning/'>machine learning</a>, <a class='category' href='/blog/categories/openwhisk/'>openwhisk</a>, <a class='category' href='/blog/categories/python/'>python</a>, <a class='category' href='/blog/categories/serverless/'>serverless</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://jamesthom.as/blog/2019/07/02/serverless-max-models/" data-via="thomasj" data-counturl="http://jamesthom.as/blog/2019/07/02/serverless-max-models/" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
    <div class="fb-like" data-send="true" data-width="450" data-show-faces="false"></div>
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2019/05/14/accessing-long-running-openwhisk-actions-results/" title="Previous Post: Accessing Long-Running Apache OpenWhisk Actions Results">&laquo; Accessing Long-Running Apache OpenWhisk Actions Results</a>
      
      
        <a class="basic-alignment right" href="/blog/2019/07/22/connecting-to-ibm-cloud-databases-for-redis-from-node-dot-js/" title="Next Post: Connecting to IBM Cloud Databases for Redis from Node.js">Connecting to IBM Cloud Databases for Redis from Node.js &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2019/07/24/hosting-static-websites-on-ibm-cloud/">Hosting Static Websites on IBM Cloud</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/22/connecting-to-ibm-cloud-databases-for-redis-from-node-dot-js/">Connecting to IBM Cloud Databases for Redis from Node.js</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/02/serverless-max-models/">Serverless APIs for MAX models</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/05/14/accessing-long-running-openwhisk-actions-results/">Accessing Long-Running Apache OpenWhisk Actions Results</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/05/08/node-dot-js-worker-threads-with-serverless-functions/">Saving Money and Time With Node.js Worker Threads in Serverless Functions</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating...</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("thomasj", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/thomasj" class="twitter-follow-button" data-show-count="false">Follow @thomasj</a>
  
</section>


<section>
  <h1>My Pinboard</h1>
  <ul id="pinboard_linkroll">Fetching linkroll...</ul>
  <p><a href="http://pinboard.in/u:jamesthomas">My Pinboard Bookmarks &raquo;</a></p>
</section>
<script type="text/javascript">
  var linkroll = 'pinboard_linkroll'; //id target for pinboard list
  var pinboard_user = "jamesthomas"; //id target for pinboard list
  var pinboard_count = 3; //id target for pinboard list
  (function(){
    var pinboardInit = document.createElement('script');
    pinboardInit.type = 'text/javascript';
    pinboardInit.async = true;
    pinboardInit.src = '/javascripts/pinboard.js';
    document.getElementsByTagName('head')[0].appendChild(pinboardInit);
  })();
</script>




  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2019 - James Thomas -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'notesonjavascript';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://jamesthom.as/blog/2019/07/02/serverless-max-models/';
        var disqus_url = 'http://jamesthom.as/blog/2019/07/02/serverless-max-models/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
