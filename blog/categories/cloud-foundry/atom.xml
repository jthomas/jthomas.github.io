<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: cloud foundry | James Thomas]]></title>
  <link href="http://jthomas.github.com/jthomas/blog/categories/cloud-foundry/atom.xml" rel="self"/>
  <link href="http://jthomas.github.com/jthomas/"/>
  <updated>2015-07-01T16:31:48+01:00</updated>
  <id>http://jthomas.github.com/jthomas/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Continuous Delivery for Phonebot]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2015/06/11/continuous-delivery-for-phonebot/"/>
    <updated>2015-06-11T16:08:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2015/06/11/continuous-delivery-for-phonebot</id>
    <content type="html"><![CDATA[<p><img src="/images/Phonebot_Pipeline.png"></p>

<p>Since creating <a href="http://jamesthom.as/blog/2015/05/29/phonebot/">Phonebot</a> last month,
I've been working on setting up a fully-automated build and deploy for the project.
Using <a href="http://hub.jazz.net">IBM DevOps Services</a>, Phonebot now has
"<a href="http://en.wikipedia.org/wiki/Continuous_delivery">Continuous Delivery</a>" enabled.</p>

<p><strong>When new code is commited to the <a href="https://github.com/IBM-Bluemix/phonebot">external Github repository</a>,
the build service will perform the following tasks.</strong></p>

<ul>
<li><em>Run Unit Tests and Code Lint Tools</em></li>
<li><em>Deploy To Test Server</em></li>
<li><em>Run Integration Tests Against Test Server</em></li>
<li><em>Deploy To Production</em></li>
</ul>


<p>Each stage will only be executed if the following stage passes.</p>

<p>In the following post, I'll explain how to set up each stage and share tips making it easy to
replicate this setup for your projects...</p>

<h2>Writing Tests for Phonebot</h2>

<p>Phonebot comes with a comprehensive <a href="https://github.com/IBM-Bluemix/phonebot/tree/master/test">test suite</a>.
I've used the <a href="http://mochajs.org">Mocha</a> test framework for creating unit and integration tests. Test
assertions use NodeJS' <a href="https://nodejs.org/api/assert.html">built-in library</a>. The <a href="https://github.com/mfncooper/mockery">mockery</a>
library is used to replace module dependencies with mock objects.</p>

<p>Setting up the <a href="https://docs.npmjs.com/misc/scripts"><em>scripts</em></a> field in
<a href="https://github.com/IBM-Bluemix/phonebot/blob/master/package.json"><em>package.json</em></a> allows us to use NPM to run our tests.</p>

<p>NPM will look into the "<em>node_modules/.bin</em>" directory for binaries when running scripts. This means we don't need Mocha installed
on the deployment host to run tests. The "<em>devDependencies</em>" field includes modules we rely on during development
but not production.</p>

<p>```
"devDependencies": {</p>

<pre><code>"mocha": "^2.2.5",
"mocha-eslint": "^0.1.7",
"mockery": "^1.4.0"
</code></pre>

<p>},
"scripts": {</p>

<pre><code>"test": "mocha test/unit",
"integration-test": "mocha test/integration",
"start": "node app.js"
</code></pre>

<p>  },
```</p>

<p>Running the following commands will run the unit and integration tests.</p>

<p><code>
$ npm test  // defaults to 'run test'
$ npm run integration-test
</code></p>

<h3>Running Code Linters</h3>

<p>Along with unit tests, we want to run 'code linters' to catch any errors in our JavaScript code.
We're using the <a href="https://github.com/eslint/eslint">eslint</a> tool with the following
<a href="https://github.com/IBM-Bluemix/phonebot/blob/master/.eslintrc">configuration</a>. Using this <a href="https://www.npmjs.com/package/mocha-eslint">module</a>,
we're setting up the eslint tool as a <a href="https://github.com/IBM-Bluemix/phonebot/blob/master/test/unit/eslint.js">test case</a>.</p>

<p>This test will
be automatically run in the unit test phase and errors incorporated into the test report.</p>

<h3>Mocking Services In Integration Tests</h3>

<p>When the unit tests have passed, we're going to deploy a test instance of the application.
Integration tests will make HTTP requests to simulate user activity, capture the responses
and then verify the application is behaving as expected.</p>

<p>Phonebot uses external services, provisioned through IBM Bluemix, to make phone calls, translate
speech to text and communicate with Slack channels. Services configuration parameters, e.g. username, password, host,
are passed into the application using <a href="http://docs.run.pivotal.io/devguide/deploy-apps/environment-variable.html">environment variables</a>.</p>

<p><strong><em>During integration tests, we want to capture all requests to external services and provide hardcoded HTTP responses to be returned.
With service parameters coming from environment properties, rather than hardcoded in the application, we can simply replace
the bound services configuration with our own values. This application will pick up these new values, pointing to our stub server, at runtime
without any changes needed to the code.</em></strong></p>

<p>This <a href="https://gist.github.com/jthomas/f573cb94de20b0e95940">stub server</a> has
been created to capture all incoming HTTP requests and make them available at a
custom HTTP endpoint. We're also configured HTTP routes to simulate each of the
external services and return hardcoded responses.</p>

<p>Deploying our test server in a different <a href="http://docs.cloudfoundry.org/concepts/roles.html#spaces">space</a> to production means we can have custom
credentials set up without having to modify the service configuration in the production environment.</p>

<p>The following commands will show the existing configuration values that we can replicate in the test environment.</p>

<p><code>
$ cf env phonebot
$ cf create-space test
$ cf target -s test
$ cf cups twilio -p "accountSID, authToken, url"
$ cf cups speech_to_text -p "username, password, url"
$ cf cups slack_webhooks -p "slackbot-testing"
</code></p>

<p>With the test credentials created, we can deploy the application to the "test" space without modifications.</p>

<h2>Setting up Build and Deploy Pipeline</h2>

<p>We're going to use <a href="http://hub.jazz.net">IBM DevOps Services</a> to build and manage the "Continuous Delivery" pipeline.
From the home page, click the <em>"Create Project"</em> button to import our existing Github project into the workspace.</p>

<p><img src="/images/create_project.png"></p>

<p>The <em>"Create Project"</em> page allows us to link an existing project from Github to the new project.
Changes to the external repository will be automatically pushed through to our project.</p>

<p><img src="/images/create_phonebot.png"></p>

<p>Selecting the <em>"Make a Bluemix project"</em> option will automatically configure deploying to the Bluemix platform.</p>

<p><img src="/images/import_phonebot_bm.png"></p>

<p>When the project has finished importing, we can access the "Build and Deploy" pipeline...</p>

<p><img src="/images/build_and_deploy.png"></p>

<p>... which will currently be empty. Clicking the <em>"Add Stage"</em> button will allow
us to start configuring the build, test and deploy jobs for our pipeline.</p>

<p><img src="/images/add_stage.png"></p>

<h3>Running Unit Tests and Code Lint Tools</h3>

<p>The first stage in our pipeline will run the unit tests when a new commit is published
to the Phonebot repository on Github.</p>

<p>Using the <em>"Input"</em> tab, we're configuring the stage to pick up all changes in the <em>"master"</em> branch
of the <a href="https://github.com/jthomas/phonebot.git">https://github.com/jthomas/phonebot.git</a> repository.
The input for a stage can also be the build artifacts from a previous stage.</p>

<p><img src="/images/unit_test_input.png"></p>

<p>On the <em>"Jobs"</em> tab, we can configure multiple tasks to be executed when triggered by the stage input.
For the unit tests, we're using a simple shell script to install the project dependencies and run
the NPM task.</p>

<p><img src="/images/unit_tests.png"></p>

<h3>Deploy Test Server</h3>

<p>Adding a second stage to the pipeline after the unit tests, we will use it to deploy our test server.
This stage will only be executed if the first stage completes successfully.</p>

<p>Using the <em>"Deploy"</em> rather than <em>"Test"</em> job, presents us with a configuration
panel to set up the deployment parameters. The <em>"test"</em> space which contains our
test configuration for our mock services. Choosing a different application name
means our test server won't clash with the existing production host already
deployed.</p>

<p><img src="/images/deploy_test.png"></p>

<h3>Running Integration Tests Against Test Server</h3>

<p>Once the test server has been deployed, we can trigger the pipeline stage to run
integration tests against this host.</p>

<p>Using Mocha to run out integration tests means we can follow the setup
as the unit test stage. Defining a "test" job, we install the project dependencies
and then run the test harness.</p>

<p><img src="/images/integration_tests.png"></p>

<p>Phonebot's integration tests use environment variables to define the test
and stub server locations. We can define these through the stage setup page, as
shown below.</p>

<p><img src="/images/environment_props.png"></p>

<h3>Deploy To Production</h3>

<p>Finally, provided all the previous stages were successfully, the last stage will
deploy our application into production.</p>

<p>Configuring a <em>"Deploy"</em> task, this time we use the production space <em>"dev"</em> and use the
proper application name.</p>

<p><img src="/images/deploy_production.png"></p>

<h2>...and that's it!</h2>

<p>With our "Continuous Delivery" pipeline now configured, new versions of
Phonebot will be automatically deployed to production without any manual work.</p>

<p><img src="/images/deploy_success.png"></p>

<p>For testing, each stage can be triggered manually. Logs are available in to diagnose any issues that may occur.</p>

<p><strong>Using IBM DevOps Services, we rapidly created a build and deploy pipeline linked to a project on Github without having to manually
configure build systems, test servers or anything else you would expect.</strong></p>

<p>Our example was relatively simple, the service can be configured for far more complicated build and deploy tasks. The <a href="https://hub.jazz.net/docs">documentation</a>
gives full details on the capabilities of that platform. If you have any issues, please use the <a href="https://developer.ibm.com/answers/smartspace/devops-services/">IBM Answers support forum</a> to post questions and get answers from the development team.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating CF CLI Plugins]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2015/04/16/creating-cf-cli-plugins/"/>
    <updated>2015-04-16T09:53:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2015/04/16/creating-cf-cli-plugins</id>
    <content type="html"><![CDATA[<p>Since the v.6.7 release of the Cloud Foundry Command Line Interface (CF CLI), users have been to create and install plugins to provide custom commands.</p>

<p>There's now a whole community of <a href="http://plugins.cloudfoundry.org/ui/">third-party plugins</a> to help make you more productive developing Cloud Foundry applications.</p>

<h2>Installing Plugins</h2>

<p>Plugins can be installed directly from the platform binary.</p>

<p><code>
$ go get github.com/sample_user/sample_plugin
$ cf install-plugin $GOPATH/bin/sample_plugin
</code></p>

<p>...or discovered and installed directly from plugin repositories.</p>

<p>```
$ cf add-plugin-repo cf-plugins http://plugins.cloudfoundry.org/
$ cf list-plugin-repos
OK</p>

<p>Repo Name    Url
cf-plugins   http://plugins.cloudfoundry.org/</p>

<p>$ cf repo-plugins
Getting plugins from all repositories ...</p>

<p>Repository: cf-plugins
name                   version   description
CLI-Recorder           1.0.1     Records and playbacks CLI commands.
Live Stats             1.0.0     Monitor CPU and Memory usage on an app via the browser.
Console                1.0.0     Start a tmate session on an application container
Diego-Beta             1.3.0     Enables Diego-specific commands and functionality
Open                   1.1.0     Open app url in browser
autopilot              0.0.1     zero downtime deploy plugin for cf applications
Brooklyn               0.1.1     Interact with Service Broker for Apache Brooklyn
kibana-me-logs         0.3.0     Launches the Kibana UI (from kibana-me-logs) for an application.
Buildpack Usage        1.0.0     View all buildpacks used in the current CLI target context.
CF App Stack Changer   1.0.0     Allows admins to list and update applications with outdated lucid64 stacks.
```</p>

<p>Once a repository has been registered, we can search and install the available plugins.</p>

<p>```
$ cf install-plugin open -r cf-plugins
Looking up 'open' from repository 'cf-plugins'
  7998292 bytes downloaded...
Installing plugin /var/folders/db/9y12sh3n0kdg4v3zxnn8dbg80000gn/T/ filename=cf-plugin-open_darwin_amd64...
OK
Plugin open v1.1.0 successfully installed.</p>

<p>$ cf plugins
Listing Installed Plugins...
OK</p>

<p>Plugin Name   Version   Command Name   Command Help
open          1.1.0     open           open app url in browser</p>

<p>$ cf open
NAME:
   open - open app url in browser</p>

<p>USAGE:
   open <appname>
```</p>

<p><strong>How about creating your own plugins? Here I'll show you how by walking through the steps used to create my first plugin, <a href="https://github.com/jthomas/copyenv">copyenv</a>.</strong></p>

<h2>Creating New Plugins</h2>

<p>Plugins are <a href="http://golang.org">Go</a> binaries, implenting a <a href="https://github.com/cloudfoundry/cli/blob/master/plugin/plugin.go">common interface</a>
defined by the CF CLI project.</p>

<p>There's a Run() function to implement that acts as a callback when the user issues the plugin command along
with a GetMetadata() function to provide the metadata for the new command.</p>

<p>There's a list of <a href="https://github.com/cloudfoundry/cli/tree/master/plugin_examples">example plugins</a>
to start with in the CF CLI repository.</p>

<p>For our plugin, we're starting with the
<a href="https://github.com/cloudfoundry/cli/blob/master/plugin_examples/basic_plugin.go">basic_plugin</a>
code. This file contains a skeleton outline for a basic plugin implementation
that you can modify.</p>

<h3>Plugin Structure</h3>

<p>Reviewing the basic_plugin example, plugins follow a simple structure.</p>

<p>First, we declare the Go package "main" as this code will be compiled into an executable command.
Application dependencies are registered with the "import" definition. We link to the CF
CLI Plugin package to access the common interface that defines a runnable plugin. BasicPlugin is the
name of our struct that will implement the Plugin Interface.
``` go
package main</p>

<p>import (
  "fmt"
  "github.com/cloudfoundry/cli/plugin"
)</p>

<p>type BasicPlugin struct{}
```</p>

<p>The "Run" function will be executed each time a user calls our custom plugin command. We are passed
a reference to the CF CLI, for running additional commands, along with the command line arguments.</p>

<p>``` go
func (c *BasicPlugin) Run(cliConnection plugin.CliConnection, args []string) {
  // Ensure that we called the command basic-plugin-command
  if args[0] == "basic-plugin-command" {</p>

<pre><code>fmt.Println("Running the basic-plugin-command")
</code></pre>

<p>  }
}
```</p>

<p>Returning metadata to install the plugin is implemented via the "GetMetadata" function. We can specify the
plugin version number, help documentation and command identifiers.</p>

<p>``` go
func (c *BasicPlugin) GetMetadata() plugin.PluginMetadata {
  return plugin.PluginMetadata{</p>

<pre><code>Name: "MyBasicPlugin",
Version: plugin.VersionType{
  Major: 1,
  Minor: 0,
  Build: 0,
},
Commands: []plugin.Command{
  plugin.Command{
    Name:     "basic-plugin-command",
    HelpText: "Basic plugin command's help text",

    // UsageDetails is optional
    // It is used to show help of usage of each command
    UsageDetails: plugin.Usage{
      Usage: "basic-plugin-command\n   cf basic-plugin-command",
    },
  },
},
</code></pre>

<p>  }
}
```
Finally, the "main" function will the entry point when executing the compiled binary.
Calling "plugin.Start" with a pointer to the struct implementing the Plugin interace will
register our plugin.</p>

<p><code>go
func main() {
  plugin.Start(new(BasicPlugin))
}
</code></p>

<h2>CopyEnv Plugin</h2>

<p><blockquote><p>Cloud Foundry CLI plugin to export application VCAP_SERVICES onto the local machine.</p></blockquote></p>

<p>Applications running on Cloud Foundry rely on the VCAP_SERVICES environment
variable to provide service credentials.</p>

<p>When running applications locally for development and testing, it's useful to
have the same VCAP_SERVICES values available in the local environment to
simulate running on the host platform.</p>

<p>This plugin will export the remote application environment variables, available
using cf env, into a format that makes it simple to expose those same values
locally.</p>

<h3>Modifying the Sample Plugin</h3>

<p>For the new plugin, we will need to get an application name from the user,
access the remote VCAP_SERVICES environment variable and then export this into
the user's local environment.</p>

<p>Accessing an application's environment variables can be retrieved using the existing cf env command.
The "plugin.CliConnection" reference passed into the Run function has <a href="https://github.com/cloudfoundry/cli/blob/master/plugin/plugin.go#L14-L17">methods for executing CLI commands</a> from within the plugin.</p>

<p>We're following the convention of the "cf env" command by having the application name as a command line argument.
This means we can modify the existing "args" value to set up the CLI command to retrieve the VCAP_SERVICES value.</p>

<p>``` go
func (c *CopyEnv) Run(cliConnection plugin.CliConnection, args []string) {
  if len(args) &lt; 2 {</p>

<pre><code>fmt.Println("ERROR: Missing application name")
 os.Exit(1)
</code></pre>

<p>  }</p>

<p>  args[0] = "env"
  output, err := cliConnection.CliCommandWithoutTerminalOutput(args...)
```</p>

<p>Now we have an array of strings, output, containing the text output from cf env APP_NAME command.
Iterating through this list, we search for the line which contains the VCAP_SERVICES definition.
This value will be a JSON object with a VCAP_SERVICES attribute defining the service credentials.</p>

<p>Exporting this JSON object to the local environment, we need to convert the VCAP_SERVICES object
into a shell environment variable definition. Go has built in support for the JSON language. We
decode the parent JSON to a Map interface and then export the VCAP_SERVICES attribute as JSON. This
text is then wrapped within a shell variable definition.</p>

<p>``` go
for _, val := range output {
  if (strings.Contains(val, "VCAP_SERVICES")) {</p>

<pre><code>var f interface{}
err := json.Unmarshal([]byte(val), &amp;f)
if err != nil {
  fmt.Println(err)
  os.Exit(1)
}

m := f.(map[string]interface{})
b, err := json.Marshal(m["VCAP_SERVICES"])
if err != nil {
  fmt.Println(err)
  os.Exit(1)
}

vcap_services := "export VCAP_SERVICES='" + string(b[:]) + "';"
fmt.Println(vcap_services)
</code></pre>

<p>  }
}
```</p>

<p>Once we've finished the code, install the compiled binary using the CF CLI.</p>

<p><code>
$ go build copyenv.go
$ cf install-plugin copyenv
</code></p>

<h3>Making plugin available for other users</h3>

<p>Exporting out plugin into an external Git repository will allow users to use the Go package manager
to retrieve and compile the plugin for installation with the CF CLI.</p>

<p><code>
$ go get github.com/sample_user/sample_plugin
$ cf install-plugin $GOPATH/bin/sample_plugin
</code></p>

<p>We can also include the plugin in the official Cloud Foundry <a href="plugins.cloudfoundry.org">Plugin Repository</a>
by forking the <a href="https://github.com/cloudfoundry-incubator/cli-plugin-repo">source project</a>,
adding their plugin definition to the <a href="https://github.com/cloudfoundry-incubator/cli-plugin-repo/blob/master/repo-index.yml">repo-index.yml</a>
file and submitting a pull request.</p>

<p>For maximum compatibility, plugin authors are encouraged to include <a href="https://github.com/jthomas/copyenv/tree/master/bin">platform binaries</a>
for their plugins.</p>

<p>Go makes it extremely easy to cross-compile your source code for different platforms.</p>

<p>On Mac OS X, if you used Brew to install Go, you can set up cross-compilation with the following commands:</p>

<p><code>
$ brew reinstall go --with-cc-common
$ GOOS=windows GOARCH=386 go build appname.go
</code></p>

<p>For the full list of supported platforms, see the <a href="https://golang.org/doc/install/source#environment">Go documentation</a></p>

<h2>Using the Plugin</h2>

<p>With the CopyEnv plugin installed, we can now run the following command to export an application's VCAP_SERVICES into our local environment.</p>

<p><code>sh
$ cf copyenv APP_NAME
export VCAP_SERVICES='{...}';
</code></p>

<p><strong>Writing a new plugin for the CF CLI was extremely straightforward. It's a
great feature to that enables people to contribute new plugins with minimal effort.
I'm looking forward to seeing what plugins the community comes up with!</strong></p>

<p>You can see the plugin in action below...</p>

<p><img src="https://dl.dropboxusercontent.com/u/10404736/copyenv.gif"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cloud Foundry Custom Buildpacks]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2015/03/04/cloud-foundry-custom-buildpacks/"/>
    <updated>2015-03-04T13:25:00+00:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2015/03/04/cloud-foundry-custom-buildpacks</id>
    <content type="html"><![CDATA[<p>Cloud Foundry <a href="http://docs.cloudfoundry.org/buildpacks/">Buildpacks</a> provide runtime and framework support for applications. Users can rely on the built-in selection for Java, NodeJS, Python, etc. or additional <a href="https://github.com/cloudfoundry-community/cf-docs-contrib/wiki/Buildpacks">community buildpacks</a> from Github.</p>

<p>Buildpacks are open-source, making them simple to customise and include  libraries needed by your application.</p>

<p><a href="https://github.com/jthomas/doctor-watson">Doctor Watson</a> uses an <a href="https://www.npmjs.com/package/sox">NPM module</a> that relies on a command-line application, <a href="sox.sourceforge.net">SOX</a>, being installed in the runtime environment.</p>

<p>Making this command-line application available on the platform required the project to create a <a href="https://github.com/jthomas/nodejs-buildpack">custom NodeJS buildpack</a>.</p>

<p>This was the first time I've needed to create a custom buildpack. Documenting the steps below will hopefully provide a guide for other people wanting to do the same.</p>

<p>Overall, the process was straightforward and left me with a greater understanding of how buildpacks works.</p>

<h2>SOX Audio Processing Library</h2>

<p>We're using the SOX package within Doctor Watson to up-sample an audio file.
This module depends on the command-line SOX audio processing utility being installed and available on the command line. SOX is an open-source C application.</p>

<h2>Buildpack Internals</h2>

<p>Cloud Foundry Buildpacks are Git repositories which must contain three shell scripts under the "bin" directory.</p>

<ul>
<li>detect - Does this buildpack apply to this application?</li>
<li>compile - Build the runtime used to execute the application</li>
<li>release - Controls how the application should be executed</li>
</ul>


<p>These shell scripts can be modified to perform any task necessary for an application runtime.</p>

<p>We're starting with the <a href="https://github.com/cloudfoundry/nodejs-buildpack">default NodeJS buildpack</a>.</p>

<p>The <a href="https://github.com/cloudfoundry/nodejs-buildpack/blob/master/bin/compile">"bin/compile"</a> script installs the correct NodeJS version, NPM modules and sets up the runtime environment to start the application. When the script is ran, a command line argument will give a directory path to place files needed at runtime.</p>

<p>We will need to install the SOX binary and dependent libraries under this directory path.</p>

<p>One method for doing this would be downloading the SOX source code and compiling during deployment, before installing the created binaries into the correct location.</p>

<p>Unfortunately, compiling from source during each deployment would add an unacceptable delay.</p>

<p><em>Therefore, most buildpacks use pre-built binaries, which are downloaded and moved to the build directory during deployment, saving a huge amount of time.</em></p>

<h2>Creating the pre-built binary archive</h2>

<p>Rather than manually creating our binaries from source, we can pull them from the Ubuntu package manager which already maintains a pre-built set of binaries for the <a href="https://packages.debian.org/unstable/sound/sox">SOX package</a>.</p>

<p>Packaging the binary and any dynamic libraries dependencies into an archive file, this can be stored in the buildpack repository for extraction during deployment.</p>

<p>We need to ensure the pre-built binaries were compiled for the same host environment that Cloud Foundry will use to run our application.</p>

<p>Using the cf stacks command, we can see the platforms details.</p>

<p>``` sh
[13:51:45 ~]$ cf stacks
Getting stacks in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...
OK</p>

<p>name      description
lucid64   Ubuntu 10.04
seDEA     private
[13:53:10 ~]$
```</p>

<p>Now we just need access to the same platform to run the package manager on...</p>

<p>Docker to the rescue!</p>

<h2>Using Docker</h2>

<p>We're going to use Docker to run a new container with the same operating system as the Cloud Foundry environment. Using this we can install the SOX package using 'apt-get' and extract all the installed files.</p>

<p>``` sh
[13:56:46 ~]$ docker run -t -i  ubuntu:10.04 /bin/bash
root@7fdb1e9047e1:/#
root@7fdb1e9047e1:/# apt-get install sox
root@7fdb1e9047e1:/# which sox
/usr/bin/sox
root@7fdb1e9047e1:/# ldd /usr/bin/sox</p>

<pre><code>linux-vdso.so.1 =&gt;  (0x00007fff2819f000)
libsox.so.1 =&gt; /usr/lib/libsox.so.1 (0x00007f0f32a94000)
libltdl.so.7 =&gt; /usr/lib/libltdl.so.7 (0x00007f0f3288a000)
libdl.so.2 =&gt; /lib/libdl.so.2 (0x00007f0f32685000)
libpng12.so.0 =&gt; /lib/libpng12.so.0 (0x00007f0f3245e000)
libmagic.so.1 =&gt; /usr/lib/libmagic.so.1 (0x00007f0f32242000)
libz.so.1 =&gt; /lib/libz.so.1 (0x00007f0f3202a000)
libgomp.so.1 =&gt; /usr/lib/libgomp.so.1 (0x00007f0f31e1c000)
libgsm.so.1 =&gt; /usr/lib/libgsm.so.1 (0x00007f0f31c0e000)
libm.so.6 =&gt; /lib/libm.so.6 (0x00007f0f3198a000)
libpthread.so.0 =&gt; /lib/libpthread.so.0 (0x00007f0f3176d000)
libc.so.6 =&gt; /lib/libc.so.6 (0x00007f0f313eb000)
/lib64/ld-linux-x86-64.so.2 (0x00007f0f32d28000)
librt.so.1 =&gt; /lib/librt.so.1 (0x00007f0f311e2000)
</code></pre>

<p>root@7fdb1e9047e1:/#
```</p>

<p>Now we have the location of the SOX binary along with a list of the dynamic libraries it depends on.</p>

<p><em>How do we know which of those libraries were already available in the operating system and those the package manager installed?</em></p>

<p>Using Docker diff, we can compare the container to the base image.</p>

<p><code>sh
[14:02:43 ~]$ docker diff 7fdb1e9047e1 | grep '\.so\.'
C /etc/ld.so.cache
C /etc/ld.so.conf.d
A /etc/ld.so.conf.d/libasound2.conf
C /lib/libgcc_s.so.1
A /usr/lib/libFLAC.so.8
A /usr/lib/libFLAC.so.8.2.0
A /usr/lib/libasound.so.2
A /usr/lib/libasound.so.2.0.0
A /usr/lib/libgomp.so.1
A /usr/lib/libgomp.so.1.0.0
....
</code></p>

<p>This command will output list of files that have been modified. Grepping this for the list of dependencies we have, it's easy to extract those which are new.</p>

<p>We can now copy the files needed from the container filesystem to our local host and bundle into an <a href="https://github.com/jthomas/nodejs-buildpack/blob/master/vendor/sox.tar.gz">archive in the "vendor" directory</a>.</p>

<p><code>sh
[14:02:43 ~]$ docker cp 7fdb1e9047e1:/usr/bin/sox .
</code></p>

<h2>Modifying the "bin/compile" script</h2>

<p>With the pre-built binary package available in the buildpack repository, we just need to extract this during deployment from the vendor directory into the build directory.</p>

<p>Modifying the PATH and LD_LIBRARY_PATH variables will expose the binary during runtime and ensure the dynamic libraries are recognised.</p>

<p>``` sh</p>

<h1>Add SOX binary and libraries to path</h1>

<p>status "Adding SOX library support"
tar xzf $bp_dir/vendor/sox.tar.gz -C $build_dir/vendor/</p>

<h1>Update the PATH</h1>

<p>status "Building runtime environment"
mkdir -p $build_dir/.profile.d
echo "export PATH=\"\$HOME/vendor/node/bin:\$HOME/bin:\$HOME/node_modules/.bin:\$HOME/vendor/:\$PATH\";" > $build_dir/.profile.d/nodejs.sh
echo "export LD_LIBRARY_PATH=\"\$HOME/vendor/libs/\";" >> $build_dir/.profile.d/nodejs.sh
```</p>

<h2>Using the custom buildpack</h2>

<p>Once the buildpack modifications have been committed to the <a href="https://github.com/jthomas/nodejs-buildpack">external Github repository</a>, the application manifest can be modified to point to this new location.</p>

<pre>
---
applications:
- name: doctor-watson
  memory: 256M 
  buildpack: https://github.com/jthomas/nodejs-buildpack.git
  command: node app.js
  services:
  - twilio
  - speech_to_text
  - question_and_answer
</pre>


<p>... at this point all we have to do is deploy our application again to take advantage of the modified runtime.</p>

<h2>Conclusion</h2>

<p>Buildpacks are a fantastic feature of the Cloud Foundry, allowing the platform to support for almost any runtime. Using open-source Git repositories means you can build on any existing buildpack.</p>

<p>For Doctor Watson, we were able to add a command line binary, built in another language, to the NodeJS runtime. Docker was a great tool when developing our custom buildpack.</p>

<p>If you want more information on customising buildpacks, check out the Cloud Foundary <a href="http://docs.cloudfoundry.org/buildpacks/custom.html">documentation</a>.</p>

<p>Source code for the custom buildpack we created is available <a href="https://github.com/jthomas/nodejs-buildpack">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zero Downtime Deployments Using IBM Bluemix]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2014/07/22/zero-downtime-deployments-using-bluemix/"/>
    <updated>2014-07-22T14:42:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2014/07/22/zero-downtime-deployments-using-bluemix</id>
    <content type="html"><![CDATA[<p>Here's a video I've made showing you how to deploy new versions of an
application on IBM Bluemix without the end-user having to suffer any down time:</p>

<iframe width="420" height="315" src="http://jthomas.github.com/jthomas//www.youtube.com/embed/yfLi2hLfgSU" frameborder="0" allowfullscreen></iframe>


<p>Utilising the <a href="http://martinfowler.com/bliki/BlueGreenDeployment.html">Blue Green deployment pattern</a>, we deploy the
new version to a separate host within the production environment, rather than
taking down and updating the existing application. The HTTP router in front of
the applications controls tunnelling application requests between the different
versions. Once we verified the new version is working correctly, we can turn
off the previous version and transfer all traffic to the new instance.</p>

<p><strong>This complex deployment pattern is automatically supported by the Cloud Foundry
technology underpinning IBM Bluemix</strong>.</p>

<p><em>Staging multiple versions of an application, bound to the same external address, with automatic load balancing is handled transparently by the platform.</em></p>

<p><em>This works for any language or
runtime without any modifications to your application.</em></p>

<p>There are a few <a href="https://www.ng.%20bluemix.net/docs/#manageapps/index-gentopic3.html#d2e1">different ways</a>
to achieve this deployment approach using the
platform. The example in the video only uses three commands
with the ‘cf’ tool.</p>

<p>```sh
// Rename the existing application to allow staging a new instance without
// overwriting existing version.<br/>
$ cf rename app old_app</p>

<p>// Deploy the updated application, which will be bound to the same external
// address. HTTP traffic is load balanced between the two versions automatically.
$ cf push</p>

<p>// Verify the new application is working and then turn off the old instance.
$ cf stop old_app
```
<strong>Amazing!</strong></p>
]]></content>
  </entry>
  
</feed>
