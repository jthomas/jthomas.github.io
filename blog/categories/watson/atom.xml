<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: watson | James Thomas]]></title>
  <link href="http://jamesthom.as/blog/categories/watson/atom.xml" rel="self"/>
  <link href="http://jamesthom.as/"/>
  <updated>2016-01-04T15:29:55+00:00</updated>
  <id>http://jamesthom.as/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Updated IBM Watson Nodes for Node-RED]]></title>
    <link href="http://jamesthom.as/blog/2016/01/04/updated-ibm-watson-nodes/"/>
    <updated>2016-01-04T15:45:00+00:00</updated>
    <id>http://jamesthom.as/blog/2016/01/04/updated-ibm-watson-nodes</id>
    <content type="html"><![CDATA[<p>{% img /images/node-red-updates.png %}</p>

<p>Earlier this year, I made a <a href="http://jamesthom.as/blog/2015/04/22/ibm-watson-nodes-for-nodered/">major upate</a> to the Node-RED nodes for the IBM
Watson services available through IBM Bluemix. Since then, the IBM Watson team
has been <a href="https://developer.ibm.com/watson/blog">busy</a>, with lots of changes to APIs. I've recently been working through
these changes, updating the nodes, to ensure they work against the latest APIs.</p>

<p><strong>Updates to these nodes have now been finished and are available through the
<a href="https://console.ng.bluemix.net/catalog/starters/node-red-starter/">boilerplate</a> on IBM Bluemix or by installing the <a href="https://github.com/node-red/node-red-bluemix-nodes">IBM Bluemix Nodes</a> package
locally.</strong></p>

<p>If you have an existing Node-RED instance running in IBM Bluemix, please review
the <a href="https://www.ng.bluemix.net/docs/#starters/Node-RED/nodered.html#nodered">documentation</a> for upgrade instructions.</p>

<p>If you encounter any issues, please raise a <a href="https://github.com/node-red/node-red-bluemix-nodes/issues">issue on Github</a>.</p>

<p><em>For full details on the changes are available in the <a href="https://github.com/node-red/node-red-bluemix-nodes/pull/30">pull request</a>.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Updated Node-RED IBM Watson Nodes]]></title>
    <link href="http://jamesthom.as/blog/2016/01/04/node-red-bluemix-nodes-update/"/>
    <updated>2016-01-04T15:45:00+00:00</updated>
    <id>http://jamesthom.as/blog/2016/01/04/node-red-bluemix-nodes-update</id>
    <content type="html"><![CDATA[<p>{% img /images/node-red-updates.png %}</p>

<p>Earlier this year, I made a <a href="http://jamesthom.as/blog/2015/04/22/ibm-watson-nodes-for-nodered/">major upate</a> to the Node-RED nodes for the IBM
Watson services available through IBM Bluemix. Since then, the IBM Watson team
has been <a href="https://developer.ibm.com/watson/blog">busy</a>, with lots of changes to APIs. I've recently been working through
these changes, updating the nodes, to ensure they work against the latest APIs.</p>

<p><strong>Updates to these nodes have now been finished and are available through the
<a href="https://console.ng.bluemix.net/catalog/starters/node-red-starter/">boilerplate</a> on IBM Bluemix or by installing the <a href="https://github.com/node-red/node-red-bluemix-nodes">IBM Bluemix Nodes</a> package
locally.</strong></p>

<p>If you have an existing Node-RED instance running in IBM Bluemix, please review
the <a href="https://www.ng.bluemix.net/docs/#starters/Node-RED/nodered.html#nodered">documentation</a> for upgrade instructions.</p>

<p>If you encounter any issues, please raise a <a href="https://github.com/node-red/node-red-bluemix-nodes/issues">issue on Github</a>.</p>

<p><em>For full details on the changes are available in the <a href="https://github.com/node-red/node-red-bluemix-nodes/pull/30">pull request</a>.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AlchemyAPI &amp; Updated Watson Nodes for Node-RED]]></title>
    <link href="http://jamesthom.as/blog/2015/07/15/alchemyapi-and-updated-watson-nodes-for-node-red/"/>
    <updated>2015-07-15T16:07:00+01:00</updated>
    <id>http://jamesthom.as/blog/2015/07/15/alchemyapi-and-updated-watson-nodes-for-node-red</id>
    <content type="html"><![CDATA[<p>{% img /images/node-red-updates.png %}</p>

<p>I've recently been working on a <a href="https://github.com/node-red/node-red-bluemix-nodes/commit/56007e60d3414da3eb5c1dac766b23bdd96dd149">number</a> of <a href="https://github.com/node-red/node-red-bluemix-nodes/commit/4d0bcfe34f5e107e3b9e0684cd26ae701f913253">updates</a> to the Node-RED <a href="https://github.com/node-red/node-red-bluemix-nodes">nodes</a> for the IBM Bluemix platform...</p>

<p>Highlights below:</p>

<h2>New AlchemyAPI Nodes</h2>

<p>There are two new nodes (Feature Extract and Image Extract) in the package, allowing users to call services from the AlchemyAPI platform.</p>

<ul>
<li><p><em>Feature Extract.</em> This node will analyse external URLs, HTML or text content with features for text-based analysis
from the AlchemyAPI service, e.g. keywords, sentiment, relationships, etc.</p></li>
<li><p><em>Image Analysis.</em> This node will analyse images, passed in as external URLs or raw image bytes, to extract faces, content and URLs.</p></li>
</ul>


<p>Configuration for each node is available through the node editor panel.</p>

<p>For full details on all the capabilities of the AlchemyAPI platform, please see their <a href="http://www.alchemyapi.com/api">documentation</a>.</p>

<h2>Updated IBM Watson Nodes</h2>

<p>With the <a href="https://developer.ibm.com/watson/blog/2015/07/06/ibm-watson-language-translation-and-speech-services-general-availability/">recent changes</a>
to the IBM Watson services, there were a number of changes needed to support the API changes. All the IBM Watson nodes now work with the GA versions
of the services.</p>

<p><strong>Users must ensure they are using GA versions of the service with the nodes. Details on migration steps are available on the IBM Watson
<a href="https://developer.ibm.com/watson/blog/2015/07/06/ibm-watson-language-translation-and-speech-services-general-availability/">blog post</a> about the updates.</strong></p>

<h2>Running Locally</h2>

<p>When running Node-RED on IBM Bluemix, credentials for the services bound to the application are automatically registered. Previously, running the nodes
outside of IBM Bluemix required complex configuration to register service credentials. With this release, users will
be prompted to input the service credentials in the node editor panel if the application isn't running on IBM Bluemix. Much easier!</p>

<p><strong>If you have questions or encounter issues, please ask over on <a href="http://stackoverflow.com/questions/tagged/node-red">Stackoverflow</a> or raise <a href="https://github.com/node-red/node-red-bluemix-nodes/issues">issues</a> in Github</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IBM Watson Nodes For Node-RED]]></title>
    <link href="http://jamesthom.as/blog/2015/04/22/ibm-watson-nodes-for-nodered/"/>
    <updated>2015-04-22T11:15:00+01:00</updated>
    <id>http://jamesthom.as/blog/2015/04/22/ibm-watson-nodes-for-nodered</id>
    <content type="html"><![CDATA[<p>{% img /images/node-red.png %}</p>

<p>I've updated the IBM Watson Nodes for Node-RED to include seven extra services.</p>

<p>Previously, the package only provided support for the following services:</p>

<ul>
<li>Language Identification.</li>
<li>Machine Translation.</li>
<li>Question &amp; Answers.</li>
</ul>


<p>With the recent <a href="https://github.com/node-red/node-red-bluemix-nodes/pull/10">code changes</a>,
users now have access to the additional services:</p>

<ul>
<li>Message Resonance.</li>
<li>Personality Insights.</li>
<li>Relationship Extraction.</li>
<li>Speech to Text.</li>
<li>Text to Speech.</li>
<li>Tradeoff Analytics.</li>
<li>Visual Recognition.</li>
</ul>


<p><strong>Using Node-RED through the <a href="https://bluemix.net">IBM Bluemix</a> boilerplate will
automatically include the IBM Watson modules in the palette.</strong></p>

<p>It is possible to use the IBM Watson nodes with Node-RED outside of IBM Bluemix
provided you have the <a href="http://docs.run.pivotal.io/devguide/deploy-apps/environment-variable.html">local environment variables</a>
configured to provide the service credentials.</p>

<p>For information about the individual services, please see the <a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/doc/">IBM Watson Developer Cloud</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Doctor Watson]]></title>
    <link href="http://jamesthom.as/blog/2015/02/27/doctor-watson/"/>
    <updated>2015-02-27T15:01:00+00:00</updated>
    <id>http://jamesthom.as/blog/2015/02/27/doctor-watson</id>
    <content type="html"><![CDATA[<p>{% img /images/doctor_watson.png %}</p>

<p><a href="http://doctor-watson.mybluemix.net/">Doctor Watson</a> is an IBM Bluemix application to answer medical questions over the phone, using IBM Watson and Twilio.</p>

<p>Ringing an external phone number, the application will answer and ask for a medical question to help with. Translating your speech into text and using IBM Watson's Question and Answer service, Doctor Watson will query the medical corpus.</p>

<p>Top rated answers will be converted to speech and used as a response over the phone. Users can continue to ask more questions for further information.</p>

<p><em>Putting together this complex application, with voice recognition, telephony handling and a medical knowledge base, was incredibly simple using the IBM Bluemix platform.</em></p>

<p>Source code for the application: <a href="https://github.com/jthomas/doctor-watson">https://github.com/jthomas/doctor-watson</a></p>

<p>Fork and deploy the repository to have your own version of Doctor Watson!</p>

<p><a href="https://bluemix.net/deploy?repository=https://github.com/jthomas/doctor-watson" target="_blank"><img src="http://bluemix.net/deploy/button.png" alt="Bluemix button" /></a></p>

<p><strong>Want to know how the project was built? Read on...</strong></p>

<h2>Overview</h2>

<p>Doctor Watson is a NodeJS application using <a href="http://expressjs.com/">Express</a>, a framework for building web applications, to handle serving static content and creating REST APIs.</p>

<p>The front page gives an overview of the application, served from static HTML files with templating to inject the phone number at runtime.</p>

<p>HTTP endpoints handle the incoming messages from Twilio as users make new phone calls. The application's public URL will be bound to a phone number using Twilio's account administration.</p>

<p>Services for IBM Watson are exposed for the application using the IBM Bluemix platform. Text to Speech and Question and Answer services are used during phone call handling.</p>

<p>The application can be deployed on IBM Bluemix, IBM's public hosted Cloud Foundry platform.</p>

<h2>Handling phone calls</h2>

<p><a href="https://www.twilio.com/">Twilio</a> provides "telephony-as-a-service", making applications able to respond to telephone calls and text messages using a REST API.</p>

<p>Twilio has been made available on the IBM Bluemix platform. Binding this service to your application will provide the authentication credentials to use with the Twilio <a href="http://twilio.github.io/twilio-node/">client library</a>.</p>

<p>Users register external phone numbers through the service, which are bound to  external web addresses controlled by the user. When a person dials that number, the service makes a HTTP call with the details to the application. HTTP responses dictates how to handle the phone call, allowing you to record audio from the user, redirect to another number, play an audio file and much more.</p>

<p>We're using ExpressJS to expose the HTTP endpoints used to handle incoming Twilio messages. Twilio's client libraries abstract the low-level network requests behind a JavaScript interface.</p>

<p>This code snippet shows the outline for message processing.</p>

<p>``` javascript
app.post('/some/path', twilio.webhook(twilio_auth_token), function(req, res) {
  // req.body -> XML body parsed to JS object
  // do some processing</p>

<p>  var twiml = new twilio.TwimlResponse();
  twiml.command(...); // where command is a 'verb' from TwilML</p>

<p>  res.send(twiml);<br/>
});
```</p>

<p>TwilML is <a href="https://www.twilio.com/docs/api/twiml">Twilio Markup Language</a>, an XML message with instructions you can use to tell Twilio how to handle incoming phone calls and SMS messages.</p>

<p>TwimlResponse instances generate the XML message responses. Primary verbs from the TwilML specification are available as chainable function calls on the class instance.</p>

<h3>Doctor Watson Call Flow</h3>

<p>When the user first calls the phone number, Twilio sends a TwilML message over a HTTP POST request to http://doctor-watson.mybluemix.net/calls.</p>

<p>``` javascript
router.post('/', twilio.webhook(twilio_auth_token), function(req, res) {
  log.info(req.body.CallSid + "-> calls/");
  log.debug(req.body);</p>

<p>  var twiml = new twilio.TwimlResponse();
  twiml.say('Hello this is Doctor Watson, how can I help you? Press any key after you have finished speaking')</p>

<pre><code>.record({timeout: 60, action: "/calls/recording"});
</code></pre>

<p>  res.send(twiml);<br/>
})
```</p>

<p>We're using the TwilML response to give the user information on asking a question. Recording their response, the audio file with their question will be sent in another request to the '/calls/recording' location.</p>

<p>``` javascript
router.post('/recording', twilio.webhook(twilio_auth_token), function(req, res) {
  var twiml = new twilio.TwimlResponse();</p>

<p>  enqueue_question(req.body);</p>

<p>  twiml.say("Let me think about that.").redirect("/calls/holding");
  res.send(twiml);
})
```</p>

<p>Using the audio file with the user's question, available as the request body, we now schedule a call to the Watson services.</p>

<p>With the question answering request in-progress, we redirect the user into a holding loop.</p>

<p>``` javascript
router.post('/holding', twilio.webhook(twilio_auth_token), function(req, res) {
  var twiml = new twilio.TwimlResponse();
  twiml.pause({length: 5})</p>

<pre><code>.say("I'm still thinking")    
.redirect("/calls/holding");
</code></pre>

<p>  res.send(twiml);<br/>
});
```</p>

<p>Every five seconds, we relay a message over the phone call until the answer has been returned.</p>

<p>Within the callback for the Question and Answer service, we have the following code.</p>

<p><code>javascript
var forward_to = cfenv.getAppEnv().url + "/calls/answer";
client.calls(call_ssid).update({url: forward_to});    
</code></p>

<p>This uses the Twilio client to update the location for a live call, redirecting to the location which returns the answer.</p>

<p>``` javascript
router.post('/answer', twilio.webhook(twilio_auth_token), function(req, res) {
  var twiml = new twilio.TwimlResponse();</p>

<p>  twiml.say(answers[req.body.CallSid])</p>

<pre><code>.say("Do you have another question?")
.record({timeout: 60, action: "/calls/recording"});
</code></pre>

<p>  res.send(twiml);
})
```</p>

<p>Now we've shown how to handle phone calls, let's dig into the Watson services...</p>

<h2>Using the Watson Services</h2>

<p>IBM Bluemix continues to roll out <a href="https://developer.ibm.com/watson/blog/2015/02/04/new-watson-services-available/">more services</a> to the Watson catalogue. There are now fifteen services to help you create cognitive applications.</p>

<p>Doctor Watson uses <a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/speech-to-text.html">Speech to Text</a> and <a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/question-answer.html">Question and Answer</a>.</p>

<p>All services come with <a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/doc/">great documentationn</a> to get help get you started, with sample code, API definitions and client libraries for different languages.</p>

<p>We're using the <a href="https://www.npmjs.com/package/watson-developer-cloud">NodeJS client library</a> in Doctor Watson.</p>

<h3>Converting audio recording to text</h3>

<p>When we have a new audio recording containing the user question, this needs converting into text to query the Watson Q&amp;A service.</p>

<p>Twilio makes the recording available at any external URL as a WAV file with an 8Khz sample rate. Watson's Speech to Text services has a minimum sample rate for audio input for 16Khz.</p>

<p>Before sending the file to the service, we need to up-sample the audio.</p>

<p>Searching for a Node package that might help, uncovered this <a href="https://www.npmjs.com/package/sox">library</a>. Using the SOX audio processing library, we can easily convert audio files between sample rates.</p>

<p>``` javascript
var job = sox.transcode(input, output, {</p>

<pre><code>sampleRate: 16000,
format: 'wav',
channelCount: 1
</code></pre>

<p>  });
  job.on('error', function(err) {</p>

<pre><code>log.error(err);
</code></pre>

<p>  });
  job.on('progress', function(amountDone, amountTotal) {</p>

<pre><code>log.debug("progress", amountDone, amountTotal);
</code></pre>

<p>  });</p>

<p>  job.on('end', function() {</p>

<pre><code>log.debug("Transcoding finished.");    
</code></pre>

<p>  });
  job.start();
```</p>

<p>This package relies on the SOX C library, which isn't installed on the default host environment in IBM Bluemix. Overcoming this hurdle meant creating a <a href="https://github.com/jthomas/nodejs-buildpack">custom NodeJS buildpack</a> which installed the pre-built binaries into the application runtime. I'm saving the details of this for another blog post...</p>

<p>Using the Watson client library, we can send this audio to the external service for converting to text.</p>

<p>``` javascript
var speech_to_text = watson.speech_to_text({
  username: USERNAME,
  password: PASSWORD,
  version: 'v1'
});</p>

<p>var params = {<br/>
  audio: fs.createReadStream(audio),
  content_type: 'audio/l16; rate=16000'
};</p>

<p>speech_to_text.recognize(params, function(err, res) {
  if (err) return;</p>

<p>  var question = res.results[res.result_index],
});
```</p>

<p>... which we can now use to query the healthcare corpus for the Watson Q&amp;A service.</p>

<h3>Getting answers</h3>

<p>When asking questions, we need to set the correct corpus to query for answers.</p>

<p>``` javascript
var question_and_answer_healthcare = watson.question_and_answer({
  username: USERNAME,
  password: PASSWORD,
  version: 'v1',
  dataset: 'healthcare'
});</p>

<p>exports.ask = function (question, cb) {
  question_and_answer_healthcare.ask({ text: question}, function (err, response) {</p>

<pre><code>  if (err) return ;

  var first_answer = response[0].question.evidencelist[0].text;  
  cb(first_answer);    
</code></pre>

<p>  });<br/>
};
```</p>

<p>This triggers the callback we've registered with the first answer in the returned results. Answers are stored as values in a map, with the key as the call ssid, before triggering the redirect to the '/calls/answer' location shown above.</p>

<h2>Deploying to Bluemix</h2>

<p>Hosting the application on IBM Bluemix uses the following manifest file to configure the application at runtime.</p>

<pre>
---
applications:
- name: doctor-watson
  memory: 256M 
  buildpack: https://github.com/jthomas/nodejs-buildpack.git
  command: node app.js
  services:
  - twilio
  - speech_to_text
  - question_and_answer
</pre>


<p>We're binding the services to the application and specifying the custom buildpack to expose the SOX library at runtime.</p>

<p>Following this...</p>

<p><code>sh
$ cf push // and Doctor Watson is live!
</code></p>

<p>Check out the source code here for further details. You can even run your own version of the application, follow the instructions in the README.md</p>
]]></content>
  </entry>
  
</feed>
