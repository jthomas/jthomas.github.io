<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: openwhisk | James Thomas]]></title>
  <link href="http://jthomas.github.com/jthomas/blog/categories/openwhisk/atom.xml" rel="self"/>
  <link href="http://jthomas.github.com/jthomas/"/>
  <updated>2018-07-20T15:45:43+01:00</updated>
  <id>http://jthomas.github.com/jthomas/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Monitoring Dashboards With Kibana For IBM Cloud Functions]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2018/07/18/monitoring-dashboards-with-kibana-for-ibm-cloud-functions/"/>
    <updated>2018-07-18T16:08:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2018/07/18/monitoring-dashboards-with-kibana-for-ibm-cloud-functions</id>
    <content type="html"><![CDATA[<p>Following all the events from the World Cup can be hard. So many matches, so many goals. Rather than manually refreshing BBC Football to check the scores, I decided to created a <a href="https://twitter.com/WC2018_Goals">Twitter bot</a> that would automatically tweet out each goal.</p>

<p><img src="/images/monitoring-goalbot/wcgoalbot.png" title="World Cup Goal Bot" ></p>

<p><a href="https://github.com/jthomas/goalbot">The Twitter bot</a> runs on <a href="https://console.bluemix.net/openwhisk">IBM Cloud Functions</a>. It is called once a minute to check for new goals, using the <a href="https://github.com/apache/incubator-openwhisk-package-alarms">alarm trigger feed</a>. If new goals have been scored, it calls another action to send the tweet messages.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">‚öΩÔ∏è GOAL ‚öΩÔ∏è<br>üë® Harry MAGUIRE (Û†Åøüè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø ) @ 30&#39;. üë®<br>üèü Sweden üá∏üá™ (0) v England Û†Åøüè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø (1) üèü<a href="https://twitter.com/hashtag/WorldCup?src=hash&amp;ref_src=twsrc%5Etfw">#WorldCup</a></p>&mdash; WC 2018 Goal Bot (@WC2018_Goals) <a href="https://twitter.com/WC2018_Goals/status/1015604110006120448?ref_src=twsrc%5Etfw">July 7, 2018</a></blockquote>


<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>Once it was running, I need to ensure it was working correctly for the duration of the tournament. Using the <a href="https://console.bluemix.net/catalog/services/log-analysis">IBM Cloud Logging</a> service, I built a custom monitoring dashboard to help to me recognise and diagnose issues.</p>

<p><img src="/images/monitoring-goalbot/dashboard-overview.png" title="Monitoring Dashboard" ></p>

<p>The dashboard showed counts for successful and failed activations, when they occurred and a list of failed activations. If issues have occurred, I can retrieve the failed activation identifiers and investigate further.</p>

<p><em>Let's walk through the steps used to create this dashboard to help you create custom visualisations for serverless applications running on IBM Cloud Functions...</em></p>

<h2>IBM Cloud Logging</h2>

<p><a href="https://console.bluemix.net/docs/services/CloudLogAnalysis/index.html">IBM Cloud Logging</a> can be accessed <a href="https://console.bluemix.net/docs/openwhisk/openwhisk_logs.html#openwhisk_logs">using the link</a> on the IBM Cloud Functions dashboard. This will open the logging service for the current organisation and space.</p>

<p><img src="/images/monitoring-goalbot/open-logging.gif" title="Opening Logging Service" ></p>

<p>All activation records and application logs are automatically forwarded to the logging service by IBM Cloud Functions.</p>

<p><img src="/images/monitoring-goalbot/discover.png" title="Kibana Discover Screen" ></p>

<h3>Log Message Fields</h3>

<p>Activation records and application log messages have a number of common record fields.</p>

<ul>
<li><code>activationId_str</code> - <em>activation identifier for log message.</em></li>
<li><code>timestamp</code> - <em>log draining time.</em></li>
<li><code>@timestamp</code> - <em>message ingestion time.</em></li>
<li><code>action_str</code> - <em>fully qualified action name</em></li>
</ul>


<p>Log records for different message types are identified using the <code>type</code> field. This is either <code>activation_record</code> or <code>user_logs</code> for IBM Cloud Functions records.</p>

<p>Activation records have the following custom fields.</p>

<ul>
<li><code>duration_int</code> - <em>activation duration in milliseconds</em></li>
<li><code>status_str</code> - <em>activation status response (non-zero for errors)</em></li>
<li><code>message</code> - <em>activation response returned from action</em></li>
<li><code>time_date</code> - <em>activation record start time</em></li>
<li><code>end_date</code> - <em>activation record end time</em></li>
</ul>


<p>Applications log lines, written to stdout or stderr, are forwarded as individual records. One application log line per record. Log message records have the following custom fields.</p>

<ul>
<li><code>message</code> - <em>single application log line output</em></li>
<li><code>stream_str</code> - <em>log message source, either <code>stdout</code> or <code>stderr</code></em></li>
<li><code>time_date</code> - <em>timestamp parsed from application log line</em></li>
</ul>


<h3>Finding Log Messages For One Activation</h3>

<p>Use this query string in the "<a href="https://www.elastic.co/guide/en/kibana/current/discover.html"><em>Discover</em>"</a> tab to retrieve all logs messages from a particular activation.</p>

<p><code>
activationId_str: &lt;ACTIVATION_ID&gt;
</code></p>

<p>Search queries are executed against log records within a <a href="https://www.elastic.co/guide/en/kibana/current/set-time-filter.html">configurable time window</a>.</p>

<h2>Monitoring Dashboard</h2>

<p><img src="/images/monitoring-goalbot/dashboard-overview.png" title="Monitoring Dashboard" ></p>

<p>This is the monitoring dashboard I created. It contains visualisations showing counts for successful and failed activations, histograms of when they occurred and a list of the recent failed activation identifiers.</p>

<p>It allows me to quickly review the previous 24 hours activations for issues. If there are notable issues, I can retrieve the failed activation identifiers and investigate further.</p>

<p>Before being able to create the dashboard, I needed to define two resources: <strong><em>saved searches</em></strong> and <strong><em>visualisations</em></strong>.</p>

<h3>Saved Searches</h3>

<p><img src="/images/monitoring-goalbot/saved-searches.png" title="Saving Search Queries" ></p>

<p>Kibana supports saving and referring to search queries from visualisations using explicit names.</p>

<p>Using <a href="https://www.elastic.co/guide/en/kibana/current/managing-saved-objects.html">saved searches</a> with visualisations, rather than explicit queries, removes the need to manually update visualisations' configuration when queries change.</p>

<p>This dashboard uses two custom queries in visualisations. Queries are needed to find activation records from both successful and failed invocations.</p>

<ul>
<li>Create a new <em>"Saved Search"</em> named <em>"activation records (success)"</em> using the following search query.</li>
</ul>


<p><code>
type: activation_record AND status_str: 0
</code></p>

<ul>
<li>Create a new <em>"Saved Search"</em> named <em>"activation records (failed)"</em> using the following search query.</li>
</ul>


<p><code>
type: activation_record AND NOT status_str: 0
</code></p>

<p><em>The <code>status_str</code> field is set to a non-zero value for failures. Using the <code>type</code> field ensures log messages from other sources are excluded from the results.</em></p>

<h3>Indexed Fields</h3>

<p>Before referencing log record fields in visualisations, those fields <a href="https://www.elastic.co/guide/en/kibana/current/index-patterns.html#reload-fields">need to be indexed</a> correctly. Use these instructions to verify activation records fields are available.</p>

<ul>
<li>Check IBM Cloud Functions logs are available in IBM Cloud Logging using the "<em>Discover</em>" tab.</li>
<li>Click the "‚öôÔ∏è <em>(Management)</em>" menu item on the left-hand drop-down menu in IBM Cloud Logging.</li>
<li>Click the "<em>Index Patterns</em>" link.</li>
<li>Click the üîÑ button to refresh the field list.</li>
</ul>


<p><img src="/images/monitoring-goalbot/refresh-fields.gif" title="Refresh field index" ></p>

<h3>Visualisations</h3>

<p>Three types of <a href="https://www.elastic.co/guide/en/kibana/current/visualize.html">visualisation</a> are used on the monitoring dashboard. Metric displays are used for the activation counts, vertical bar charts for the activation times and a data table to list failed activations.</p>

<p><em>Visualisations <a href="https://www.elastic.co/guide/en/kibana/current/createvis.html">can be created</a> by opening the "Visualize" menu item and select a new visualisation type under the "Create New Visualization" menu.</em></p>

<p>Create five different visualisations, using the instructions below, before moving on to create the dashboard.</p>

<h4>Activation Counts</h4>

<p>Counts for successful and failed activations are displayed as singular <a href="https://www.elastic.co/guide/en/kibana/current/metric-chart.html">metric values</a>.</p>

<ul>
<li>Select the "Metric" visualisation from the visualisation type list.</li>
<li>Use the "activation records (success)" saved search as the data source.</li>
<li>Ensure the Metric Aggregation is set to "Count"</li>
<li>Set the "Font Size" under the Options menu to 120pt.</li>
<li>Save the visualisation as "Activation Counts (Success)"</li>
</ul>


<p><img src="/images/monitoring-goalbot/metrics-success.png" title="Activation success metric" ></p>

<ul>
<li>Repeat this process to create the failed activation count visualisation.</li>
<li>Use the "activation records (failed)" saved search as the data source.</li>
<li>Save the visualisation as "Activation Counts (Failed)".</li>
</ul>


<p><img src="/images/monitoring-goalbot/metrics-fail.png" title="Activation failed metric" ></p>

<h4>Activation Times</h4>

<p>Activation counts over time, for successful and failed invocations, are displayed in <a href="https://www.elastic.co/guide/en/kibana/current/xy-chart.html">vertical bar charts</a>.</p>

<ul>
<li>Select the "Vertical bar chart" visualisation from the visualisation type list.</li>
<li>Use the "activation records (success)" saved search as the data source.</li>
<li>Set the "Custom Label" to Invocations</li>
<li>Add an "X-Axis" bucket type under the Buckets section.</li>
<li>Choose "Date Histogram" for the aggregation, "@timestamp" for the field and "Minute" for the interval.</li>
<li>Save the visualisation as "Activation Times (Success)"</li>
</ul>


<p><img src="/images/monitoring-goalbot/activation-times.png" title="Activation times chart" ></p>

<ul>
<li>Repeat this process to create the failed activation times visualisation.</li>
<li>Use the "activation records (failed)" saved search as the data source.</li>
<li>Save the visualisation as "Activation Times (Failed)"</li>
</ul>


<h4>Failed Activations List</h4>

<p>Activation identifiers for failed invocations are shown using a <a href="https://www.elastic.co/guide/en/kibana/current/data-table.html">data table</a>.</p>

<ul>
<li>Select the "Data table" visualisation from the visualisation type list.</li>
<li>Use the "activation records (failed)" saved search as the data source.</li>
<li>Add a "Split Rows" bucket type under the Buckets section.</li>
<li>Choose "Date Histogram" for the aggregation, "@timestamp" for the field and "Second" for the interval.</li>
<li>Add a "sub-bucket" with the "Split Rows" type.</li>
<li>Set sub aggregation to "Terms", field to "activationId_str" and order by "Term".</li>
<li>Save the visualisation as "Errors Table"</li>
</ul>


<p><img src="/images/monitoring-goalbot/activations-table.png" title="Failed activation table" ></p>

<h3>Creating the dashboard</h3>

<p>Having created the individual visualisations components, the <a href="https://www.elastic.co/guide/en/kibana/current/dashboard.html">monitoring dashboard</a> can be constructed.</p>

<ul>
<li>Click the "Dashboard" menu item from the left-and menu panel.</li>
<li>Click the "Add" button to import visualisations into the current dashboard.</li>
<li>Add each of the five visualisations created above.</li>
</ul>


<p><em>Hovering the mouse cursor over visualisations will reveal icons for moving and re-sizing.</em></p>

<ul>
<li>Re-order the visualisations into the following rows:

<ul>
<li>Activations Metrics</li>
<li>Activation Times</li>
<li>Failed Activations List</li>
</ul>
</li>
<li>Select the "Last 24 hours" time window, available from the relative time ranges menu.</li>
<li>Save the dashboard as "<em>Cloud Functions Monitoring</em>". Tick the "<em>store time with dashboard</em>" option.</li>
</ul>


<p><img src="/images/monitoring-goalbot/dashboard-overview.png" title="Monitoring Dashboard" ></p>

<p>Having saved the dashboard with time window, re-opening the dashboard will show our visualisations with data for the previous 24 hours. This dashboard can be used to quickly review recent application issues.</p>

<h2>Conclusion</h2>

<p>Monitoring serverless applications is crucial to diagnosing issues on serverless platforms.</p>

<p><a href="https://console.bluemix.net/openwhisk/dashboard">IBM Cloud Functions</a> provides automatic integration with the <a href="https://console.bluemix.net/catalog/services/log-analysis">IBM Cloud Logging</a> service. All activation records and application logs from serverless applications are automatically forwarded as log records. This makes it simple to build custom monitoring dashboards using these records for serverless applications running on IBM Cloud Functions.</p>

<p>Using this service with World Cup Twitter bot allowed me to easily monitor the application for issues. This was much easier than manually retrieving and reviewing activation records using the CLI!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debugging Node.js OpenWhisk Actions]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2018/07/10/debugging-node-dot-js-openwhisk-actions/"/>
    <updated>2018-07-10T09:00:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2018/07/10/debugging-node-dot-js-openwhisk-actions</id>
    <content type="html"><![CDATA[<p>Debugging serverless applications is one of the <a href="https://www.stackery.io/blog/the-serverless-learning-curve/">most challenging issues</a> developers face when using serverless platforms. How can you use debugging tools without any access to the runtime environment?</p>

<p>Last week, I worked out <a href="https://twitter.com/thomasj/status/1013006648439443458">how to expose the Node.js debugger</a> in the Docker environment used for the application runtime in Apache OpenWhisk.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Want to use Node.js debugger for <a href="https://twitter.com/openwhisk?ref_src=twsrc%5Etfw">@openwhisk</a> actions? Start runtime container locally with this command to expose v8 inspector.<br>$ docker run -p 8080:8080 -p 9229:9229 -it openwhisk/action-nodejs-v8 node --inspect=0.0.0.0:9229 app.js<br>Then connect Chrome Dev Tools or <a href="https://twitter.com/code?ref_src=twsrc%5Etfw">@code</a>. üíØ <a href="https://t.co/X4i01QEOmg">pic.twitter.com/X4i01QEOmg</a></p>&mdash; James Thomas (@thomasj) <a href="https://twitter.com/thomasj/status/1013006648439443458?ref_src=twsrc%5Etfw">June 30, 2018</a></blockquote>


<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>Using the remote debugging service, we can set breakpoints and step through action handlers live, rather than just being reliant on logs and metrics to diagnose bugs.</p>

<p><strong>So, how does this work?</strong></p>

<p><em>Let's find out more about how Apache OpenWhisk executes serverless functions...</em></p>

<h2>Background</h2>

<p><a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> is the open-source serverless platform which powers <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a>. OpenWhisk <a href="https://medium.com/openwhisk/uncovering-the-magic-how-serverless-platforms-really-work-3cb127b05f71">uses Docker containers</a> to create isolated runtime environments for executing serverless functions.</p>

<p>Containers are started on-demand as invocation requests arrive. Serverless function source files are dynamically injected into the runtime and executed for each invocation. Between invocations, containers are paused and kept in a cache for re-use with further invocations.</p>

<p>The benefit of using an open-source serverless platform is that the <a href="https://github.com/search?q=incubator-openwhisk-runtime">build files</a> used to create runtime images are also open-source. OpenWhisk also automatically builds and publishes all <a href="https://hub.docker.com/r/openwhisk/">runtime images externally</a> on Docker Hub. Running containers using these images allows us to simulate the remote serverless runtime environment.</p>

<h3>Runtime Images</h3>

<p>All OpenWhisk runtime images are <a href="https://hub.docker.com/r/openwhisk/">published externally</a> on Docker Hub.</p>

<p>Runtime images <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-new.md#action-interface">start a HTTP server</a> which listens on port 8080. This HTTP server must implement two API endpoints (<code>/init</code> &amp; <code>/run</code>) accepting HTTP POST requests. The platform uses these endpoints to initialise the runtime with action code and then invoke the action with event parameters.</p>

<p>More details on the API endpoints can be found in this <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">blog post</a> on creating Docker-based actions.</p>

<h3>Node.js Runtime Image</h3>

<p>This repository contains the source code used to create <a href="https://hub.docker.com/r/openwhisk/action-nodejs-v8/">Node.js runtime environment image</a>.</p>

<p><a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs">https://github.com/apache/incubator-openwhisk-runtime-nodejs</a></p>

<p>Both <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/tree/master/core/nodejs8Action">Node.js 8</a> and <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/tree/master/core/nodejs6Action">6 runtimes</a>  are built from a <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/tree/master/core/nodejsActionBase">common base image</a>. This base image contains an <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/app.js">Express.js server</a> which handles the platform API requests. The <code>app.js</code> file containing the server <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejs8Action/Dockerfile#L28">is executed</a> when the containers starts.</p>

<p>JavaScript code is injected into the runtime using the <code>/init</code> API. Actions created from source code are <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L76">dynamically evaluated</a> to instantiate the code in the runtime. Actions created from zip files are <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L54">extracted into a temporary directory</a> and <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L61">imported as a Node.js module</a>.</p>

<p>Once instantiated, actions are executed using the <code>/run</code> API. Event parameters are come from the request body. Each time a new request is received, the server <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L95">calls the action handler with event parameters</a>. Returned values are serialised as the JSON body in the API response.</p>

<h3>Starting Node.js Runtime Containers</h3>

<p><a href="https://docs.docker.com/engine/reference/commandline/run/">Use this command</a> to start the Node.js runtime container locally.</p>

<p><code>
$ docker run -it -p 8080:8080 openwhisk/action-nodejs-v8
</code></p>

<p>Once the container has started, port 8080 on localhost will be mapped to the HTTP service exposed by the runtime environment. This can be used to inject serverless applications into the runtime environment and invoke the serverless function handler with event parameters.</p>

<h2>Node.js Remote Debugging</h2>

<p>Modern versions of the Node.js runtime have a command-line flag (<code>--inspect</code>) to expose a <a href="https://nodejs.org/api/debugger.html#debugger_advanced_usage">remote debugging service</a>. This service runs a WebSocket server on localhost which implements the <a href="https://chromedevtools.github.io/devtools-protocol/">Chrome DevTools Protocol</a>.</p>

<p><code>
$ node --inspect index.js
Debugger listening on 127.0.0.1:9229.
</code></p>

<p>External tools can connect to this port to provide debugging capabilities for Node.js code.</p>

<p>Docker images for the OpenWhisk Node.js runtimes use the <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejs8Action/Dockerfile#L28">following command</a> to start the internal Node.js process. <strong>Remote debugging is not enabled by default.</strong></p>

<p><code>
node --expose-gc app.js
</code></p>

<p>Docker allows containers to override the default image start command using a <a href="https://docs.docker.com/engine/reference/run/">command line argument</a>.</p>

<p><strong>This command will start the OpenWhisk Node.js runtime container with the remote debugging service enabled.</strong> Binding the HTTP API and WebSocket ports to the host machine allows us to access those services remotely.</p>

<p><code>
docker run -p 8080:8080 -p 9229:9229 -it openwhisk/action-nodejs-v8 node --inspect=0.0.0.0:9229 app.js
</code></p>

<p><em>Once a container from the runtime image has started, we can connect our favourite debugging tools...</em></p>

<h3>Chrome Dev Tools</h3>

<p>To connect <a href="https://developers.google.com/web/tools/chrome-devtools/">Chrome Dev Tools</a> to the remote Node.js debugging service, follow these steps.</p>

<ul>
<li>Open the following page in Chrome: <a href="chrome://inspect/#devices">chrome://inspect/#devices</a></li>
</ul>


<p><img src="/images/debugging/devtools.png" title="Chrome Dev Tools" ></p>

<p>Chrome Dev Tools is configured to open a connection on port 9229 on localhost. If the web socket connection succeeds, the debugging target should be listed in the "Remote Target" section.</p>

<ul>
<li>Click the "<em>Open dedicated DevTools for Node</em>" link.</li>
</ul>


<p>In the "Sources" panel the JavaScript files loaded by the Node.js process are available.</p>

<p><img src="/images/debugging/devtools-debugging.png" title="Chrome Dev Tools Debugging" ></p>

<p>Setting breakpoints in the <code>runner.js</code> file will allow you to halt execution for debugging upon invocations.</p>

<h3>VSCode</h3>

<p><a href="https://code.visualstudio.com/">Visual Studio Code</a> supports remote debugging of Node.js code using the Chrome Dev Tools protocol. Follow these steps to connect the editor to the remote debugging service.</p>

<ul>
<li>Click the menu item "<em>Debug -> Add Configuration</em>"</li>
<li>Select the "<em>Node.js: Attach to Remote Program</em>" from the Intellisense menu.</li>
<li>Edit the default configuration to have the following values.</li>
</ul>


<p><code>json
{
  "type": "node",
  "request": "attach",
  "name": "Attach to Remote",
  "address": "127.0.0.1",
  "port": 9229,
  "localRoot": "${workspaceFolder}"
}
</code></p>

<p><img src="/images/debugging/vscode.png" title="Visual Studio Code" ></p>

<ul>
<li>Choose the new "<em>attach to remote</em>" debugging profile and click the Run button.</li>
</ul>


<p>The "<em>Loaded Scripts</em>" window will show all the JavaScript files loaded by the Node.js process.</p>

<p><img src="/images/debugging/vscode-debugging.png" title="Visual Studio Code Debugging" ></p>

<p>Setting breakpoints in the <code>runner.js</code> file will allow you to halt execution for debugging upon invocations.</p>

<h3>Breakpoint Locations</h3>

<p>Here are some useful locations to set breakpoints to catch errors in your serverless functions for the OpenWhisk Node.js runtime environments.</p>

<h4>Initialisation Errors - Source Actions</h4>

<p>If you are creating OpenWhisk actions from JavaScript source files, the code is dynamically evaluated during  the <code>/init</code> request at <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L76">this location</a>. Putting a breakpoint here will allow you to catch errors thrown during that <code>eval()</code> call.</p>

<h4>Initialisation Errors - Binary Actions</h4>

<p>If you are creating OpenWhisk actions from a zip file containing JavaScript modules, <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L54">this location</a> is where the archive is extracted in the runtime filesystem. Putting a breakpoint here will catch errors from the extraction call and runtime checks for a valid JavaScript module.</p>

<p><a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L61">This code</a> is where the JavaScript module is imported once it has been extracted. Putting a breakpoint here will catch errors thrown importing the module into the Node.js environment.</p>

<h4>Action Handler Errors</h4>

<p>For both source file and zipped module actions, <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L95">this location</a> is where the action handler is invoked on each <code>/run</code> request. Putting a breakpoint here will catch errors thrown from within action handlers.</p>

<h2>Invoking OpenWhisk Actions</h2>

<p>Once you have attached the debugger to the remote Node.js process, you need to send the API requests to simulate the platform invocations. Runtime containers use separate HTTP endpoints to import the action source code into the runtime environment (<code>/init</code>)  and then fire the invocation requests (<code>/run</code>).</p>

<h4>Generating Init Request Body - Source Files</h4>

<p>If you are creating OpenWhisk actions from JavaScript source files, send the following JSON body in the HTTP POST to the <code>/init</code> endpoint.</p>

<p>```json
{
  "value": {</p>

<pre><code>"main": "&lt;FUNCTION NAME IN SOURCE FILE&gt;",
"code": "&lt;INSERT SOURCE HERE&gt;"
</code></pre>

<p>  }
}
```</p>

<p><code>code</code> is the JavaScript source to be evaluated which contains the action handler. <code>main</code> is the function name in the source file used for the action handler.</p>

<p>Using the <code>jq</code> <a href="https://stedolan.github.io/jq/">command-line tool</a>, we can create the JSON body for the source code in <code>file.js</code>.</p>

<p><code>sh
$ cat file.js | jq -sR  '{value: {main: "main", code: .}}'
</code></p>

<h4>Generating Init Request Body - Zipped Modules</h4>

<p>If you are creating OpenWhisk actions from a zip file containing JavaScript modules, send the following JSON body in the HTTP POST to the <code>/init</code> endpoint.</p>

<p>```json
{
  "value": {</p>

<pre><code>"main": "&lt;FUNCTION NAME ON JS MODULE&gt;",
"code": "&lt;INSERT BASE64 ENCODED STRING FROM ZIP FILE HERE&gt;",
"binary": true
</code></pre>

<p>  }
}
```</p>

<p><code>code</code> must be a Base64 encoded string for the zip file. <code>main</code> is the function name returned in the imported JavaScript module to call as the action handler.</p>

<p>Using the <code>jq</code> <a href="https://stedolan.github.io/jq/">command-line tool</a>, we can create the JSON body for the zip file in <code>action.zip</code>.</p>

<p><code>sh
$ base64 action.zip | tr -d '\n' | jq -sR '{value: {main: "main", binary: true, code: .}}'
</code></p>

<h4>Sending Init Request</h4>

<p>The <a href="https://httpie.org/">HTTPie</a> tool makes it simple to send HTTP requests from the command-line.</p>

<p>Using this tool, the following command will initialise the runtime container with an OpenWhisk action.</p>

<p>```sh
$ http post localhost:8080/init &lt; init.json
HTTP/1.1 200 OK
...
{</p>

<pre><code>"OK": true
</code></pre>

<p>}
```</p>

<p>If this HTTP request returns without an error, the action is ready to be invoked.</p>

<p><em>No further initialisation requests are needed unless you want to modify the action deployed.</em></p>

<h4>Generating Run Request Body</h4>

<p>Invocations of the action handler functions are triggered from a HTTP POST to the <code>/run</code> API endpoint.</p>

<p>Invocations parameters are sent in the JSON request body, using a JSON object with a <code>value</code> field.</p>

<p>```json
{
  "value": {</p>

<pre><code>"some-param-name": "some-param-value",
"another-param-name": "another-param-value",
</code></pre>

<p>  }
}
```</p>

<h4>Sending Run Request</h4>

<p>Using the <a href="https://httpie.org/">HTTPie</a> tool, the following command will invoke the OpenWhisk action.</p>

<p>```sh
$ http post localhost:8080/run &lt; run.json
HTTP/1.1 200 OK
...
{</p>

<pre><code>"msg": "Hello world"
</code></pre>

<p>}
```</p>

<p>Returned values from the action handler are serialised as the JSON body in the HTTP response. Issuing further HTTP POST requests to the <code>/run</code> endpoint allows us to re-invoke the action.</p>

<h2>Conclusion</h2>

<p>Lack of debugging tools is one of the biggest complaints from developers migrating to serverless platforms.</p>

<p>Using an open-source serverless platform helps with this problem, by making it simple to run the same containers locally that are used for the platform's runtime environments. Debugging tools can then be started from inside these local environments to simulate remote access.</p>

<p>In this example, this approach was used to enable the remote debugging service from the OpenWhisk Node.js runtime environment. The same approach could be used for any language and debugging tool needing local access to the runtime environment.</p>

<p>Having access to the Node.js debugger is huge improvement when debugging challenging issues, rather than just being reliant on logs and metrics collected by the platform.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Binding IAM Services To IBM Cloud Functions]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2018/06/05/binding-iam-services-to-ibm-cloud-functions/"/>
    <updated>2018-06-05T09:47:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2018/06/05/binding-iam-services-to-ibm-cloud-functions</id>
    <content type="html"><![CDATA[<p><a href="https://console.bluemix.net/docs/openwhisk/binding_services.html#binding_services">Binding service credentials</a> to actions and packages is a much better approach to handling authentication credentials in <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a>, than manually updating (and maintaining) <a href="https://console.bluemix.net/docs/openwhisk/parameters.html#default-params-action">default parameters</a> üîê.</p>

<p>IBM Cloud Functions supports binding credentials from <a href="https://console.bluemix.net/docs/iam/index.html#iamoverview">IAM-based</a> and <a href="https://console.bluemix.net/docs/iam/cfaccess.html#cfaccess">Cloud Foundry provisioned</a> services.</p>

<p><a href="https://console.bluemix.net/docs/openwhisk/binding_services.html#binding_services">Documentation</a> and <a href="https://lornajane.net/posts/2018/bind-services-to-openwhisk-packages">blog posts</a> demonstrating service binding focuses on traditional platform services, created using the Cloud Foundry service broker. As IBM Cloud integrates IAM across the platform, more platform services will migrate to use the IAM service for managing authentication credentials.</p>

<p><blockquote><p></p></p><p><p>How do we bind credentials for IAM-based services to IBM Cloud Functions? ü§î</p></p><p><p></p></blockquote></p>

<p>Binding IAM-based services to IBM Cloud Functions works the same as traditional platform services, but has some differences in how to retrieve details needed for the <code>service bind</code> command.</p>

<p><em>Let's look at how this works...</em></p>

<h2>Binding IAM Credentials</h2>

<h3>Requirements</h3>

<p>Before binding an IAM-based service to IBM Cloud Functions, the following conditions must be met.</p>

<ul>
<li><a href="https://console.bluemix.net/docs/overview/ui.html">Service instance has been provisioned</a>.</li>
<li><a href="https://console.bluemix.net/docs/resources/service_credentials.html#service_credentials">Service credentials have been created for that instance</a>.</li>
</ul>


<p>You will need the following information to bind a service credentials.</p>

<ul>
<li>Service name.</li>
<li><em>(Optional)</em> Instance name.</li>
<li><em>(Optional)</em> Credentials identifier.</li>
</ul>


<h3>Using the CLI</h3>

<p>Use the <code>ibmcloud wsk service bind</code> command to <a href="https://console.bluemix.net/docs/openwhisk/binding_services.html#binding_services">bind service credentials</a> to actions or packages.</p>

<p><code>
bx wsk service bind &lt;SERVICE_NAME&gt; &lt;ACTION|PACKAGE&gt; --instance &lt;INSTANCE&gt; --keyname &lt;KEY&gt;
</code></p>

<p>This command supports the following (optional) flags: <code>--instance</code> and <code>--keyname</code>.</p>

<p><em>If the instance and/or key names are not specified, the CLI uses the first instance and credentials returned from the system for the service identifier.</em></p>

<h3>Accessing from actions</h3>

<p>Credentials are stored as <a href="https://console.bluemix.net/docs/openwhisk/parameters.html#default-params-action">default parameters</a> on the action or package.</p>

<p>The command uses a special parameter name (<code>__bx_creds</code>) to store all credentials. Individual service credentials are indexed using the service name.</p>

<p>```json
{
   "__bx_creds":{</p>

<pre><code>  "service-name":{
     "apikey":"&lt;API_KEY&gt;",
     ...
  }
</code></pre>

<p>   }
}
```</p>

<p>Default parameters are automatically merged into the request parameters during invocations.</p>

<h2>Common Questions</h2>

<h4>How can I tell whether a service instance uses IAM-based authentication?</h4>

<p>Running the <code>ibmcloud resource service-instances</code> command will return the IAM-based service instances provisioned.</p>

<p>Cloud Foundry provisioned services are available using a different command: <code>ibmcloud service list</code>.</p>

<p><em>Both service types can be bound using the CLI but the commands to retrieve the necessary details are different.</em></p>

<h4>How can I find the service name for an IAM-based service instance?</h4>

<p>Run the <code>ibmcloud resource service-instance &lt;INSTANCE_NAME&gt;</code> command.</p>

<p>Service names are shown as the <code>Service Name:</code> field value.</p>

<h4>How can I list available service credentials for an IAM-based service instance?</h4>

<p>Use the <code>ibmcloud resource service-keys --instance-name &lt;NAME&gt; </code> command.</p>

<p>Replace the <code>&lt;NAME&gt;</code> value with the service instance returned from the <code>ibmcloud service list</code> command.</p>

<h4>How can I manually retrieve IAM-based credentials for an instance?</h4>

<p>Use the <code>ibmcloud resource service-key &lt;CREDENTIALS_NAME&gt;</code> command.</p>

<p>Replace the <code>&lt;CREDENTIALS_NAME&gt;</code> value with credential names returned from the <code>ibmcloud service service-keys</code> command.</p>

<h4>How can I create new service credentials?</h4>

<p>Credentials can be created through the service management page on <a href="https://console.bluemix.net">IBM Cloud</a>.</p>

<p>You can also use the CLI to create credentials using the <code>ibmcloud resource service-key-create</code> command. This command needs a name for the credentials, IAM role and service instance identifier.</p>

<h2>Example - Cloud Object Storage</h2>

<p><em>Having explained how to bind IAM-based services to IBM Cloud Functions, let's look at an example....</em></p>

<p><a href="https://console.bluemix.net/catalog/services/cloud-object-storage">Cloud Object Storage</a> is the service used to <a href="http://jamesthom.as/blog/2018/05/31/using-cloud-object-storage-from-ibm-cloud-functions-node-dot-js/">manage files for serverless applications</a> on IBM Cloud. This service supports the newer IAM-based authentication service.</p>

<p><strong>Let's look at how to bind authentication credentials for an instance of this service to an action.</strong></p>

<p>Using the CLI, we can check an instance of this service is available...</p>

<p><code>sh
$ ibmcloud resource service-instances
Retrieving service instances in resource group default..
OK
Name                     Location   State    Type               Tags
my-cos-storage           global     active   service_instance
</code></p>

<p>In this example, we have a single instance of IBM Cloud Object Storage provisioned as <code>my-cos-storage</code>.</p>

<p>Retrieving instance details will show us the service name to use in the service binding command.</p>

<p>```sh
$ ibmcloud resource service-instance my-cos-storage
Retrieving service instance my-cos-storage in resource group default..
OK</p>

<p>Name:                  my-cos-storage
ID:                    crn:v1:bluemix:public:cloud-object-storage:global:<GUID>:
GUID:                  <GUID>
Location:              global
Service Name:          cloud-object-storage
Service Plan Name:     lite
Resource Group Name:   default
State:                 active
Type:                  service_instance
Tags:
```</p>

<p>The IBM Cloud Object Storage service name is <code>cloud-object-storage</code>.</p>

<p>Before we can bind service credentials, we need to verify service credentials are available for this instance.</p>

<p><code>
$ ibmcloud resource service-keys --instance-name my-cos-storage
Retrieving service keys in resource group default...
OK
Name                     State    Created At
serverless-credentials   active   Tue Jun  5 09:11:06 UTC 2018
</code></p>

<p>This instance has a single service key available, named <code>serverless-credentials</code>.</p>

<p>Retrieving the service key details shows us the API secret for this credential.</p>

<p>```
$ ibmcloud resource service-key serverless-credentials
Retrieving service key serverless-credentials in resource group default...
OK</p>

<p>Name:          serverless-credentials
ID:            <ID>
Created At:    Tue Jun  5 09:11:06 UTC 2018
State:         active
Credentials:</p>

<pre><code>           ...
           apikey:                   &lt;SECRET_API_KEY_VALUE&gt;
</code></pre>

<p>```</p>

<p><em><code>apikey</code> denotes the secret API key used to authenticate calls to the service API.</em></p>

<p>Having retrieved the service name, instance identifier and available credentials, we can use these values to bind credentials to an action.</p>

<p><code>
$ bx wsk service bind cloud-object-storage params --instance my-cos-storage --keyname serverless-credentials
Credentials 'serverless-credentials' from 'cloud-object-storage' service instance 'my-cos-storage' bound to 'params'.
</code></p>

<p>Retrieving action details shows default parameters bound to an action. These will now include the API key for the Cloud Object Storage service.</p>

<p>```
$ bx wsk action get params
ok: got action params
{
  ...
  "parameters": [{</p>

<pre><code>"key": "__bx_creds",
"value": {
  "cloud-object-storage": {
    "apikey": "&lt;API_KEY_SECRET&gt;",
    ...
  }
}
</code></pre>

<p>  }]
}
```</p>

<p>Under the <code>__bx_creds</code> default parameter, there is a <code>cloud-object-storage</code> property with the API key amongst other service credential values.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Cloud Object Storage from IBM Cloud Functions (Node.js)]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2018/05/31/using-cloud-object-storage-from-ibm-cloud-functions-node-dot-js/"/>
    <updated>2018-05-31T10:00:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2018/05/31/using-cloud-object-storage-from-ibm-cloud-functions-node-dot-js</id>
    <content type="html"><![CDATA[<p>How do you manage files for a serverless application? ü§î</p>

<p><a href="http://jamesthom.as/blog/2018/04/27/managing-serverless-files-with-ibm-cloud-object-storage/">Previous blog posts</a> discussed this common problem and introduced the most popular solution, using a <a href="https://gigaom.com/2016/11/10/serverless-enabled-storage-its-a-big-deal/">cloud-based object storage service</a>. üëèüëèüëè</p>

<p>Object stores provide elastic storage in the cloud, with a billing model which charges for capacity used. These services are the storage solution for serverless applications, which do not have access to a traditional file system. üëç</p>

<p><strong>I'm now going to demonstrate how to use <a href="https://console.bluemix.net/catalog/services/cloud-object-storage">IBM Cloud Object Storage</a> from <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a>.</strong></p>

<p>This blog post will show you...</p>

<ul>
<li>How to provision IBM Cloud Object Storage and create authentication tokens.</li>
<li>How use client libraries to access IBM Cloud Object Storage from IBM Cloud Functions.</li>
<li>Example serverless functions for common use-cases, e.g uploading files.</li>
</ul>


<p><a href="https://github.com/jthomas/serverless-file-storage">Code examples</a> in this blog post will focus on the Node.js runtime.</p>

<p><em>Instructions on service provisioning and authentication credentials are relevant for any runtime.</em></p>

<h2>IBM Cloud Accounts and Storage Services</h2>

<p>IBM Cloud Object Storage is available to all IBM Cloud users.</p>

<p>IBM Cloud has <a href="https://console.bluemix.net/docs/account/index.html#accounts">three different account types</a>: <em>lite, pay-as-you-go</em> or <em>subscription</em>.</p>

<h3>Lite Accounts</h3>

<p><a href="https://www.ibm.com/blogs/bluemix/2017/11/introducing-ibm-cloud-lite-account/">Lite accounts</a> do not require a credit card to register and do not expire after a limited time period.</p>

<p>Numerous platform services, including Cloud Object Storage, provide <a href="https://console.bluemix.net/catalog/?search=label:lite">free resources for lite account users</a>. IBM Cloud Object Storage's free resource tier comes the <a href="https://www.ibm.com/cloud-computing/bluemix/pricing-object-storage#s3api">following monthly limits</a>.</p>

<ul>
<li><em>Store 25GB of new data.</em></li>
<li><em>Issue 20,000 GET and 2,000 PUT requests.</em></li>
<li><em>Use 10GB of public bandwidth.</em></li>
</ul>


<p><em>Lite tier usage supports all resiliency and storage class options but are limited to a single service instance.</em></p>

<p>Users can sign up for a free "Lite" account <a href="https://console.ng.bluemix.net/registration/free">here</a>. Please follow the instructions to <a href="https://console.bluemix.net/docs/cli/reference/bluemix_cli/get_started.html#getting-started">install the IBM Cloud CLI.</a></p>

<h3>Pay-as-you-Go &amp; Subscription Accounts</h3>

<p>Lite accounts can be upgraded to <a href="https://console.bluemix.net/docs/account/index.html#paygo">Pay-As-You-Go</a> or <a href="https://console.bluemix.net/docs/account/index.html#subscription-account">Subscription</a> accounts. Upgraded accounts still have access to the free tiers provided in Lite accounts. Users with Pay-As-You-Go or Subscriptions accounts can access services and tiers not included in the Lite account.</p>

<p>Benefits of the additional service tiers for IBM Cloud Object Storage include unlimited instances of the object storage service. Costs are billed according to usage per month. See the pricing page for more details: <a href="https://www.ibm.com/cloud-computing/bluemix/pricing-object-storage#s3api">https://www.ibm.com/cloud-computing/bluemix/pricing-object-storage#s3api</a></p>

<h2>Provisioning IBM Cloud Object Storage</h2>

<p>IBM Cloud Object Storage can be provisioned through the <a href="https://console.bluemix.net/catalog/">IBM Cloud service catalog</a>.</p>

<p><img src="/images/cos_storage/catalog.png"></p>

<p>From the <em><a href="https://console.bluemix.net/catalog/services/cloud-object-storage">Service Details</a></em> page, follow these instructions to provision a new instance.</p>

<ul>
<li>Give the service an identifying name.</li>
<li>Leave the resource group as "<em>default</em>".</li>
<li>Click the "Create" button.</li>
</ul>


<p>Once the service has been provisioned, it will be shown under the "Services" section of the <a href="https://console.bluemix.net/dashboard/apps">IBM Cloud Dashboard</a>. <strong>IBM Cloud Object Storage services are global services and not bound to individual regions.</strong></p>

<ul>
<li>Click the service instance from the dashboard to visit the service management page.</li>
</ul>


<p><img src="/images/cos_storage/go-to-service-instance.gif"></p>

<p><em>Once the service has been provisioned, we need to create authentication credentials for external access‚Ä¶</em></p>

<h2>Service Credentials</h2>

<p>Service credentials for IBM Cloud Object Storage use <a href="https://console.bluemix.net/docs/services/cloud-object-storage/iam/overview.html#getting-started-with-iam">IBM Cloud's IAM service</a>.</p>

<p>I'm just going to cover the basics of using IAM with Cloud Object Storage. Explaining all the <a href="https://console.bluemix.net/docs/iam/index.html#iamoverview">concepts and capabilities</a> of the IAM service would need a separate (and lengthy) blog post!</p>

<h3>Auto-Binding Service Credentials</h3>

<p>IBM Cloud Functions can <a href="https://console.bluemix.net/docs/openwhisk/binding_services.html#binding_services">automatically provision and bind service credentials</a> to actions.</p>

<p><em>This feature is supported through the IBM Cloud CLI command: <code>bx wsk service bind</code>.</em></p>

<p>Bound service credentials are stored as default action parameters. Default parameters are automatically included as request parameters for each invocation.</p>

<p><strong>Using this approach means users do not have to manually provision and manage service credentials.</strong> üëç</p>

<p><em>Service credentials provisioned in this manner use the following configuration options:</em></p>

<ul>
<li><strong>IAM Role</strong>: <em>Manager</em></li>
<li><strong>Optional Configuration Parameters</strong>: <em>None</em>.</li>
</ul>


<p>If you need to use different configuration options, you will have to manually provision service credentials.</p>

<h3>Manually Creating Credentials</h3>

<ul>
<li>Select the "<em>Service Credentials</em>" menu item from the service management page.</li>
<li>Click the "New credential" button.</li>
</ul>


<p><em>Fill in the details for the new credentials.</em></p>

<ul>
<li>Choose an identifying name for the credentials.</li>
<li><p>Select an access role. Access roles define which operations applications using these credentials can perform. Permissions for each role are <a href="https://console.bluemix.net/docs/services/cloud-object-storage/iam/buckets.html#bucket-permissions">listed in the documentation</a>.</p>

<p><em>Note: If you want to make objects publicly accessible <a href="https://stackoverflow.com/questions/50007460/ibm-cloud-object-storage-cannot-modify-object-acl-permissions">make sure you use the manager permission</a>.</em></p></li>
<li><p>Leave the <code>Service ID</code> unselected.</p></li>
</ul>


<p>If you need HMAC service keys, which are necessary for generating presigned URLs, use the following inline configuration parameters before. Otherwise, leave this field blank.</p>

<p><code>json
{"HMAC": true}
</code></p>

<ul>
<li>Click the "Add" button.</li>
</ul>


<p><img src="/images/cos_storage/provision-credentials.gif"></p>

<p>üîê <em>Credentials shown in this GIF were deleted after the demo (before you get any ideas...)</em> üîê</p>

<p>Once created, new service credentials will be shown in the credentials table.</p>

<h2>IBM Cloud Object Storage API</h2>

<p>Cloud Object Storage exposes a <a href="https://console.bluemix.net/docs/services/cloud-object-storage/api-reference/about-compatibility-api.html#about-the-ibm-cloud-object-storage-api">HTTP API</a> for interacting with buckets and files.</p>

<p>This API implements the same interface as <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html">AWS S3 API</a>.</p>

<p>Service credentials created above are used to authenticate requests to the API endpoints. Full details on the API operations are available in the <a href="https://console.bluemix.net/docs/services/cloud-object-storage/api-reference/about-compatibility-api.html#about-the-ibm-cloud-object-storage-api">documentation</a>.</p>

<h3>HTTP Endpoints</h3>

<p>IBM Cloud Object Storage's HTTP API is available through <a href="https://console.bluemix.net/docs/services/cloud-object-storage/basics/endpoints.html#select-regions-and-endpoints">region-based endpoints</a>.</p>

<p>When creating new buckets to store files, the data resiliency for the bucket (and therefore the files within it) is based upon the endpoint used for the bucket create operation.</p>

<p>Current endpoints are listed in the <a href="https://console.bluemix.net/docs/services/cloud-object-storage/basics/endpoints.html#select-regions-and-endpoints">external documentation</a> and available through an external API: <a href="https://cos-service.bluemix.net/endpoints">https://cos-service.bluemix.net/endpoints</a></p>

<h4>Choosing an endpoint</h4>

<p>IBM Cloud Functions is available in the following regions: <em>US-South, United Kingdom and Germany.</em></p>

<p>Accessing Cloud Object Storage using regional endpoints closest to the Cloud Functions application region will result in better application performance.</p>

<p>IBM Cloud Object Storage lists public and private endpoints for each region (and resiliency) choice. <strong>IBM Cloud Functions only supports access using public endpoints.</strong></p>

<p>In the following examples, IBM Cloud Functions applications will be hosted in the <code>US-South</code> region. Using the <code>US Regional</code> endpoint for Cloud Object Storage will minimise network latency when using the service from IBM Cloud Functions.</p>

<p><em>This endpoint will be used in all our examples:</em> <code>s3-api.us-geo.objectstorage.softlayer.net</code></p>

<h3>Client Libraries</h3>

<p>Rather than manually creating HTTP requests to interact with the Cloud Object Storage API, <a href="https://console.bluemix.net/docs/services/cloud-object-storage/libraries/node.html#using-node-js">client libraries</a> are available.</p>

<p>IBM Cloud Object Storage publishes modified versions of the Node.js, Python and Java AWS S3 SDKs, enhanced with IBM Cloud specific features.</p>

<ul>
<li><code>ibm-cos-sdk-js</code> - <a href="https://github.com/IBM/ibm-cos-sdk-js">https://github.com/IBM/ibm-cos-sdk-js</a></li>
<li><code>ibm-cos-sdk-python</code> - <a href="https://github.com/ibm/ibm-cos-sdk-python">https://github.com/ibm/ibm-cos-sdk-python</a></li>
<li><code>ibm-cos-sdk-java</code> - <a href="https://github.com/ibm/ibm-cos-sdk-java">https://github.com/ibm/ibm-cos-sdk-java</a></li>
</ul>


<p>Both the Node.js and Python COS libraries are pre-installed in the IBM Cloud Functions <a href="https://github.com/ibm-functions">runtime environments</a> for those languages. They can be used without bundling those dependencies in the deployment package.</p>

<p><em>We're going to look at using the JavaScript client library from the Node.js runtime in IBM Cloud Functions.</em></p>

<h4>JavaScript Client Library</h4>

<p>When using the JavaScript client library for IBM Cloud Object Storage, endpoint and authentication credentials need to be passed as configuration parameters.</p>

<p>```javascript
const COS = require('ibm-cos-sdk');</p>

<p>const config = {</p>

<pre><code>endpoint: '&lt;endpoint&gt;',
apiKeyId: '&lt;api-key&gt;',    
serviceInstanceId: '&lt;resource-instance-id&gt;',
</code></pre>

<p>};</p>

<p>const cos = new COS.S3(config);
```</p>

<p>Hardcoding configuration values within source code is not recommended. IBM Cloud Functions allows <a href="https://console.bluemix.net/docs/openwhisk/parameters.html#default-params-action">default parameters</a> to be bound to actions. Default parameters are automatically passed into action invocations within the event parameters.</p>

<p><em>Default parameters are recommended for managing application secrets for IBM Cloud Functions applications.</em></p>

<p><strong>Having provisioned the storage service instance, learnt about service credentials, chosen an access endpoint and understood how to use the client library, there's one final step before we can start to creating functions‚Ä¶</strong></p>

<h2>Creating Buckets</h2>

<p>IBM Cloud Object Storage organises files into a flat hierarchy of named containers, called buckets. Buckets can be created <a href="https://console.bluemix.net/docs/services/cloud-object-storage/cli/curl.html#add-a-bucket">through the command-line</a>, <a href="https://console.bluemix.net/docs/services/cloud-object-storage/api-reference/api-reference-buckets.html#new-bucket">using the API</a> or the web console.</p>

<p>Let's create a new bucket, to store all files for our serverless application, using the web console.</p>

<ul>
<li>Open the "<em>Buckets</em>" page from the COS management page.</li>
<li><p>Click the "<em>Create Bucket</em>" link.</p></li>
<li><p>Create a bucket name.
<em>Bucket names must be unique across the entire platform, rather than just your account.</em></p></li>
<li>Select the following configuration options

<ul>
<li><strong>Resiliency</strong>: <code>Cross Region</code></li>
<li><strong>Location</strong>: <code>us-geo</code></li>
<li><strong>Storage class</strong>: <code>Standard</code></li>
</ul>
</li>
<li>Click the "<em>Create</em>" button.</li>
</ul>


<p><img src="/images/cos_storage/creating-buckets.gif"></p>

<p><em>Once the bucket has been created, you will be taken back to the bucket management page.</em></p>

<h4>Test Files</h4>

<p>We need to put some test files in our new bucket. Download the following images files.</p>

<ul>
<li><a href="https://cdn.pixabay.com/photo/2015/06/08/15/02/pug-801826_640.jpg">Pug Blanket</a></li>
<li><a href="https://cdn.pixabay.com/photo/2016/07/07/15/35/swimming-1502563_640.jpg">Swimming Pug</a></li>
<li><a href="https://cdn.pixabay.com/photo/2017/02/28/13/11/dog-2105686_640.jpg">Jumping Pug</a></li>
</ul>


<p><strong>Using the bucket management page, upload these files to the new bucket.</strong></p>

<p><img src="/images/cos_storage/upload-files.png"></p>

<h2>Using Cloud Object Storage from Cloud Functions</h2>

<p>Having created a storage bucket containing test files, we can start to develop our <a href="https://github.com/jthomas/serverless-file-storage">serverless application</a>.</p>

<p>Let's begin with a serverless function that returns a list of files within a bucket. Once this works, we will extend the application to support retrieving, removing and uploading files to a bucket. We can also show how to make objects publicly accessible and generate pre-signed URLs, allowing external clients to upload new content directly.</p>

<p><a href="https://github.com/jthomas/serverless-file-storage">Separate IBM Cloud Functions actions</a> will be created for each storage operation.</p>

<h3>Managing Default Parameters</h3>

<p>Serverless functions will need the bucket name, service endpoint and authentication parameters to access the object storage service. Configuration parameters will be bound to actions as <a href="https://console.bluemix.net/docs/openwhisk/parameters.html#default-params-action">default parameters</a>.</p>

<p>Packages can be used to share configuration values across multiple actions. Actions created within a package inherit all <a href="https://console.bluemix.net/docs/openwhisk/parameters.html#default-params-package">default parameters stored on that package</a>. This removes the need to manually configure the same default parameters for each action.</p>

<p>Let's create a new package (<code>serverless-files</code>) for our serverless application.</p>

<p><code>sh
$ bx wsk package create serverless-files
ok: created package serverless-files
</code></p>

<p>Update the package with default parameters for the bucket name (<code>bucket</code>) and service endpoint (<code>cos_endpoint</code>).</p>

<p><code>sh
$ bx wsk package update serverless-files -p bucket &lt;MY_BUCKET_NAME&gt; -p cos_endpoint s3-api.us-geo.objectstorage.softlayer.net
ok: updated package serverless-files
</code></p>

<p><strong><em>Did you notice we didn't provide authentication credentials as default parameters?</em></strong></p>

<p>Rather than manually adding these credentials, the CLI can <a href="https://console.bluemix.net/docs/openwhisk/binding_services.html#binding_services">automatically provision and bind them</a>. Let's do this now for the <code>cloud-object-storage</code> service...</p>

<ul>
<li>Bind service credentials to the <code>serverless-files</code> package using the <code>bx wsk service bind</code> command.</li>
</ul>


<p><code>
$ bx wsk service bind cloud-object-storage serverless-files
Credentials 'cloud-fns-key' from 'cloud-object-storage' service instance 'object-storage' bound to 'serverless-files'.
</code></p>

<ul>
<li>Retrieve package details to check default parameters contain expected configuration values.</li>
</ul>


<p>```
$ bx wsk package get serverless-files
ok: got package serverless-files
{</p>

<pre><code>...    
"parameters": [
    {
        "key": "bucket",
        "value": "&lt;MY_BUCKET_NAME&gt;"
    },
    {
        "key": "cos_endpoint",
        "value": "s3-api.us-geo.objectstorage.softlayer.net"
    },
    {
        "key": "__bx_creds",
        "value": {
            "cloud-object-storage": {
                ...
            }
        }
    }
]
</code></pre>

<p>}
```</p>

<h3>List Objects Within the Bucket</h3>

<ul>
<li>Create a new file (<code>action.js</code>) with the following contents.</li>
</ul>


<p>```javascript
const COS = require('ibm-cos-sdk')</p>

<p>function cos_client (params) {
  const bx_creds = params['<strong>bx_creds']
  if (!bx_creds) throw new Error('Missing </strong>bx_creds parameter.')</p>

<p>  const cos_creds = bx_creds['cloud-object-storage']
  if (!cos_creds) throw new Error('Missing cloud-object-storage parameter.')</p>

<p>  const endpoint = params['cos_endpoint']
  if (!endpoint) throw new Error('Missing cos_endpoint parameter.')</p>

<p>  const config = {</p>

<pre><code>endpoint: endpoint,
apiKeyId: cos_creds.apikey,
serviceInstanceId: cos_creds.resource_instance_id
</code></pre>

<p>  }</p>

<p>  return new COS.S3(config);
}</p>

<p>function list (params) {
  if (!params.bucket) throw new Error("Missing bucket parameter.")
  const client = cos_client(params)</p>

<p>  return client.listObjects({ Bucket: params.bucket }).promise()</p>

<pre><code>.then(results =&gt; ({ files: results.Contents }))
</code></pre>

<p>}
```</p>

<p>This action retrieves the bucket name, service endpoint and authentication credentials from invocation parameters. Errors are returned if those parameters are missing.</p>

<ul>
<li>Create a new package action from this source file with the following command.</li>
</ul>


<p><code>
$ bx wsk action create serverless-files/list-files actions.js --main list --kind nodejs:8
ok: created action list-files
</code></p>

<p><em>The <code>‚Äîmain</code> flag set the function name to call for each invocation. This defaults to <code>main</code>. Setting this to an explicit value allows us to use a single source file for multiple actions.</em></p>

<p><em>The <code>‚Äîkind</code> sets the action runtime. This optional flag ensures we use the <a href="https://github.com/ibm-functions/runtime-nodejs">Node.js 8 runtime</a> rather than <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/tree/master/core/nodejs6Action">Node.js 6</a>, which is the default for JavaScript actions. The IBM Cloud Object Storage client library is only included in the <a href="https://github.com/ibm-functions/runtime-nodejs">Node.js 8 runtime</a>.</em></p>

<ul>
<li>Invoke the new action to verify it works.</li>
</ul>


<p>```
$ bx wsk action invoke serverless-files/list-files -r
{</p>

<pre><code>"files": [
    { "Key": "jumping pug.jpg", ... },
    { "Key": "pug blanket.jpg", ... },
    { "Key": "swimming pug.jpg", ... }
]
</code></pre>

<p>}
```</p>

<p>The action response should contain a list of the files uploaded before. üíØüíØüíØ</p>

<h3>Retrieve Object Contents From Bucket</h3>

<p>Let's add another action for retrieving object contents from a bucket.</p>

<ul>
<li>Add a new function (<code>retrieve</code>) to the existing source file (<code>action.js</code>) with the following source code.</li>
</ul>


<p>```javascript
function retrieve (params) {
  if (!params.bucket) throw new Error("Missing bucket parameter.")
  if (!params.name) throw new Error("Missing name parameter.")
  const client = cos_client(params)</p>

<p>  return client.getObject({ Bucket: params.bucket, Key: params.name }).promise()</p>

<pre><code>.then(result =&gt; ({ body: result.Body.toString('base64') }))
</code></pre>

<p>}
```</p>

<p>Retrieving files needs a file name in addition to the bucket name. File contents <a href="https://stackoverflow.com/questions/47653181/return-binary-http-response-from-openwhisk-ibm-cloud-function-action">needs encoding as a Base64 string</a> to support returning in the JSON response returned by IBM Cloud Functions.</p>

<ul>
<li>Create an additional action from this updated source file with the following command.</li>
</ul>


<p><code>
$ bx wsk action create serverless-files/retrieve-file actions.js --main retrieve --kind nodejs:8
ok: created action serverless-files/retrieve-file
</code></p>

<ul>
<li>Invoke this action to test it works, passing the parameter name for the file to retrieve.</li>
</ul>


<p>```
$ bx wsk action invoke serverless-files/retrieve-file -r -p name "jumping pug.jpg"
{</p>

<pre><code>"body": "&lt;BASE64 ENCODED STRING&gt;"
</code></pre>

<p>}
```</p>

<p>If this is successful, a (very long) response body containing a base64 encoded image should be returned. üëç</p>

<h3>Delete Objects From Bucket</h3>

<p>Let's finish this section by adding a final action that removes objects from our bucket.</p>

<ul>
<li>Update the source file (<code>actions.js</code>) with this additional function.</li>
</ul>


<p>```javascript
function remove (params) {
  if (!params.bucket) throw new Error("Missing bucket parameter.")
  if (!params.name) throw new Error("Missing name parameter.")
  const client = cos_client(params)</p>

<p>  return client.deleteObject({ Bucket: params.bucket, Key: params.name }).promise()
}
```</p>

<ul>
<li>Create a new action (<code>remove-file</code>) from the updated source file.</li>
</ul>


<p><code>
$ bx wsk action create serverless-files/remove-file actions.js --main remove --kind nodejs:8
ok: created action serverless-files/remove-file
</code></p>

<ul>
<li>Test this new action using it to remove a file from the bucket.</li>
</ul>


<p><code>
$ bx wsk action invoke serverless-files/remove-file -r -p name "jumping pug.jpg"
{}
</code></p>

<ul>
<li>Listing bucket files should now return two files, rather than three.</li>
</ul>


<p>```
$ bx wsk action invoke serverless-files/list-files -r
{</p>

<pre><code>"files": [
    { "Key": "pug blanket.jpg", ... },
    { "Key": "swimming pug.jpg", ... }
]
</code></pre>

<p>}
```</p>

<p>Listing, retrieving and removing files using the client library is relatively simple. Functions just need to call the correct method passing the bucket and object name.</p>

<p><em>Let's move onto a more advanced example, creating new files in the bucket from our action‚Ä¶</em></p>

<h3>Create New Objects Within Bucket</h3>

<p>File content will be passed into our action as Base64 encoded strings. JSON does not support binary data.</p>

<p>When creating new objects, we should <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/RESTCommonRequestHeaders.html">set the MIME type</a>. This is necessary for public access from web browsers, something we'll be doing later on. <a href="https://www.npmjs.com/package/mime-types">Node.js libraries</a> can calculate the correct MIME type value, rather than requiring this as an invocation parameter.</p>

<ul>
<li>Update the source file (<code>action.js</code>) with the following additional code.</li>
</ul>


<p>```javascript
const mime = require('mime-types');</p>

<p>function upload (params) {
  if (!params.bucket) throw new Error("Missing bucket parameter.")
  if (!params.name) throw new Error("Missing name parameter.")
  if (!params.body) throw new Error("Missing object parameter.")</p>

<p>  const client = cos_client(params)
  const body = Buffer.from(params.body, 'base64')</p>

<p>  const ContentType = mime.contentType(params.name) || 'application/octet-stream'
  const object = {</p>

<pre><code>Bucket: params.bucket,
Key: params.name,
Body: body,
ContentType
</code></pre>

<p>  }</p>

<p>  return client.upload(object).promise()
}</p>

<p>exports.upload = upload;
```</p>

<p><strong>As this code uses an external NPM library, we need to create the action from a zip file containing source files and external dependencies.</strong></p>

<ul>
<li>Create a <code>package.json</code> file with the following contents.</li>
</ul>


<p>```json
{
  "name": "upload-files",
  "main": "actions.js",
  "dependencies": {</p>

<pre><code>"mime-types": "^2.1.18"
</code></pre>

<p>  }
}
```</p>

<ul>
<li>Install external libraries in local environment.</li>
</ul>


<p><code>sh
$ npm install
added 2 packages in 0.804s
</code></p>

<ul>
<li>Bundle source file and dependencies into zip file.</li>
</ul>


<p><code>bash
$ zip -r upload.zip package.json actions.js node_modules
  adding: actions.js (deflated 72%)
  adding: node_modules/ (stored 0%)
  ...
</code></p>

<ul>
<li>Create a new action from the zip file.</li>
</ul>


<p><code>
$ bx wsk action create serverless-files/upload-file upload.zip --main upload --kind nodejs:8
ok: created action serverless-files/upload-file
</code></p>

<ul>
<li>Create the Base64-encoded string used to pass the new file's content.</li>
</ul>


<p><code>
$ wget http://www.pugnow.com/wp-content/uploads/2016/04/fly-pug-300x300.jpg
$ base64 fly-pug-300x300.jpg &gt; body.txt
</code></p>

<ul>
<li>Invoke the action with the file name and content as parameters.</li>
</ul>


<p><code>
$ bx wsk action invoke serverless-files/upload-file -r -p body $(cat body.txt) -p name "flying pug.jpg"
</code></p>

<p>Object details should be returned if the file was uploaded correctly.</p>

<p>```json
{</p>

<pre><code>"Bucket": "my-serverless-files",
"ETag": "\"b2ae0fb61dc827c03d6920dfae58e2ba\"",
"Key": "flying pug.jpg",
"Location": "https://&lt;MY_BUCKET_NAME&gt;.s3-api.us-geo.objectstorage.softlayer.net/flying%20pug.jpg",
"key": "flying pug.jpg"
</code></pre>

<p>}
```</p>

<p>Accessing the <a href="https://console.bluemix.net/objectstorage/">object storage dashboard</a> shows the new object in the bucket, with the correct file name and size.</p>

<p><img src="/images/cos_storage/upload-file-display.png"></p>

<p><em>Having actions to create, delete and access objects within a bucket, what's left to do?</em> ü§î</p>

<h3>Expose Public Objects From Buckets</h3>

<p>Users can also choose to make certain <a href="https://console.bluemix.net/docs/services/cloud-object-storage/iam/public-access.html#allowing-public-access">objects within a bucket public</a>. Public objects can be retrieved, using the external HTTP API, without any further authentication.</p>

<p>Public file access allows external clients to access files directly. It removes the need to invoke (and pay for) a serverless function to serve content. This is useful for serving static assets and media files.</p>

<p>Objects have an explicit property (<code>x-amz-acl</code>) which controls access rights. Files default to having this value set as <code>private</code>, meaning all operations require authentication. Setting this value to <code>public-read</code> will enable <code>GET</code> operations without authentication.</p>

<p><strong><em>Files can be created with an explicit ACL property using credentials with the <code>Writer</code> or <code>Manager</code> role. Modifying ACL values for existing files is only supported using credentials with the <code>Manager</code> role.</em></strong></p>

<ul>
<li>Add the following source code to the existing actions file (<code>action.js</code>).</li>
</ul>


<p>```javascript
function make_public (params) {
  return update_acl(params, 'public-read')
}</p>

<p>function make_private (params) {
  return update_acl(params, 'private')
}</p>

<p>function update_acl (params, acl) => {
  if (!params.bucket) throw new Error("Missing bucket parameter.")
  if (!params.name) throw new Error("Missing name parameter.")
  const client = cos_client(params)</p>

<p>  const options = {</p>

<pre><code>Bucket: params.bucket,
Key: params.name,
ACL: acl
</code></pre>

<p>  }</p>

<p>  return client.putObjectAcl(options).promise()
}
```</p>

<ul>
<li>Create two new actions with the update source file.</li>
</ul>


<p><code>sh
$ bx wsk action create serverless-files/make-public actions.js --main make_public --kind nodejs:8
ok: created action serverless-files/make-public
$ bx wsk action create serverless-files/make-private actions.js --main make_private --kind nodejs:8
ok: created action serverless-files/make-private
</code></p>

<p><em>Bucket objects use the following URL scheme</em>: <em>https://<BUCKET_NAME>.<ENDPOINT_HOST>/<OBJECT_NAME></em></p>

<p>We have been using the following endpoint hostname:  <code>s3-api.us-geo.objectstorage.softlayer.net</code>.</p>

<ul>
<li>Checking the status code returned when accessing an existing object confirms it defaults to private.</li>
</ul>


<p><code>bash
$ curl -I https://&lt;BUCKET_NAME&gt;.s3-api.us-geo.objectstorage.softlayer.net/flying%20pug.jpg
HTTP/1.1 403 Forbidden
...
</code></p>

<ul>
<li>Invoke the <code>make-public</code> action to allow GET requests without authentication.</li>
</ul>


<p><code>
$ bx wsk action invoke serverless-files/make-public -r -p name "flying pug.jpg"
</code></p>

<ul>
<li>Retry file access using the external HTTP API. This time a <code>200</code> response is returned with the content.</li>
</ul>


<p><code>
$ curl -I https://&lt;BUCKET_NAME&gt;.s3-api.us-geo.objectstorage.softlayer.net/flying%20pug.jpg
HTTP/1.1 200 OK
Content-Type: image/jpeg
...
</code></p>

<p>Having set an explicit content type for the file, opening this URL in a web browser will show the image.</p>

<p><img src="http://www.pugnow.com/wp-content/uploads/2016/04/fly-pug-300x300.jpg"></p>

<ul>
<li>Disable public access using the other new action.</li>
</ul>


<p><code>
bx wsk action invoke serverless-files/make-private -r -p name "flying pug.jpg"
</code></p>

<ul>
<li>Re-issue the <code>curl</code> request to the file location.</li>
</ul>


<p><code>
$ curl -I https://&lt;BUCKET_NAME&gt;.s3-api.us-geo.objectstorage.softlayer.net/flying%20pug.jpg
HTTP/1.1 403 Forbidden
...
</code></p>

<p>HTTP requests to this file now return a <code>403</code> status. Authentication is required again. üîë</p>

<p><em>In addition to allowing public read access we can go even further in allowing clients to interact with buckets‚Ä¶</em></p>

<h3>Provide Direct Upload Access To Buckets</h3>

<p>Cloud Object Storage provides a mechanism (<a href="https://console.bluemix.net/docs/services/cloud-object-storage/hmac/presigned-urls.html#create-a-presigned-url"><em>presigned URLs</em></a>) to generate temporary links that allow clients to interact with buckets without further authentication. Passing these links to clients means they can access to private objects or upload new files to buckets. Presigned URLs expire after a configurable time period.</p>

<p><strong>Generating presigned URLs is only supported from <a href="https://console.bluemix.net/docs/services/cloud-object-storage/hmac/credentials.html#using-hmac-credentials">HMAC authentication keys</a>.</strong></p>

<p>HMAC service credentials must be manually provisioned, rather than using the <code>bx wsk service bind</code> command. See above for instructions on how to do this.</p>

<ul>
<li>Save provisioned HMAC keys into a file called <code>credentials.json</code>.</li>
</ul>


<p>Let's create an action that returns presigned URLs, allowing users to upload files directly. Users will call the action with a new file name. Returned URLs will support an unauthenticated PUT request for the next five minutes.</p>

<ul>
<li>Create a new file called <code>presign.js</code></li>
</ul>


<p>```javascript
'use strict';</p>

<p>const COS = require('ibm-cos-sdk');
const mime = require('mime-types');</p>

<p>function cos_client (params) {
  const creds = params.cos_hmac_keys
  if (!creds) throw new Error('Missing cos_hmac_keys parameter.')</p>

<p>  const endpoint = params.cos_endpoint
  if (!endpoint) throw new Error('Missing cos_endpoint parameter.')</p>

<p>  const config = {</p>

<pre><code>endpoint: endpoint,
accessKeyId: creds.access_key_id, 
secretAccessKey: creds.secret_access_key
</code></pre>

<p>  }</p>

<p>  return new COS.S3(config);
}</p>

<p>function presign (params) {
  if (!params.bucket) throw new Error("Missing bucket parameter.")
  if (!params.name) throw new Error("Missing name parameter.")</p>

<p>  const client = cos_client(params)</p>

<p>  const options = {</p>

<pre><code>Bucket: params.bucket,
Key: params.name,
Expires: 300,
ContentType: mime.contentType(params.name) || 'application/octet-stream'
</code></pre>

<p>  }</p>

<p>  return { url: client.getSignedUrl('putObject', options) }
}</p>

<p>exports.presign = presign;
```</p>

<ul>
<li>Update the <code>package.json</code> file with the following contents.</li>
</ul>


<p>```json
{
  "name": "presign",
  "main": "presign.js",
  "dependencies": {</p>

<pre><code>"mime-types": "^2.1.18"
</code></pre>

<p>  }
}
```</p>

<ul>
<li>Bundle source file and dependencies into zip file.</li>
</ul>


<p><code>sh
$ zip -r presign.zip package.json presign.js node_modules
  adding: actions.js (deflated 72%)
  adding: node_modules/ (stored 0%)
  ...
</code></p>

<ul>
<li>Create a new action from the zip file.</li>
</ul>


<p><code>sh
$ bx wsk action create serverless-files/presign presign.zip --main presign --kind nodejs:8 -P credentials.json
ok: created action serverless-files/presign
</code></p>

<ul>
<li>Invoke the action to return a presigned URL for a new file.</li>
</ul>


<p>```
$ bx wsk action invoke serverless-files/presign -r -p name pug.jpg
{</p>

<pre><code>"url": "https://&lt;BUCKET&gt;.s3-api.us-geo.objectstorage.softlayer.net/pug.jpg?AWSAccessKeyId=&lt;SECRET&gt;&amp;Content-Type=image%2Fjpeg&amp;Expires=&lt;TIME&gt;&amp;Signature=&lt;KEY&gt;"
</code></pre>

<p>}
```</p>

<p>Using this URL we can upload a new image without providing authentication credentials.</p>

<ul>
<li>This curl command <code>‚Äîupload-file</code> will send a HTTP PUT, with image file as request body, to that URL.</li>
</ul>


<p><code>
$ curl --upload-file "my pug.jpg" &lt;URL&gt; --header "Content-Type: image/jpeg"
</code></p>

<p><em>The HTTP request must include the correct "Content-Type" header. Use the value provided when creating the presigned URL. If these values do not match, the request will be rejected.</em></p>

<p>Exploring the objects in our bucket confirms we have uploaded a file! üï∫üíÉ</p>

<p><img src="/images/cos_storage/uploaded-my-pug.png"></p>

<p>Presigned URLs are a brilliant feature of Cloud Object Storage. Allowing users to upload files directly overcomes the payload limit for cloud functions. It also reduces the cost for uploading files, removing the cloud functions' invocation cost.</p>

<h2>conclusion</h2>

<p>Object storage services are the solution for managing files with serverless applications.</p>

<p>IBM Cloud provides both a serverless runtime (<a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a>) and an object storage service (<a href="https://console.bluemix.net/catalog/services/cloud-object-storage">IBM Cloud Object Store</a>). In this blog post, we looked at how integrate these services to provide a file storage solution for serverless applications.</p>

<p>We showed you how to provision new COS services, create and manage authentication credentials, access files using a client library and even allow external clients to interact directly with buckets. Sample serverless functions using the Node.js runtime were also provided.</p>

<p><em>Do you have any questions, comments or issues about the content above? Please leave a comment below, find me on the <a href="http://openwhisk.incubator.apache.org/slack.html">openwhisk slack</a> or send me a <a href="https://twitter.com/thomasj">tweet</a>.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[File Storage For Serverless Applications]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2018/04/27/managing-serverless-files-with-ibm-cloud-object-storage/"/>
    <updated>2018-04-27T14:27:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2018/04/27/managing-serverless-files-with-ibm-cloud-object-storage</id>
    <content type="html"><![CDATA[<blockquote><p><strong><em>"Where do you store files without a server?"</em></strong></p></blockquote>

<p>‚Ä¶is the most common question I get asked during Q&amp;A after one of my "<a href="http://bit.ly/james_thomas">Introduction to Serverless Platforms</a>" conference talks. Searching for this question online, <a href="https://gigaom.com/2016/11/10/serverless-enabled-storage-its-a-big-deal/">this is the answer</a> you will often find.</p>

<blockquote><p> <strong><em>"Use an object store for file storage and access using the S3-compatible interface. Provide direct access to files by making buckets public and return pre-signed URLs for uploading content. Easy, right?"</em></strong></p></blockquote>

<p>Responding to people with this information often leads to the following response:</p>

<p>ü§îü§îü§î</p>

<p>Developers who are not familiar with cloud platforms, can often understand the benefits and concepts behind serverless, but don't know the other cloud services needed to replicate application services from traditional (or server-full) architectures.</p>

<p><strong>In this blog post, I want to explain why we do not use the file system for files in serverless applications and introduce the cloud services used to handle this.</strong></p>

<h2>serverless runtime file systems</h2>

<p>Serverless runtimes do provide access to a filesystem with a (small) amount of ephemeral storage.</p>

<p>Serverless application <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md#packaging-an-action-as-a-nodejs-module">deployment packages</a> are extracted into this filesystem prior to execution. Uploading files into the environment relies on them being included within the application package. Serverless functions can read, modify and create files within this local file system.</p>

<p>These temporary file systems come with the following restrictions‚Ä¶</p>

<ul>
<li><a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/reference.md#per-action-artifact-mb-fixed-48mb">Maximum application package size</a> limits additional files that can be uploaded.</li>
<li>Serverless platforms usually limit total usable space to around 512MB.</li>
<li>Modifications to the file system are lost once the environment is <a href="https://hackernoon.com/im-afraid-you-re-thinking-about-aws-lambda-cold-starts-all-wrong-7d907f278a4f">not used for further invocations</a>.</li>
<li>Concurrent executions of the same function use independent runtime environments and do not share filesystem storage.</li>
<li>There is no access to these temporary file systems outside the runtime environment.</li>
</ul>


<p><em>All these limitations make the file system provided by serverless platforms unsuitable as a scalable storage solution for serverless applications.</em></p>

<p><strong><em>So, what is the alternative?</em></strong></p>

<h2>object stores</h2>

<blockquote><p>Object stores manage data as objects, as opposed to other storage architectures like <a href="https://en.wikipedia.org/wiki/File_systems">file systems</a> which manage data as a file hierarchy. Object-storage systems allow retention of massive amounts of <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured data</a>, with simple retrieval and search capabilities.</p>

<p><a href="https://en.wikipedia.org/wiki/Object_storage"><em>https://en.wikipedia.org/wiki/Object_storage</em></a></p></blockquote>

<p>Object stores provide "storage-as-a-service" solutions for cloud applications.</p>

<p><strong>These services are used for file storage within serverless applications.</strong></p>

<p>Unlike traditional block storage devices, data objects in object storage services are organised using flat hierarchies of containers, known as "<em>buckets</em>". Objects within buckets are identified by unique identifiers, known as "<em>keys</em>". Metadata can also be stored alongside data objects for additional context.</p>

<p>Object stores provide simple access to files by applications, rather than users.</p>

<h2>advantages of an object store</h2>

<h3>scalable and elastic storage</h3>

<p>Rather than having a disk drive, with a fixed amount of storage, object stores provide scalable and elastic storage for data objects. Users are <a href="https://www.ibm.com/cloud-computing/bluemix/pricing-object-storage">charged</a> based upon the amount of data stored, API requests and bandwidth used. Object stores are built to scale as storage needs grow towards the <a href="https://www.ibm.com/cloud/object-storage/faq">petabyte range</a>.</p>

<h3>simple http access</h3>

<p>Object stores provide a <a href="https://console.bluemix.net/docs/services/cloud-object-storage/api-reference/about-compatibility-api.html#about-the-ibm-cloud-object-storage-api">HTTP-based API endpoint</a> to interact with the data objects.</p>

<p>Rather than using a standard library methods to access the file system, which translates into system calls to the operating system, files are available over a standard HTTP endpoint.</p>

<p><a href="https://console.bluemix.net/docs/services/cloud-object-storage/libraries/node.html#using-node-js">Client libraries</a> provide a simple interface for interacting with the remote endpoints.</p>

<h3>expose direct access to files</h3>

<p>Files stored in object storage can be made <a href="https://console.bluemix.net/docs/services/cloud-object-storage/iam/public-access.html#allowing-public-access">publicly accessible</a>. Client applications can access files directly without needing to use an application backend as a proxy.</p>

<p>Special URLs can also be generated to provide <a href="https://console.bluemix.net/docs/services/cloud-object-storage/hmac/presigned-urls.html#create-a-presigned-url">temporary access to files</a> for external clients. Clients can even use these URLs to directly upload and modify files. URLs are set to expire after a fixed amount of time.</p>

<h2>ibm cloud object storage</h2>

<p><a href="https://bluemix.net/">IBM Cloud</a> provides an object storage service called <a href="https://console.bluemix.net/docs/services/cloud-object-storage/about-cos.html">IBM Cloud Object Storage</a>. This service provides the following features concerning resiliency, reliability and cost.</p>

<h3>data resiliency</h3>

<p>Buckets' contents can be stored with the following automatic <a href="https://console.bluemix.net/docs/services/cloud-object-storage/basics/endpoints.html#select-regions-and-endpoints">data resiliency choices</a>.</p>

<ul>
<li><strong><em>Cross Region.</em></strong> Store data across three regions within a geographic area.</li>
<li><strong><em>Regional.</em></strong> Store data in multiple data centres within a single geographic region.</li>
<li><strong><em>Single Data Centre.</em></strong> Store data across multiple devices in a single data centre.</li>
</ul>


<p>Cross Region is the best choice for "<em>regional concurrent access and highest availability</em>". Regional is used for <em>"high availability and performance"</em>. Single Data Centre is appropriate when <em>"when data locality matters most".</em></p>

<h3>storage classes</h3>

<p>Data access patterns can be used to save costs by choosing the appropriate <a href="https://console.bluemix.net/docs/services/cloud-object-storage/basics/classes.html#use-storage-classes">storage class for data storage</a>.</p>

<p>IBM Cloud Object Storage offers the following storage classes: <strong><em>Standard, Vault, Cold Vault, Flex.</em></strong></p>

<p><em>Standard class</em> is used for workloads with frequent data access. <em>Vault and Cold Vault</em> are used with infrequent data retrieval and data archiving workloads. <em>Flex</em> is a mixed storage class for workloads where access patterns are more difficult to predict.</p>

<h3>costs</h3>

<p>Storage class and data resiliency options are used to <a href="https://www.ibm.com/cloud-computing/bluemix/pricing-object-storage#s3api">calculate the cost of service usage</a>.</p>

<p>Storage is charged based upon the amount of data storage used, operational requests (GET, POST, PUT‚Ä¶) and outgoing public bandwidth.</p>

<p>Storage classes affect the price of data retrieval operations and storage costs. Storage classes used for archiving, e.g. <em>cold vault</em>, charge less for data storage and more for operational requests. Storage classes used for frequency access, e.g. <em>standard</em>, charge more for data storage and less for operational requests.</p>

<p>Higher resiliency data storage is more expensive than lower resiliency storage.</p>

<h3>lite plan</h3>

<p>IBM Cloud Object Storage provides a generous free tier (<em>25GB storage per month, 5GB public bandwidth</em>) for Lite account users. <a href="https://www.ibm.com/cloud/lite-account">IBM Cloud Lite accounts</a> provide perpetual access to a free set of IBM Cloud resources. Lite accounts do not expire after a time period or need a credit card to sign up.</p>

<h2>conclusion</h2>

<p>Serving files from serverless runtimes is often accomplished using object storage services.</p>

<p>Object stores provide a scalable and cost-effective service for managing files without using storage infrastructure directly. Storing files in an object store provides simple access from serverless runtimes and even allows the files to be made directly accessible to end users.</p>

<p>In the next blog posts, I'm going to show you how to set up IBM Cloud Object Storage and access files from serverless applications on IBM Cloud Functions. I'll be demonstrating this approach for both the Node.js and Swift runtimes.</p>
]]></content>
  </entry>
  
</feed>
