<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: openwhisk | James Thomas]]></title>
  <link href="http://jamesthom.as/blog/categories/openwhisk/atom.xml" rel="self"/>
  <link href="http://jamesthom.as/"/>
  <updated>2019-04-15T11:53:59+01:00</updated>
  <id>http://jamesthom.as/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Automating Apache OpenWhisk Releases With Serverless]]></title>
    <link href="http://jamesthom.as/blog/2019/04/10/automating-apache-openwhisk-releases-with-serverless/"/>
    <updated>2019-04-10T15:00:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/04/10/automating-apache-openwhisk-releases-with-serverless</id>
    <content type="html"><![CDATA[<p>This blog post explains how I used <a href="https://github.com/jthomas/openwhisk-release-verification">serverless functions</a> to automate <a href="https://cwiki.apache.org/confluence/display/OPENWHISK/How+to+verify+the+release+checklist+and+vote+on+OpenWhisk+modules+under+Apache">release candidate verification</a> for the <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> project.</p>

<p><img src="https://raw.githubusercontent.com/jthomas/openwhisk-release-verification/master/release-verification-tool.gif" alt="Apache OpenWhisk Release Verification Tool" /></p>

<p><em>Automating this process has the following benefits...</em></p>

<ul>
<li><strong>Removes the chance of human errors compared to the previously manual validation process.</strong></li>
<li><strong>Allows me to validate new releases without access to my dev machine.</strong></li>
<li><strong>Usable by all committers by hosting as an <a href="http://apache.jamesthom.as/">external serverless web app</a>.</strong></li>
</ul>


<p>Automating release candidate validation makes it easier for project committers to participate in release voting. This should make it faster to get necessary release votes, allowing us to ship new versions sooner!</p>

<h2>background</h2>

<h3>apache software foundation</h3>

<p>The <a href="http://www.apache.org/">Apache Software Foundation</a> has a well-established <a href="https://www.apache.org/dev/release-publishing.html">release process</a> for delivering new product releases from projects belonging to the foundation. According to their <a href="https://www.apache.org/dev/release-publishing.html#goal">documentation</a>...</p>

<blockquote><p>An Apache release is a set of valid &amp; signed artifacts, voted on by the appropriate PMC and distributed on the ASF's official release infrastructure.</p>

<p>https://www.apache.org/dev/release-publishing.html</p></blockquote>

<p>Releasing a new software version requires the release manager to create a release candidate from the  project source files. Source archives must be cryptographically <a href="http://www.apache.org/legal/release-policy.html#release-signing">signed</a> by the release manager. All source archives for the release must be comply with <a href="http://www.apache.org/legal/release-policy.html">strict criteria</a> to be considered valid release candidates. This includes (but is not limited to) the following requirements:</p>

<ul>
<li><em>Checksums and PGP signatures for source archives are valid.</em></li>
<li><em>LICENSE, NOTICE and DISCLAIMER files included and correct.</em></li>
<li><em>All source files have license headers.</em></li>
<li><em>No compiled archives bundled in source archives.</em></li>
</ul>


<p>Release candidates can then be proposed on the project mailing list for review by members of the <a href="https://apache.org/dev/pmc.html">Project Management Committee</a> (PMC). PMC members are <a href="http://www.apache.org/legal/release-policy.html#release-approval">eligible to vote</a> on all release candidates. Before casting their votes, PMC members are required to check release candidate meets the requirements above.</p>

<p><strong>If a minimum of three positive votes is cast (with more positive than negative votes), the release passes!</strong> The release manager can then move the release candidate archives to the release <a href="https://dist.apache.org/repos/dist/release/incubator/openwhisk/">directory</a>.</p>

<h3>apache openwhisk releases</h3>

<p>As a committer and PMC member on the Apache OpenWhisk project, I'm eligible to vote on new releases.</p>

<p>Apache OpenWhisk (currently) has 52 separate <a href="https://github.com/apache?q=openwhisk">source repositories</a> under the project on GitHub. With a fast-moving open-source project, new releases candidate are constantly <a href="https://lists.apache.org/list.html?dev@openwhisk.apache.org:lte=3y:%5BVOTE%5D">being proposed</a>, which all require the necessary number of binding PMC votes to pass.</p>

<p>Manually validating release candidates can be a time-consuming process. This can make it challenging to get a quorum of binding votes from PMC members for the release to pass. I started thinking how I could improve my productivity around the validation process, enabling me to participate in more votes.</p>

<p><strong>Would it be possible to automate some (or all) of the steps in release candidate verification? Could we even use a serverless application to do this?</strong></p>

<h1>apache openwhisk release verifier</h1>

<p><strong>Spoiler Alert: YES! I ended up building a serverless application to do this for me.</strong></p>

<p>It is available at <a href="https://apache.jamesthom.as/">https://apache.jamesthom.as/</a></p>

<p><img src="/images/ow_release_verifier/overview.png" alt="Apache OpenWhisk Release Verifier" /></p>

<p>Source code for this project is available <a href="https://github.com/jthomas/openwhisk-release-verification">here</a>.</p>

<p><a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a> is used to run the serverless backend for the web application. This means Apache OpenWhisk is being used to validate future releases of itself‚Ä¶ which is awesome.</p>

<h2>architecture</h2>

<p><img src="/images/ow_release_verifier/architecture.png" alt="Project Architecture" /></p>

<p>HTML, JS and CSS files are served by Github Pages from the <a href="https://github.com/jthomas/openwhisk-release-verification">project repository</a>.</p>

<p>Backend APIs are Apache OpenWhisk actions running on <a href="http://cloud.ibm.com/openwhisk">IBM Cloud Functions</a>.</p>

<p>Both the front-page and API are served from a custom sub-domains of my <a href="http://jamesthom.as/">personal domain</a>.</p>

<h3>available release candidates</h3>

<p>When the user loads the page, the drop-down list needs to contain the current list of release candidates from the ASF development <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/">distribution site</a>.</p>

<p>This information is available to the web page via the <a href="https://apache-api.jamesthom.as/api/versions">https://apache-api.jamesthom.as/api/versions</a> endpoint. The <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/">serverless function</a> powering this API parses that <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/">live HTML page</a> (extracting the current list of release candidates) each time it is invoked.</p>

<p>```sh
$ http get https://apache-api.jamesthom.as/api/versions
HTTP/1.1 200 OK
...
{</p>

<pre><code>"versions": [
    "apache-openwhisk-0.11.0-incubating-rc1",
    "apache-openwhisk-0.11.0-incubating-rc2",
    "apache-openwhisk-1.13.0-incubating-rc1",
    "apache-openwhisk-1.13.0-incubating-rc2",
    "apache-openwhisk-2.0.0-incubating-rc2",
    "apache-openwhisk-3.19.0-incubating-rc1"
]
</code></pre>

<p>}
```</p>

<h3>release candidate version info</h3>

<p>Release candidates may have <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/apache-openwhisk-2.0.0-incubating-rc2/">multiple source archives</a> being distributed in that release. Validation steps need to be executed for each of those archives within the release candidate.</p>

<p>Once a user has selected a release candidate version, source archives to validate are shown in the table. This data is available from the <a href="https://apache-api.jamesthom.as/api/versions/VERSION">https://apache-api.jamesthom.as/api/versions/VERSION</a> endpoint. This information is parsed from the <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/apache-openwhisk-2.0.0-incubating-rc2/">HTML page</a> on the ASF site.</p>

<p>```sh
$ http get https://apache-api.jamesthom.as/api/versions/apache-openwhisk-2.0.0-incubating-rc2
HTTP/1.1 200 OK
...</p>

<p>{</p>

<pre><code>"files": [
    "openwhisk-package-alarms-2.0.0-incubating-sources.tar.gz",
    "openwhisk-package-cloudant-2.0.0-incubating-sources.tar.gz",
    "openwhisk-package-kafka-2.0.0-incubating-sources.tar.gz"
]
</code></pre>

<p>}
```</p>

<h3>release verification</h3>

<p>Having selected a release candidate version, clicking the "<em>Validate</em>" button will start validation process. Triggering the <a href="https://apache-api.jamesthom.as/api/versions/VERSION/validate">https://apache-api.jamesthom.as/api/versions/VERSION/validate</a> endpoint will run the <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/index.js#L47-L64">serverless function</a> used to execute the validation steps.</p>

<p><em>This serverless function will carry out the following verification steps...</em></p>

<h4>checking download links</h4>

<p>All the source archives for a release candidate are downloaded to temporary storage in the runtime environment. The function also downloads the associated SHA512 and PGP signature files for comparison. Multiple readable streams can be created from the same file path to allow the verification steps to happen in parallel, rather than having to re-download the archive for each task.</p>

<h4>checking SHA512 hash values</h4>

<p>SHA512 sums are distributed in a text file containing hex strings with the hash value.</p>

<p><code>sh
openwhisk-package-alarms-2.0.0-incubating-sources.tar.gz:
3BF87306 D424955B B1B2813C 204CC086 6D27FA11 075F0B30 75F67782 5A0198F8 091E7D07
 B7357A54 A72B2552 E9F8D097 50090E9F A0C7DBD1 D4424B05 B59EE44E
</code></p>

<p>The serverless function needs to dynamically compute the hash for the source archive and compare the hex bytes against the text file contents. Node.js comes with a <a href="https://nodejs.org/docs/latest-v10.x/api/crypto.html">built-in crypto library</a> making it easy to create hash values from input streams.</p>

<p><em>This is the <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/lib/verify.js#L18-L35">function</a> used to compute and compare the hash values.</em></p>

<p>```javascript
const hash = async (file_stream, hash_file, name) => {
  return new Promise((resolve, reject) => {</p>

<pre><code>const sha512 = parse_hash_from_file(hash_file)

const hmac = crypto.createHash('sha512')
file_stream.pipe(hmac)

hmac.on('readable', () =&gt; {
  const stream_hash = hmac.read().toString('hex')
  const valid = stream_hash === sha512.signature
  logger.log(`file (${name}) calculated hash: ${stream_hash}`)
  logger.log(`file (${name}) hash from file:  ${sha512.signature}`)
  resolve({valid})
})

hmac.on('error', err =&gt; reject(err))
</code></pre>

<p>  })
}
```</p>

<h4>validating PGP signatures</h4>

<p><strong>Node.js' crypto library does not support validating PGP signatures.</strong></p>

<p>I've used the <a href="https://www.npmjs.com/package/openpgp">OpenPGP.js library</a> to handle this task. This is a Javascript implementation of the OpenPGP protocol (and the most popular PGP library for Node.js). Three input values are needed to <a href="https://github.com/openpgpjs/openpgpjs#create-and-verify-detached-signatures">validate PGP messages</a>.</p>

<ul>
<li><em>Message contents to check.</em></li>
<li><em>PGP signature for the message.</em></li>
<li><em>Public key for the private key used to sign the release.</em></li>
</ul>


<p>The "message" to check is the source archive. PGP signatures come from the <code>.asc</code> files located in the release candidate directory.</p>

<p>```
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1</p>

<p>iQIcBAABAgAGBQJcpO0FAAoJEHKvDMIsTPMgf0kP+wbtJ1ONZJQKjyDVx8uASMDQ
...
-----END PGP SIGNATURE-----
```</p>

<p>Public keys used to sign releases are <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/KEYS">stored in the root folder</a> of the release directory for that project.</p>

<p><em>This <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/lib/verify.js#L37-L58">function</a> is used to implement the signature checking process.</em></p>

<p>```javascript
const signature = async (file_stream, signature, public_keys, name) => {
  const options = {</p>

<pre><code>message: openpgp.message.fromBinary(file_stream),
signature: await openpgp.signature.readArmored(signature),
publicKeys: (await openpgp.key.readArmored(public_keys)).keys
</code></pre>

<p>  }</p>

<p>  const verified = await openpgp.verify(options)
  await openpgp.stream.readToEnd(verified.data)
  const valid = await verified.signatures[0].verified</p>

<p>  return { valid }
}
```</p>

<h4>scanning archive files</h4>

<p>Using the <a href="https://github.com/npm/node-tar">node-tar library</a>, downloaded source archives are extracted into the local runtime to allow scanning of individual files.</p>

<p>LICENSE.txt, DISCLAIMER.txt and NOTICE.txt files are checked to ensure correctness. An <a href="https://www.npmjs.com/package/isbinaryfile">external NPM library</a> is used to check all files in the archive for binary contents. The code also scans for directory names that might contain third party libraries (<code>node_modules</code> or <code>.gradle</code>).</p>

<h3>capturing validation logs</h3>

<p>It is important to provide PMC members with verifiable logs on the validation steps performed. This allows them to sanity check the steps performed (including manual validation). This verification text can also be provided in the voting emails as evidence of release candidate validity.</p>

<p>Using a <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/lib/logger.js">custom logging library</a>, all debug logs sent to the console <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/index.js#L63">are recorded in the action result</a> (and therefore returned in the API response).</p>

<h3>showing results</h3>

<p>Once all the validation tasks have been executed - the results are returned to the front-end as a JSON response. The client-side JS parses these results and updates the validation table. Validation logs are shown in a collapsible window.</p>

<p><img src="/images/ow_release_verifier/emojis.png" alt="Verification Results" /></p>

<p>Using visual emojis for pass and failure indicators for each step - the user can easily verify whether a release passes the validation checks. If any of the steps have failed, the validation logs provide an opportunity to understand why.</p>

<p><img src="/images/ow_release_verifier/logs.png" alt="Verification Logs" /></p>

<h2>other tools</h2>

<p>This is not the only tool that can automate checks needed to validate Apache Software Foundation releases.</p>

<p>Another <a href="https://twitter.com/rabbah">community member</a> has also built a bash script (<a href="https://gitbox.apache.org/repos/asf?p=incubator-openwhisk-release.git;a=blob_plain;f=tools/rcverify.sh;hb=HEAD">rcverify.sh</a>) that can verify releases on your local machine. This script will automatically download the release candidate files and run many of the same validation tasks as the remote tool locally.</p>

<p>There is also an existing tool (<a href="https://creadur.apache.org/rat/">Apache Rat</a>) from another project that provides a Java-based application for auditing license headers in source files.</p>

<h2>conclusion</h2>

<p>Getting new product releases published for an open-source project under the ASF is not a simple task for developers used to pushing a button on Github! The ASF has a series of strict guidelines on what constitutes a release and the ratification process from PMC members. PMC members need to run a series of manual verification tasks before casting binding votes on proposed release candidates.</p>

<p>This can be a time-consuming task for PMC members on a project like Apache OpenWhisk, with 52 different project repositories all being released at different intervals. In an effort to improve my own productivity around this process, I started looking for ways to automate the verification tasks. This would enable me to participate in more votes and be a "better" PMC member.</p>

<p>This led to building a serverless web application to run all the verification tasks remotely, which is now hosted at <a href="https://apache.jamesthom.as">https://apache.jamesthom.as</a>. This tool uses Apache OpenWhisk (provided by IBM Cloud Functions), which means the project is being used to verify future releases of itself! I've also <a href="https://github.com/jthomas/openwhisk-release-verification">open-sourced</a> the code to provide an example of how to use the platform for automating tasks like this.</p>

<p>With this tool and others listed above, verifying new <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> releases has never been easier!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenWhisk Web Action Errors With Sequences]]></title>
    <link href="http://jamesthom.as/blog/2019/02/27/openwhisk-web-action-errors-with-sequences/"/>
    <updated>2019-02-27T10:00:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/27/openwhisk-web-action-errors-with-sequences</id>
    <content type="html"><![CDATA[<p>This week, I came across an interesting problem when building HTTP APIs on <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a>.</p>

<p><blockquote><p>How can Apache OpenWhisk Web Actions, implemented using action sequences, handle application errors that need the sequence to stop processing and a custom HTTP response to be returned?</p></blockquote></p>

<p>This came from wanting to add custom <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication">HTTP authentication</a> to existing Web Actions. I had decided to enhance existing Web Actions with authentication using action sequences. This would combine a new action for authentication validation with the existing API route handlers.</p>

<p><img src="/images/sequences-and-web-actions/outline.png" title="" ></p>

<p>When the HTTP authentication is valid, the authentication action becomes a "<a href="https://en.wikipedia.org/wiki/NOP_(code)">no-op</a>", which passes along the HTTP request to the route handler action to process as normal.</p>

<p><strong>But what happens when authentication fails?</strong></p>

<p>The authentication action needs to stop request processing and return a <a href="https://httpstatuses.com/401">HTTP 401</a> response immediately.</p>

<p><img src="/images/sequences-and-web-actions/options.png" title="" ></p>

<p><em>Does Apache OpenWhisk even support this?</em></p>

<p>Fortunately, it does (phew) and I eventually worked out how to do this (based on a combination of re-reading <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/">documentation</a>, the platform <a href="https://github.com/apache/incubator-openwhisk/blob/master/core/controller/src/main/scala/org/apache/openwhisk/core/controller/WebActions.scala">source code</a> and just trying stuff out!).</p>

<p><em>Before explaining how to return custom HTTP responses using web action errors in sequences, let's review web actions, actions sequences and why developers often use them together...</em></p>

<h2>Web Actions</h2>

<p><a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md">Web Actions</a> are OpenWhisk <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md">actions</a> that can be invoked using external HTTP requests.</p>

<p>Incoming HTTP requests are provided as event parameters. HTTP responses are controlled using attributes (<code>statusCode</code>, <code>body</code>, <code>headers</code>) in the action result.</p>

<p>Web Actions can be invoked directly, using the platform API, or connected to <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/apigateway.md">API Gateway endpoints</a>.</p>

<h3>example</h3>

<p>Here is an example Web Action that returns a static HTML page.</p>

<p>```javascript
function main() {
  return {</p>

<pre><code>headers: {      
  'Content-Type': 'text/html'
},
statusCode: 200,
body: '&lt;html&gt;&lt;body&gt;&lt;h3&gt;hello&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;'
</code></pre>

<p>  }
}
```</p>

<h3>exposing web actions</h3>

<p>Web actions can be exported from any existing action by setting an <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/annotations.md#annotations-specific-to-web-actions">annotation</a>.</p>

<p>This is handled automatically by CLI using the <code>‚Äîweb</code> configuration flag when creating or updating actions.</p>

<p><code>
wsk action create ACTION_NAME ACTION_CODE --web true
</code></p>

<h2>Action Sequences</h2>

<p>Multiple actions can be composed together into a "meta-action" using <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md#creating-action-sequences">sequences</a>.</p>

<p>Sequence configuration defines a series of existing actions to be called sequentially upon invocation.  Actions connected in sequences can use different runtimes and even be sequences themselves.</p>

<p><code>
wsk action create mySequence --sequence action_a,action_b,action_c
</code></p>

<p>Input events are passed to the first action in the sequence. Action results from each action in the sequence are passed to the next action in the sequence. The response from the last action in the sequence is returned as the action result.</p>

<h3>example</h3>

<p>Here is a sequence (<code>mySequence</code>) composed of three actions (<code>action_a</code>, <code>action_b</code>, <code>action_c</code>).</p>

<p><code>
wsk action create mySequence --sequence action_a,action_b,action_c
</code></p>

<p>Invoking <code>mySequence</code> will invoke <code>action_a</code> with the input parameters. <code>action_b</code> will be invoked with the result from <code>action_a</code>.  <code>action_c</code> will be invoked with the result from <code>action_b</code>. The result returned by <code>action_c</code> will be returned as the sequence result.</p>

<h2>Web Actions from Action Sequences</h2>

<p>Using Action Sequences as Web Actions is a useful pattern for externalising common HTTP request and response processing tasks into separate serverless functions.</p>

<p>These common actions can be included in multiple Web Actions, rather than manually duplicating the same boilerplate code in each HTTP route action. This is similar to the "<a href="https://dzone.com/articles/understanding-middleware-pattern-in-expressjs">middleware</a>" pattern used by lots of common web application frameworks.</p>

<p>Web Actions using this approach are easier to test, maintain and allows API handlers to implement core business logic rather than lots of duplicate boilerplate code.</p>

<h3>authentication example</h3>

<p>In my application, new authenticated web actions were composed of two actions (<code>check_auth</code> and the API route handler, e.g. <code>route_handler</code>).</p>

<p>Here is an outline of the <code>check_auth</code> function in Node.js.</p>

<p>```javascript
const check_auth = (params) => {
  const headers = params.__ow_headers
  const auth = headers['authorization']</p>

<p>  if (!is_auth_valid(auth)) {</p>

<pre><code>// stop sequence processing and return HTTP 401?
</code></pre>

<p>  }</p>

<p>  // ...else pass along request to next sequence action
  return params
}
```</p>

<p>The <code>check_auth</code> function will inspect the HTTP request and validate the authorisation token. If the token is valid, the function returns the input parameters untouched, which leads the platform the invoke the <code>route_handler</code> to generate the HTTP response from the API route.</p>

<p><strong>But what happens if the authentication is invalid?</strong></p>

<p>The  <code>check_auth</code> action needs to return a HTTP 401 response immediately, rather than proceeding to the  <code>route_handler</code> action.</p>

<p><img src="/images/sequences-and-web-actions/options.png" title="" ></p>

<h3>handling errors - synchronous results</h3>

<p>Sequence actions can stop sequence processing by returning an error. Action errors are indicated by action results which include an "error" property or return rejected promises (for asynchronous results). Upon detecting an error, the platform will return the error result as the sequence action response.</p>

<p><em>If <code>check_auth</code> returns an error upon authentication failures, sequence processing can be halted, but how to control the HTTP response?</em></p>

<p><a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md#error-handling">Error responses</a> can also control the HTTP response, using the same properties (<code>statusCode</code>, <code>headers</code> and <code>body</code>) as a successful invocation result, with one difference: <strong>those properties must be the children of the <code>error</code> property rather than top-level properties.</strong></p>

<p>This example shows the error result needed to generate an immediate HTTP 401 response.</p>

<p>```json
{
   "error": {</p>

<pre><code>  "statusCode": 401,
  "body": "Authentication credentials are invalid."
}
</code></pre>

<p>}
```</p>

<p>In Node.js, this can be returned using a synchronous result as shown here.</p>

<p>```javascript
const check_auth = (params) => {
  const headers = params.__ow_headers
  const auth = headers['authorization']</p>

<p>  if (!is_auth_valid(auth)) {</p>

<pre><code>const response = { statusCode: 401, body: "Authentication credentials are invalid." }
return { error: response }
</code></pre>

<p>  }</p>

<p>  return params
}
```</p>

<h3>handling errors - using promises</h3>

<p>If a rejected Promise is used to return an error from an asynchronous operation, the promise result needs to contain the HTTP response properties as <strong>top-level properties</strong>, rather than under an <code>error</code> parent. This is because the Node.js runtime automatically <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L118">serialises the promise value</a> to an <code>error</code> property on the activation result.</p>

<p>```javascript
const check_auth = (params) => {
  const headers = params.__ow_headers
  const auth = headers['authorization']</p>

<p>  if (!is_auth_valid(auth)) {</p>

<pre><code>const response = { statusCode: 401, body: "Authentication credentials are invalid." }
return Promise.reject(response)
</code></pre>

<p>  }</p>

<p>  return params
}
```</p>

<h2>conclusion</h2>

<p>Creating web actions from sequences is a novel way to implement the "HTTP middleware" pattern on serverless platforms. Surrounding route handlers with pre-HTTP request modifier actions for common tasks, allows route handlers to remove boilerplate code and focus on the core business logic.</p>

<p>In my application, I wanted to use this pattern was being used for custom HTTP authentication validation.</p>

<p>When the HTTP request contains the correct credentials, the request is passed along unmodified. When the credentials are invalid, the action needs to stop sequence processing and return a HTTP 401 response.</p>

<p>Working out how to do this wasn't immediately obvious from the documentation. HTTP response parameters need to included under the <code>error</code> property for synchronous results. I have now opened a PR to improve the project documentation about this.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pluggable Event Providers for Apache OpenWhisk]]></title>
    <link href="http://jamesthom.as/blog/2019/02/20/pluggable-event-providers-for-apache-openwhisk/"/>
    <updated>2019-02-20T11:53:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/20/pluggable-event-providers-for-apache-openwhisk</id>
    <content type="html"><![CDATA[<p>Recently I presented my work building "<em><a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">pluggable event providers</a></em>" for <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> to the open-source community on the <a href="https://www.youtube.com/openwhisk">bi-weekly video meeting</a>.</p>

<p>This was based on my experience building a <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/feeds.md">new event provider</a> for Apache OpenWhisk, which led me to prototype an <strong>easier way to add event sources to platform</strong> whilst <strong>cutting down on the boilerplate code</strong> required.</p>

<p>Slides from the talk are <a href="https://speakerdeck.com/jthomas/apache-openwhisk-pluggable-event-providers">here</a> and there's also a video recording <a href="https://www.youtube.com/watch?v=krm7X5YpGy0">available</a>.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/krm7X5YpGy0?start=89" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<p>This blog post is overview of what I talked about on the call, explaining the background for the project and what was built. Based on positive feedback from the community, I have now open-sourced <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed">both</a> <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">components</a> of the experiment and will be merging it back upstream into Apache OpenWhisk in future.</p>

<h2>pluggable event providers - why?</h2>

<p>At the end of last year, I was asked to prototype an <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html">S3-compatible</a> Object Store event source for Apache OpenWhisk. Reviewing the <a href="https://github.com/search?q=incubator-openwhisk-package">existing event providers</a> helped me understand how they work and what was needed to build a new event source.</p>

<p>This led me to an interesting question...</p>

<blockquote><p>Why do we have relatively few community contributions for event sources?</p></blockquote>

<p>Most of the existing event sources in the project were contributed by IBM. There hasn't been a new event source from an external community member. This is in stark contrast to <a href="https://github.com/search?q=incubator-openwhisk-runtime">additional platform runtimes</a>. Support for PHP, Ruby, DotNet, Go and many more languages all came from community contributions.</p>

<p><em>Digging into the source code for the existing feed providers, I came to the following conclusions....</em></p>

<ul>
<li><strong>Trigger feed providers are not simple to implement.</strong></li>
<li><strong>Documentation how existing providers work is lacking.</strong></li>
</ul>


<p>Feed providers can feel a bit like magic to users. You call the <code>wsk</code> CLI with a <code>feed</code> parameter and that's it, the platform handles everything else. But what actually happens to bind triggers to external event sources?</p>

<p><em>Let's start by explaining how trigger feeds are implemented in Apache OpenWhisk, before moving onto my idea to make contributing new feed providers easier.</em></p>

<h2>how trigger feeds work</h2>

<p>Users normally interact with trigger feeds using the <code>wsk</code> CLI. Whilst creating a trigger, the <code>feed</code> parameter can be included to connect that trigger to an external event source. Feed provider options as provided as further CLI parameters.</p>

<p><code>
wsk trigger create periodic \
  --feed /whisk.system/alarms/alarm \
  --param cron "*/2 * * * *" \
  --param trigger_payload ‚Äú{‚Ä¶}‚Äù \
  --param startDate "2019-01-01T00:00:00.000Z" \
  --param stopDate "2019-01-31T23:59:00.000Z"
</code></p>

<p><em>But what are those trigger feed identifiers used with the <code>feed</code> parameter?</em></p>

<p><strong>It turns out they are just normal actions which have been shared in a public package!</strong></p>

<p>The CLI creates the trigger (using the platform API) and then invokes the referenced feed action. Invocation parameters include the following values used to manage the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/feeds.md#implementing-feed-actions">trigger feed lifecycle</a>.</p>

<ul>
<li><code>lifecycleEvent</code> - Feed operation (<code>CREATE</code>, <code>READ</code>, <code>UPDATE</code>, <code>DELETE</code>, <code>PAUSE</code>, or <code>UNPAUSE</code>).</li>
<li><code>triggerName</code> - Trigger identifier.</li>
<li><code>authKey</code> - API key provided to invoke trigger.</li>
</ul>


<p>Custom feed parameters from the user are also included in the event parameters.</p>

<p><strong>This is the entire interaction of the platform with the feed provider.</strong></p>

<p>Providers are responsible for the full management lifecycle of trigger feed event sources. They have to maintain the list of registered triggers and auth keys, manage connections to user-provided event sources, fire triggers upon external events, handle retries and back-offs in cases of rate-limiting and much more.</p>

<p>Feed providers used with a trigger are stored as custom annotations. This allows the CLI to call the same feed action to stop the event binding when the trigger is deleted.</p>

<h3>trigger management</h3>

<p>Reading the source code for the <a href="https://github.com/search?q=incubator-openwhisk-package">existing feed providers</a>, nearly all of the code is responsible for handling the lifecycle of trigger management events, rather than integrating with the external event source.</p>

<p>Despite this, all of the existing providers are in separate repositories and don't share code explicitly, although the same source files have been replicated in different repos.</p>

<p>The <a href="https://github.com/apache/incubator-openwhisk-package-cloudant">CouchDB feed provider</a> is a good example of how feed providers can be implemented.</p>

<h3>couchdb feed provider</h3>

<p>The <a href="https://github.com/apache/incubator-openwhisk-package-cloudant">CouchDB trigger feed provider</a> uses a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/actions/event-actions/changes.js">public action</a> to handle the lifecycle events from the <code>wsk</code> CLI.</p>

<p><img src="/images/pluggable-providers/feeds-overview.png" title="" ></p>

<p>This <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/actions/event-actions/changes.js">action</a> just proxies the incoming requests to a separate <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/actions/event-actions/changesWebAction.js">web actio</a>n. The <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md">web action</a> implements the logic to handle the trigger lifecycle event. The web action uses a CouchDB database used to store registered triggers. Based upon the lifecycle event details, the web action updates the database document for that trigger.</p>

<p><img src="/images/pluggable-providers/feeds-provider.png" title="" ></p>

<p>The feed provider also runs a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/tree/master/provider">seperate Docker container</a>, which handles listening to CouchDB change feeds from user-provided credentials. It uses the changes feed from the trigger management database, modified from the web action, to listen for triggers being added, removed, disabled or re-enabled.</p>

<p><img src="/images/pluggable-providers/feeds-fire-trigger.png" title="" ></p>

<p>When database change events <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/provider/lib/utils.js#L78">occur</a>, the container <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/provider/lib/utils.js#L66-L76">fires triggers</a> on the platform with the event details.</p>

<h2>building a new event provider?</h2>

<p>Having understood how feed providers work (and how the existing providers were designed), I started to think about the new event source for an S3-compatible object store.</p>

<p>Realising ~90% of the code between providers was the same, I wondered if there was a different approach to creating new event providers, rather than cloning an existing provider and changing the small amount of code used to interact with the event sources.</p>

<p><strong>What about building a generic event provider which a pluggable event source?</strong></p>

<p>This generic event provider would handle all the trigger management logic, which isn't specific to individual event sources. The event source plugin would manage connecting to external event sources and then firing triggers as event occurred. Event source plugins would implement a standard interface and be registered dynamically during startup.</p>

<p><img src="/images/pluggable-providers/generic-provider.png" title="" ></p>

<h3>advantages</h3>

<p>Using this approach would make it much easier to contribute and maintain new event sources.</p>

<ul>
<li><p>Users would be able to create new event sources with a few lines of custom integration code, rather than replicating all the generic trigger lifecycle management code.</p></li>
<li><p>Maintaining a single repo for the generic event provider is easier than having the same code copied and pasted in multiple independent repositories.</p></li>
</ul>


<p>I started hacking away at the existing CouchDB event provider to replace the event source integration with a generic plugin interface. Having completed this, I then wrote a new S3-compatible event source using the plugin model. After a couple of weeks I had something working....</p>

<h2>generic event provider</h2>

<p>The <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">generic event provider</a> is based on the exiting CouchDB feed provider source code. The project contains the stateful container code and feed package actions (public &amp; web). It uses the same platform services (CouchDB and Redis) as the existing provider to maintain trigger details.</p>

<p>The event provider plugin is integrated through the <code>EVENT_PROVIDER</code> environment variable. The name should refer to a Node.js module from NPM with the following <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider#plugin-interface">interface</a>.</p>

<p>```javascript
// initialise plugin instance (must be a JS constructor)
module.exports = function (trigger_manager, logger) {</p>

<pre><code>// register new trigger feed
const add = async (trigger_id, trigger_params) =&gt; {}
// remove existing trigger feed
const remove = async trigger_id =&gt; {}
</code></pre>

<p>   return { add, remove }
}</p>

<p>// valiate feed parameters
module.exports.validate = async trigger_params => {}
```</p>

<p>When a new trigger is added to the trigger feeds' database, the details will be passed to the <code>add</code> method. Trigger parameters will be used to set up listening to the external event source. When external events occur, the <code>trigger_manager</code> can be use to automatically fire triggers.</p>

<p>When users delete triggers with feeds, the trigger will be removed from the database. This will lead to the <code>remove</code> method being called. Plugins should stop listening to messages for this event source.</p>

<h3>firing trigger events</h3>

<p>As event arrive from the external source, the plugin can use the <code>trigger_manager</code> instance, passed in through the constructor, to fire triggers with the identifier.</p>

<p>The <code>trigger_manager</code> parameter exposes two async functions:</p>

<ul>
<li><code>fireTrigger(id, params)</code> - fire trigger given by id passed into <code>add</code> method with event parameters.</li>
<li><code>disableTrigger(id, status_code, message)</code> - disable trigger feed due to external event source issues.</li>
</ul>


<p>Both functions handle the retry logic and error handling for those operations. These should be used by the event provider plugin to fire  triggers when events arrive from external sources and then disable triggers due to external event source issues.</p>

<h3>validating event source parameters</h3>

<p>This static function on the plugin constructor is used to validate incoming trigger feed parameters for correctness, e.g. checking  authentication credentials for an event source. It is passed the trigger  parameters from the user.</p>

<h2>S3 event feed provider</h2>

<p>Using this new generic event provider, I was able to create an event source for an <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed">S3-compatible object store</a>. Most importantly, this new event source was implemented using just <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed/tree/master/lib">~300 lines</a> of JavaScript! This is much smaller than the 7500 lines of code in the generic event provider.</p>

<p>The feed provider polls buckets on an interval using the <code>ListObjects</code> <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/v2-RESTBucketGET.html">API call</a>. Results are cached in Redis to allow comparison between intervals. Comparing the differences in bucket file name and etags, allows file change events to be detected.</p>

<p>Users can call the feed provider with a bucket name, endpoint, API key and polling interval.</p>

<p><code>
wsk trigger create test-s3-trigger --feed /&lt;PROVIDER_NS&gt;/s3-trigger-feed/changes --param bucket &lt;BUCKET_NAME&gt; --param interval &lt;MINS&gt; --param s3_endpoint &lt;S3_ENDPOINT&gt; --param s3_apikey &lt;COS_KEY&gt;
</code></p>

<p>File events are fired as the bucket files change with the following trigger events.</p>

<p>```
{
  "file": {</p>

<pre><code>"ETag": "\"fb47672a6f7c34339ca9f3ed55c6e3a9\"",
"Key": "file-86.txt",
"LastModified": "2018-12-19T08:33:27.388Z",
"Owner": {
  "DisplayName": "80a2054e-8d16-4a47-a46d-4edf5b516ef6",
  "ID": "80a2054e-8d16-4a47-a46d-4edf5b516ef6"
},
"Size": 25,
"StorageClass": "STANDARD"
</code></pre>

<p>  },
  "status": "deleted"
}
```</p>

<p><em>Pssst - if you are using <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a> - I actually have this deployed and running so you can try it out. Use the <code>/james.thomas@uk.ibm.com_dev/s3-trigger-feed/changes</code> feed action name. This package is only available in the London region.</em></p>

<h2>next steps</h2>

<p>Feedback on the call was overwhelming positive on my experiment. Based upon this, I've now open-sourced both the <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">generic event provider</a> and <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed">s3 event source plugin</a> to allow the community to evaluate the project further.</p>

<p>I'd like to build a few more example event providers to validate the approach further before moving towards contributing this code back upstream.</p>

<p>If you want to try this generic event provider out with your own install of OpenWhisk, please see the <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider/blob/master/README.md#running-the-provider--plugin">documentation</a> in the README for how to get started.</p>

<p>If you want to build new event sources, please see the <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider/blob/master/README.md#plugin-interface">instructions</a> in the generic feed provider repository and take a look at the S3 plugin for an example to follow.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CouchDB Filters with OpenWhisk Triggers]]></title>
    <link href="http://jamesthom.as/blog/2019/02/12/couchdb-filters-with-openwhisk-triggers/"/>
    <updated>2019-02-12T14:22:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/12/couchdb-filters-with-openwhisk-triggers</id>
    <content type="html"><![CDATA[<p>Imagine you have an <a href="http://openwhisk.incubator.apache.org/">OpenWhisk</a> <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md">action</a> to send emails to users to verify their email addresses. User profiles, containing email addresses and verification statuses, are maintained in a <a href="https://couchdb.apache.org/">CouchDB</a> database.</p>

<p>```json
{</p>

<pre><code>...
"email": {
    "address": "user@host.com",
    "status": "unverified"
}
</code></pre>

<p>}
```</p>

<p>Setting up a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant">CouchDB trigger feed</a> allows the email action <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/triggers_rules.md">to be invoked</a> when the user profile changes. When user profiles have unverified email addresses, the action can send verification emails.</p>

<p>Whilst this works fine - it will result in a lot of unnecessary invocations. All modifications to user profiles, not just the email field, will result in the action being invoked. This will incur a cost despite the action having nothing to do.</p>

<blockquote><p>How can we restrict document change events to just those we care about?</p></blockquote>

<p>CouchDB <a href="https://docs.couchdb.org/en/stable/ddocs/ddocs.html#filter-functions">filter functions</a> to the rescue ü¶∏‚Äç‚ôÇÔ∏èü¶∏‚Äç.</p>

<h2>CouchDB Filter Functions</h2>

<p><a href="https://docs.couchdb.org/en/stable/ddocs/ddocs.html#filter-functions">Filter functions</a> are Javascript functions executed against (potential) <a href="http://guide.couchdb.org/draft/notifications.html">change feed events</a>. The function is invoked with each document update. The return value is evaluated as a boolean variable. If true, the document is published on the changes feed. Otherwise, the event is filtered from the changes feed.</p>

<h3>example</h3>

<p>Filter functions are created through <a href="https://docs.couchdb.org/en/stable/ddocs/ddocs.html">design documents</a>. Function source strings are stored as properties under the <code>filters</code> document attribute. Key names are used as filter identifiers.</p>

<p>Filter functions should have the following interface.</p>

<p>```javascript
function(doc, req){</p>

<pre><code>// document passes test
if (doc.property == 'value'){
    return true;
}

// ... else ignore document upate
return false;
</code></pre>

<p>}
```</p>

<p> <code>doc</code> is the modified document object and <code>req</code> contains (optional) request parameters.</p>

<p><em>Let's now explain how to create a filter function to restrict profile update events to just those with unverified email addresses...</em></p>

<h2>Filtering Profile Updates</h2>

<h3>user profile documents</h3>

<p>In this example, email addresses are stored in user profile documents under the <code>email</code> property. <code>address</code> contains the user's email address and <code>status</code> records the verification status (<code>unverified</code> or <code>verified</code>).</p>

<p>When a new user is added, or an existing user changes their email address, the <code>status</code> attribute is set to <code>unverified</code>. This indicates a verification message needs to be sent to the email address.</p>

<p>```json
{</p>

<pre><code>...
"email": {
    "address": "user@host.com",
    "status": "unverified"
}
</code></pre>

<p>}
```</p>

<h3>unverified email filter</h3>

<p>Here is the CouchDB filter function that will ignore document updates with verified email addresses.</p>

<p>```
function(doc){</p>

<pre><code>if (doc.email.status == 'unverified'){
    return true;
}

return false
</code></pre>

<p>}
```</p>

<h3>design document with filters</h3>

<p>Save the following JSON document in CouchDB. This creates a new design document (<code>profile</code>) containing a filter function (<code>unverified-emails</code>).</p>

<p>```json
{
  "<em>id": "</em>design/profile",<br/>
  "filters": {</p>

<pre><code>"unverified-emails": "function (doc) {\n  if (doc.email.status == 'unverified') {\n    return true\n  }\n  return false\n}"
</code></pre>

<p>  },
  "language": "javascript"
}
```</p>

<h3>trigger feed with filter</h3>

<p>Once the design document is created, the filter name can be used as a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant#create-the-trigger-using-the-filter-function">trigger feed parameter</a>.</p>

<p><code>
wsk trigger create verify_emails --feed /_/myCloudant/changes \
--param dbname user_profiles \
--param filter "profile/unverified-emails"
</code></p>

<p>The trigger only fires when a profile change contains an unverified email address. No more unnecessary invocations, which saves us money! üòé</p>

<h3>caveats</h3>

<p><em>"Why are users getting multiple verification emails?"</em> üò°</p>

<p>If a user changes their profile information, whilst leaving their email address the same but before clicking the verification email, an additional email will be sent.</p>

<p>This is because the <code>status</code> field is still in the <code>unverified</code> state when the next document update occurs. Filter functions are stateless and can't decide if this email address has already been seen.</p>

<p>Instead of leaving the <code>status</code> field as <code>unverified</code>, the email action should change the state to another value, e.g. <code>pending</code>, to indicate the verification email has been sent.</p>

<p>Any further document updates, whilst waiting for the verification response, won't pass the filter and users won't receive multiple emails. üëç</p>

<h2>Conclusion</h2>

<p>CouchDB filters are an easy way to subscribe to a subset of events from the changes feed. Combining CouchDB trigger feeds with filters allows actions to ignore irrelevant document updates. Multiple trigger feeds can be set up from a single database using filter functions.</p>

<p>As well as saving unnecessary invocations (and therefore money), this can simplify data models. A single database can be used to store all documents, rather than having to split different types into multiple databases, whilst still supporting changes feeds per document type.</p>

<p>This is an awesome feature of CouchDB!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Large (Java) Applications on Apache OpenWhisk]]></title>
    <link href="http://jamesthom.as/blog/2019/02/05/large-java-applications-on-openwhisk/"/>
    <updated>2019-02-05T10:49:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/05/large-java-applications-on-openwhisk</id>
    <content type="html"><![CDATA[<p>This blog post will explain how to run large <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-java.md">Java applications</a> on <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>.</p>

<p>Java actions are <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-java.md">deployed from JAR files</a> containing application class files. External libraries can be used by bundling those dependencies into a <a href="https://stackoverflow.com/questions/19150811/what-is-a-fat-jar">fat JAR file</a>. The JAR file must be less than the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/reference.md#per-action-artifact-mb-default-48mb">maximum action size</a> of 48MB.</p>

<blockquote><p>So, what if the application uses lots of external libraries and the JAR file is larger than 48MB? ü§î</p></blockquote>

<p>Apache OpenWhisk's support for <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">custom Docker runtimes</a> provides a workaround. In a <a href="http://jamesthom.as/blog/2017/08/04/large-applications-on-openwhisk/">previous blog post</a>, we showed how this feature could be used with Python applications which rely on lots of external libraries.</p>

<p>Using the same approach with Java, a <a href="https://github.com/apache/incubator-openwhisk-runtime-java/">custom Java runtime</a> can be created with additional libraries pre-installed. Those libraries do not need to be included in the application jar, which will just contain private class files. This should hopefully reduce the JAR file to under the action size limit.</p>

<p><em>Let's walk through an example to show how this works....</em></p>

<h2>Example Java Class using External Libraries</h2>

<p>```java
import com.google.gson.JsonObject;
import org.apache.commons.text.WordUtils;</p>

<p>public class Capitialize {</p>

<pre><code>public static JsonObject main(JsonObject args) {
    String name = args.getAsJsonPrimitive("message").getAsString();
    JsonObject response = new JsonObject();
    response.addProperty("capitalized", WordUtils.capitalize(name));
    return response;
}
</code></pre>

<p>}
```</p>

<p>This example Java action capitalises sentences from the input event. It uses the <a href="https://commons.apache.org/proper/commons-text/">Apache Commons Text library</a> to handle <a href="https://commons.apache.org/proper/commons-text/javadocs/api-release/org/apache/commons/text/WordUtils.html#capitalize(java.lang.String)">capitialisation</a> of input strings. This external library will be installed in the runtime, rather than bundled in the application JAR file.</p>

<h2>Build Custom Java Runtime</h2>

<ul>
<li>Clone the existing <a href="https://github.com/apache/incubator-openwhisk-runtime-java/">Apache OpenWhisk Java runtime repository</a>.</li>
</ul>


<p><code>sh
git clone https://github.com/apache/incubator-openwhisk-runtime-java
</code></p>

<ul>
<li>Edit the <code>core/java8/proxy/build.gradle</code> file and update the <code>dependencies</code> <a href="https://github.com/apache/incubator-openwhisk-runtime-java/blob/master/core/java8/proxy/build.gradle#L24-L26">configuration</a> with extra dependencies needed in the runtime.</li>
</ul>


<p>```
dependencies {</p>

<pre><code>compile 'com.google.code.gson:gson:2.6.2'
compile 'org.apache.commons:commons-text:1.6' // &lt;-- the additional library
</code></pre>

<p>}
```</p>

<p><em>Note: <code>com.google.code.gson:gson:2.6.2</code> is used by the runtime to handle JSON encoding/decoding. Do not remove this dependency.</em></p>

<ul>
<li>Execute the following command to build the custom <a href="https://en.wikipedia.org/wiki/Docker_%28software%29">Docker</a> image.</li>
</ul>


<p><code>
./gradlew core:java8:distDocker
</code></p>

<h2>Push Image To Docker Hub</h2>

<p>If the build process succeeds, a local Docker image named <code>java8action</code> should be available. This needs to be pushed to <a href="https://hub.docker.com/">Docker Hub</a> to allow Apache OpenWhisk to use it.</p>

<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/tag/">Tag</a> the custom image with a <a href="https://hub.docker.com/signup">Docker Hub username</a>.</li>
</ul>


<p><code>
docker tag java8action &lt;DOCKERHUB_USERNAME&gt;/java8action
</code></p>

<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/push/">Push</a> the tagged custom image to Docker Hub.</li>
</ul>


<p><code>
docker push &lt;DOCKERHUB_USERNAME&gt;/java8action
</code></p>

<h2>Create OpenWhisk Action With Custom Runtime</h2>

<ul>
<li>Compile the Java source file.</li>
</ul>


<p><code>
javac Capitialize.java
</code></p>

<ul>
<li>Create the application JAR from the class file.</li>
</ul>


<p><code>
jar cvf capitialize.jar Capitialize.class
</code></p>

<ul>
<li>Create the Java action with the custom runtime.</li>
</ul>


<p><code>
wsk action create capitialize capitialize.jar --main Capitialize --docker &lt;DOCKERHUB_USERNAME&gt;/java8action
</code></p>

<p><em><code>--main</code> is the class file name containing the action handler in the JAR file. <code>--docker</code> is the Docker image name for the custom runtime.</em></p>

<h2>Test it out!</h2>

<ul>
<li>Execute the <code>capitialize</code> action with input text to returned capitalised sentences.</li>
</ul>


<p><code>
wsk action invoke capitialize -b -r -p message "this is a sentence"
</code></p>

<p>If this works, the following JSON should be printed to the console.</p>

<p>```json
{</p>

<pre><code>"capitalized": "This Is A Sentence"
</code></pre>

<p>}
```</p>

<p>The external library has been used in the application without including it in the application JAR file! üíØüíØüíØ</p>

<h2>Conclusion</h2>

<p>Apache OpenWhisk supports running Java applications using fat JARs, which bundle application source code and external dependencies. JAR files cannot be more than 48MB, which can be challenging when applications uses lots of external libraries.</p>

<p>If application source files and external libraries result in JAR files larger than this limit, Apache OpenWhisk's support for custom Docker runtimes provide a solution for running large Java applications on the platform.</p>

<p>By building a custom Java runtime, extra libraries can be pre-installed in the runtime. These dependencies do not need to be included in the application JAR file, which reduces the file size to under the action size limit. üëç</p>
]]></content>
  </entry>
  
</feed>
