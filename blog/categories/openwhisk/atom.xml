<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: openwhisk | James Thomas]]></title>
  <link href="http://jamesthom.as/blog/categories/openwhisk/atom.xml" rel="self"/>
  <link href="http://jamesthom.as/"/>
  <updated>2017-01-18T09:40:01+00:00</updated>
  <id>http://jamesthom.as/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OpenWhisk and Rust]]></title>
    <link href="http://jamesthom.as/blog/2017/01/18/openwhisk-and-rust/"/>
    <updated>2017-01-18T09:00:00+00:00</updated>
    <id>http://jamesthom.as/blog/2017/01/18/openwhisk-and-rust</id>
    <content type="html"><![CDATA[<p><em>This blog post is <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">one of</a> <a href="http://jamesthom.as/blog/2017/01/17/openwhisk-and-go/">a series</a> looking at using Docker Actions in OpenWhisk to support extra runtimes.</em></p>

<p>Let's look at writing serverless functions for <a href="http://openwhisk.org/">OpenWhisk</a> using <a href="https://rust-lang.org">Rust</a>.</p>

<p><blockquote><p>Rust is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety.</p></blockquote></p>

<p>Rust has been growing in popularity since it launched in 2010. Rust is a popular language for writing microservices due to the focus on the attention to safety and strong concurrency support.</p>

<p>None of the major serverless platform natively support Rust at the moment. OpenWhisk does not include this as a default runtime. However, <a href="https://www.ibm.com/blogs/bluemix/2017/01/docker-bluemix-openwhisk/">recent updates</a> to OpenWhisk provide a path for writing serverless functions with Rust.</p>

<p>Let's re-write <a href="http://jamesthom.as/blog/2017/01/17/openwhisk-and-go/">the example</a> from the previous post in Rust and see how to get it running using this new approachâ€¦</p>

<p><strong><em>Have you seen <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">this post</a> explaining how Docker-based Actions work? This post assumes you have already read that first.</em></strong></p>

<h2>Rust Language Actions</h2>

<p>Rust has a <a href="http://doc.crates.io/guide.html">build system</a> that supports creating static binaries. These binaries contain the application source code and dependent libraries.</p>

<p>Using the same approach as the <a href="http://jamesthom.as/blog/2017/01/17/openwhisk-and-go/">Go-based example</a>, bundling this binary into a zip file allows us to overwrite the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/stub.sh">runtime stub</a> prior to invocation.</p>

<p>Runtime binaries will be executed by the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py">Python-based invoker</a> for each invocation. Request parameters will be passed as a JSON string using the first command-line argument. The invoker expects the Action result to be written to standard output as a JSON string.</p>

<h3>Action Source Code</h3>

<p>Here's a simple Rust function that returns a greeting string from an input parameter. It parses the JSON string provided on the command-line to look for a <code>name</code> parameter. If this isn't present, it defaults to <code>stranger</code>. It returns a JSON object with the greeting string (<code>msg</code>) by writing to the console.</p>

<p>``` rust
extern crate rustc_serialize;
use rustc_serialize::json;
use rustc_serialize::json::Json;
use std::env;</p>

<h1>[derive(RustcDecodable, RustcEncodable)]</h1>

<p>pub struct Greeting {</p>

<pre><code>message: String
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let mut name = "stranger".to_string();

// first arg contains JSON parameters
if let Some(arg1) = env::args().nth(1) {
    // parse JSON and extract 'name' field
    let params = Json::from_str(&amp;arg1).unwrap();
    if let Some(params_obj) = params.as_object() {
        if let Some(params_name) = params_obj.get("name") {
            name = params_name.as_string().unwrap().to_string();
        }
    }
};

let greeting = Greeting {
    message: format!("Hello, {}!", name),
};

println!("{}", json::encode(&amp;greeting).unwrap());
</code></pre>

<p>}
```</p>

<h3>Set Up Project</h3>

<p>Using Rust's package management tool, create a new project for our serverless function.</p>

<p>Add the source code above into the <code>src/main.rs</code> file.</p>

<p>```sh
$ cargo new action; cd action</p>

<pre><code> Created library `action` project
</code></pre>

<p>$ mv src/lib.rs src/main.rs
$ vim src/main.rs
$ tree .
.
â”œâ”€â”€ Cargo.toml
â””â”€â”€ src</p>

<pre><code>â””â”€â”€ main.rs
</code></pre>

<p>1 directory, 2 files
```</p>

<p>This function uses the <code>rustc-serialize</code> crate to handle parsing and producing JSON.</p>

<p>Add this identifier to the project's dependencies listed in <code>Cargo.toml</code>.</p>

<p>``` sh
[package]
name = "action"
version = "0.1.0"
authors = ["Me <a href="&#109;&#x61;&#105;&#x6c;&#x74;&#x6f;&#x3a;&#x6d;&#101;&#64;&#x65;&#x6d;&#97;&#x69;&#x6c;&#x2e;&#99;&#x6f;&#x6d;">&#x6d;&#x65;&#64;&#101;&#109;&#x61;&#105;&#x6c;&#46;&#99;&#x6f;&#x6d;</a>"]</p>

<p>[dependencies]
rustc-serialize = "0.3"
```</p>

<p>Build and run the binary to test it works as expected.</p>

<p>```go
$ cargo run</p>

<pre><code>Updating registry `https://github.com/rust-lang/crates.io-index`
</code></pre>

<p>   Compiling rustc-serialize v0.3.22
   Compiling action v0.1.0 (file:///private/tmp/test/action)</p>

<pre><code>Finished debug [unoptimized + debuginfo] target(s) in 7.0 secs
 Running `target/debug/action`
</code></pre>

<p>{"message":"Hello, stranger!"}
$ cargo run '{"name": "James"}'</p>

<pre><code>Finished debug [unoptimized + debuginfo] target(s) in 0.0 secs
 Running `target/debug/action {\"name\":\ \"James\"}`
</code></pre>

<p>{"message":"Hello, James!"}
```</p>

<p><em>Before we can deploy this binary to OpenWhisk, it must be compiled for the platform architecture.</em></p>

<h3>Cross-Compiling Locally</h3>

<p>Rust's compiler uses LLVM under the covers, making it possible to generate machine code for different architectures. Cross-compiling for different platforms requires having the correct compiler, linker and libraries for that architecture installed.</p>

<p>Rust <a href="https://blog.rust-lang.org/2016/05/13/rustup.html">recently released</a> a <a href="https://rustup.rs/">toolchain manager</a> to simplify this process.</p>

<p>Install the Rust toolchain for the <code>x86_64-unknown-linux-musl</code> runtime.</p>

<p><code>sh
$ rustup target add x86_64-unknown-linux-musl
info: downloading component 'rust-std' for 'x86_64-unknown-linux-musl'
info: installing component 'rust-std' for 'x86_64-unknown-linux-musl'
</code></p>

<p>Add the configuration file to set the correct linker for the runtime.</p>

<p><code>sh
$ cat .cargo/config
[target.x86_64-unknown-linux-musl]
linker = "x86_64-linux-musl-gcc"
</code></p>

<p>We can now cross-compile the binary for the correct environment.</p>

<p>``` sh
$ cargo build --target=x86_64-unknown-linux-musl --release
   Compiling rustc-serialize v0.3.22
   Compiling action v0.1.0 (file:///Users/james/code/bluemix/openwhisk-languages/rust/action)</p>

<pre><code>Finished release [optimized] target(s) in 9.30 secs
</code></pre>

<p>```</p>

<p>Checking the file type demonstrates we have built a static binary for the Linux x86_64 platform.</p>

<p><code>sh
$ file target/x86_64-unknown-linux-musl/release/action
target/x86_64-unknown-linux-musl/release/action: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, not stripped
</code></p>

<h3>Cross-Compiling Using Docker</h3>

<p>If you don't want to install the Rust development toolchain, Docker can be used to start a container with the <a href="https://github.com/emk/rust-musl-builder">environment set up</a>.</p>

<p>```sh
$ docker pull ekidd/rust-musl-builder
$ docker run -it -v $(pwd):/home/rust/src ekidd/rust-musl-builder cargo build --release</p>

<pre><code>Updating registry `https://github.com/rust-lang/crates.io-index`
</code></pre>

<p> Downloading rustc-serialize v0.3.22
   Compiling action v0.1.0 (file:///home/rust/src)</p>

<pre><code>Finished release [optimized] target(s) in 1.80 secs
</code></pre>

<p>$ file target/x86_64-unknown-linux-musl/release/action
target/x86_64-unknown-linux-musl/release/action: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, not stripped
```</p>

<h3>Create &amp; Deploy Archive</h3>

<p>Add the binary to a zip file, ensuring the file is named <code>exec</code> in the archive.</p>

<p>Use the <code>wsk</code> command-line to create a new Docker Action using this archive.</p>

<p><code>sh
$ cp target/x86_64-unknown-linux-musl/release/action exec
$ zip action.zip exec
  adding: exec (deflated 64%)
$ wsk action create rust_test action.zip --docker
ok: created action rust_test
</code></p>

<h3>Invoking Action</h3>

<p>Test the action from the command-line to verify it works.</p>

<p>```sh
$ wsk action invoke rust_test --blocking --result
{</p>

<pre><code>"msg": "Hello, Stranger!"
</code></pre>

<p>}
$ wsk action invoke rust_test --blocking --result --param name James
{</p>

<pre><code>"msg": "Hello, James!"
</code></pre>

<p>}
```</p>

<p>Success ðŸ˜Ž.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Openwhisk and Go]]></title>
    <link href="http://jamesthom.as/blog/2017/01/17/openwhisk-and-go/"/>
    <updated>2017-01-17T09:00:00+00:00</updated>
    <id>http://jamesthom.as/blog/2017/01/17/openwhisk-and-go</id>
    <content type="html"><![CDATA[<p><a href="http://jamesthom.as/blog/2016/06/21/serverless-go-actions/">In an earlier blog post</a>, I explained how to use Go language binaries on OpenWhisk using Docker-based Actions. It relied on building Docker images for each serverless function and hosting them on Docker Hub.</p>

<p><a href="https://www.ibm.com/blogs/bluemix/2017/01/docker-bluemix-openwhisk/">Recent updates</a>  to Docker-based Actions have made this process much simpler. Developers don't need to build and expose public images anymore.</p>

<p>Let's re-visit the example from the previous post and see how to get it running using this new approachâ€¦</p>

<p><strong><em>Have you seen <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">this post</a> explaining how Docker-based Actions work? This post assumes you have already read that first.</em></strong></p>

<h2>Go Language Actions</h2>

<p>Go's <a href="https://golang.org/pkg/go/build/">build system</a> combines application source code and dependencies into a single execution binary. Bundling this binary into a zip file allows us to overwrite the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/stub.sh">runtime stub</a> prior to invocation.</p>

<p>Runtime binaries will be executed by the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py">Python-based invoker</a> for each invocation. Request parameters will be passed as a JSON string using the first command-line argument. The invoker expects the Action result to be written to standard output as a JSON string.</p>

<h3>Action Source Code</h3>

<p>Here's a simple Go function that returns a greeting string from an input parameter. It parses the JSON string provided on the command-line to look for a <code>name</code> parameter. If this isn't present, it defaults to <code>Stranger</code>. It returns a JSON object with the greeting string (<code>msg</code>) by writing to the console.</p>

<p>``` go
package main</p>

<p>import "encoding/json"
import "fmt"
import "os"</p>

<p>func main() {</p>

<pre><code>// native actions receive one argument, the JSON object as a string
arg := os.Args[1]

// unmarshal the string to a JSON object
var obj map[string]interface{}
json.Unmarshal([]byte(arg), &amp;obj)
name, ok := obj["name"].(string)
if !ok {
    name = "Stranger"
}
msg := map[string]string{"msg": ("Hello, " + name + "!")}
res, _ := json.Marshal(msg)
fmt.Println(string(res))
</code></pre>

<p>}
```</p>

<p>Building this locally allows us to test it works.</p>

<p><code>go
$ go run test.go '{"name": "James"}'
{"msg":"Hello, James!"}
</code></p>

<p><em>Before we can deploy this binary to OpenWhisk, it must be compiled for the platform architecture.</em></p>

<h3>Cross-Compiling Locally</h3>

<p>Go 1.5 <a href="https://dave.cheney.net/2015/08/22/cross-compilation-with-go-1-5">introduced much improved</a> support for cross-compilation.</p>

<p>If you have the development environment installed locally, you can compile the binary for another platform by setting environment variables. The full list of supported architectures is available <a href="https://golang.org/doc/install/source#environment">here</a>.</p>

<p><em>OpenWhisk uses an <a href="https://hub.docker.com/_/alpine/">Alpine Linux-based</a> environment to execute Actions.</em></p>

<p><code>sh
$ env GOOS=linux GOARCH=amd64 go build exec.go
</code></p>

<p>Checking the file type demonstrates we have built a static binary for the Linux x86_64 platform.</p>

<p><code>sh
$ file exec
exec: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped
</code></p>

<h3>Cross-Compiling Using Docker</h3>

<p>If you don't want to install the Go development toolchain, Docker can be used to start a container with the environment set up.</p>

<p><code>sh
$ docker pull golang
$ docker run -it -v $(pwd):/go/src golang
root@0a2f1655eece:/go# cd src/
root@0a2f1655eece:/go/src# go build exec.go
root@0a2f1655eece:/go/src# ls
exec  exec.go
$ file exec
exec: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped
</code></p>

<h3>Create &amp; Deploy Archive</h3>

<p>Add the binary to a zip file, ensuring the file is named <code>exec</code> in the archive.</p>

<p>Use the <code>wsk</code> command-line to create a new Docker Action using this archive.</p>

<p><code>sh
$ zip action.zip exec
  adding: exec (deflated 66%)
$ wsk action create go_test action.zip --docker
ok: created action go_test
</code></p>

<h3>Invoking Action</h3>

<p>Test the action from the command-line to verify it works.</p>

<p>```sh
$ wsk action invoke go_test --blocking --result
{</p>

<pre><code>"msg": "Hello, Stranger!"
</code></pre>

<p>}
$ wsk action invoke go_test --blocking --result --param name James
{</p>

<pre><code>"msg": "Hello, James!"
</code></pre>

<p>}
```</p>

<p>Success ðŸ˜Ž.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenWhisk Docker Actions]]></title>
    <link href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/"/>
    <updated>2017-01-16T11:05:00+00:00</updated>
    <id>http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions</id>
    <content type="html"><![CDATA[<p><a href="http://openwhisk.org/">OpenWhisk</a> recently announced the <a href="https://www.ibm.com/blogs/bluemix/2017/01/docker-bluemix-openwhisk/">following changes</a> to Docker-based Actions.</p>

<p>Developers can now deploy runtime files to the Action environment prior to invocation.</p>

<p>This makes it much easier to support (<em>almost</em>) any programming language in OpenWhisk. Awesome!</p>

<p>Let's start by explaining how this new feature works...</p>

<h2>Docker Actions</h2>

<p>Docker Actions in OpenWhisk are <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/Dockerfile">built</a> from the following <a href="https://github.com/openwhisk/openwhisk/tree/master/core/actionProxy">repository</a> using the <a href="https://github.com/docker-library/python/blob/693a75332e8ae5ad3bfae6e8399c4d7cc3cb6181/2.7/alpine/Dockerfile">python:2.7.12-alpine</a> base image. This image is available on Docker Hub as <a href="https://hub.docker.com/r/openwhisk/dockerskeleton/"><code>openwhisk/dockerskeletion</code></a>.</p>

<p>The image includes a Python application which <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py">implements the HTTP API</a> used to handle platform requests, e.g. <em>invoke the action with these parameters</em>.</p>

<p>This service executes a file (<code>/action/exec</code>) for each invocation. Replacing this file allows us to control the runtime environment.</p>

<p>Request parameters are passed, using a JSON string, as the first command-line argument. Response values are interpreted as JSON written to <code>stdout</code>.</p>

<p>Developers can now include a zip file when creating Docker-based Actions. This archive will be extracted into the <code>/action</code> directory prior to invocations. If the archive contains a file named <code>exec</code> this will replace the exectuable file called by the invocation handler.</p>

<h3>Testing It Out</h3>

<p>Using the <code>wsk</code> command-line, developers can create Actions using this Docker image.</p>

<p>If the archive file is missing, the <code>/action/exec</code> path contains the the following <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/stub.sh">stub file</a>.</p>

<p><code>sh
$ wsk action create skeleton --docker openwhisk/dockerskeleton
ok: created action skeleton
$ wsk action invoke skeleton --blocking --result
{ "error": "This is a stub action. Replace it with custom logic." }
</code></p>

<p>Let's update this stub file to return a custom greeting.</p>

<p>``` sh
$ cat exec</p>

<h1>!/bin/bash</h1>

<p>echo "{ \"hello\": \"ran without a docker pull!\" }"
$ ./exec
{ "hello": "ran without a docker pull!" }
$ zip exec.zip exec
  adding: exec (stored 0%)
$ wsk action create custom_docker_action exec.zip --docker
ok: created action custom_docker_action
$ wsk action invoke custom_docker_action --blocking --result
{ "hello": "ran without a docker pull!" }
```</p>

<p>The archive file could include a static binary, or even a complete runtime, to replace the <code>exec</code> stub.</p>

<p>All files in the archive file will be available under the <code>/action</code> directory.</p>

<h2>Running Locally</h2>

<p>The <code>openwhisk/dockerskeleton</code> image exposes a Python-based HTTP server on port 8080.</p>

<p>Pulling the <code>openwhisk/dockerskeleton</code> image from Docker Hub allows us to run it locally for development.</p>

<p><code>sh
$ docker pull openwhisk/dockerskeleton
$ docker run -it -p 8080:8080 openwhisk/dockerskeleton
</code></p>

<p>The platform uses the following HTTP endpoints to initialise and invoke Actions.</p>

<ul>
<li><code>POST /init</code> -> Set up Action source from JSON payload.</li>
<li><code>POST /run</code> -> Invoke Action</li>
</ul>


<h3>Initialising The Environment</h3>

<p>Before invoking Actions using this image, we need to deploy and unpack the archive file into the <code>/action</code> directory.</p>

<p>Reviewing the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py#L47-L80">Python source code</a>, the platform triggers this by sending a HTTP POST with the following JSON to <code>/init</code> endpoint.</p>

<p>``` json
{
  "value": {</p>

<pre><code>"binary": true,
"code": "..."
</code></pre>

<p>  }
}
```</p>

<p><code>code</code> contains the archive file as a base64 encoded string.</p>

<p>Let's try this out using the action archive we created above.</p>

<p>``` sh
$ base64 exec.zip  | echo "\"$(cat)\"" | jq '{value: {binary: true, code: .}}' > init.json
$ cat init.json
{
  "value": {</p>

<pre><code>"binary": true,
"code": "UEsDBAoAAAAAAOlqMEr1+JNAQQAAAEEAAAAEABwAZXhlY1VUCQADRcl8WFDJfFh1eAsAAQT1AQAABBQAAAAjIS9iaW4vYmFzaAplY2hvICJ7IFwiaGVsbG9cIjogXCJyYW4gd2l0aG91dCBhIGRvY2tlciBwdWxsIVwiIH0iClBLAQIeAwoAAAAAAOlqMEr1+JNAQQAAAEEAAAAEABgAAAAAAAEAAADtgQAAAABleGVjVVQFAANFyXxYdXgLAAEE9QEAAAQUAAAAUEsFBgAAAAABAAEASgAAAH8AAAAAAA=="
</code></pre>

<p>  }
}
```</p>

<p>Now we can issue the HTTP request to push this archive into the container.</p>

<p>``` sh
$ http post localhost:8080/init &lt; init.json
HTTP/1.1 200 OK
Content-Length: 2
Content-Type: text/html; charset=utf-8
Date: Mon, 16 Jan 2017 14:11:04 GMT</p>

<p>OK
```</p>

<p>Accessing the container filesystem allows us to verify the archive has been extracted correctly.</p>

<p>``` sh
$ docker ps
CONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS              PORTS                    NAMES
b37a7dc1cab1        openwhisk/dockerskeleton      "/bin/bash -c 'cd ..."   About an hour ago   Up About an hour    0.0.0.0:8080->8080/tcp   relaxed_davinci
$ docker exec -it b37a7dc1cab1 /bin/sh
/ # cd /action
/action # ls
exec
/action # cat exec</p>

<h1>!/bin/bash</h1>

<p>echo "{ \"hello\": \"ran without a docker pull!\" }"
```</p>

<h3>Invocation Requests</h3>

<p>Action invocations are triggered by sending a HTTP POST to the <code>/run</code> endpoint.</p>

<p>This endpoint expects the following JSON body.</p>

<p>```
{
  "value": {</p>

<pre><code>"foo": "bar"
</code></pre>

<p>  }
}
```</p>

<p>The inner object parameters under the <code>value</code> property are passed, as a JSON string, to the executable as the first command-line argument.</p>

<p>Sending this request to our container will trigger the shell script from our archive and return the JSON response.</p>

<p>``` sh
$ echo "{}" | jq '{value: .}' | http post localhost:8080/run
HTTP/1.1 200 OK
Content-Length: 44
Content-Type: application/json
Date: Mon, 16 Jan 2017 14:17:15 GMT</p>

<p>{</p>

<pre><code>"hello": "ran without a docker pull!"
</code></pre>

<p>}
```</p>

<h2>Conclusion</h2>

<p>Recent updates to Docker-based Actions in OpenWhisk make it much easier to customise the runtime environment.</p>

<p>Being able to deploy arbitrary files into the runtime container, prior to invocation, simplifies the process of supporting new runtimes.</p>

<p>Hopefully this blog post has shown you how to get started with this feature.</p>

<p>Over the next few weeks, we're going to show you how to use this approach to run lots of new programming languages on the platform. Stay tuned for updates...</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NPM Modules in OpenWhisk]]></title>
    <link href="http://jamesthom.as/blog/2016/11/28/npm-modules-in-openwhisk/"/>
    <updated>2016-11-28T14:03:00+00:00</updated>
    <id>http://jamesthom.as/blog/2016/11/28/npm-modules-in-openwhisk</id>
    <content type="html"><![CDATA[<p>OpenWhisk now <a href="https://github.com/openwhisk/openwhisk/blob/master/docs/actions.md#packaging-an-action-as-a-nodejs-module">supports creating Node.js Actions from a zip file</a>. The archive file will be extracted into the runtime environment by the platform. This allows us to split microservice logic across multiple files, use third-party <a href="https://www.npmjs.com/">NPM modules</a> or include non-JavaScript assets (configuration files, images, HTML files).</p>

<h2>"Hello World" Example</h2>

<p>Let's look at a "Hello World" example of registering a serverless function from a zip file. Our archive will contain two files, the <a href="https://docs.npmjs.com/files/package.json">package descriptor</a> and a JavaScript file.</p>

<p>Here is the minimal <code>package.json</code> file required for loading a module from a directory.</p>

<p><code>json package.json
{
  "main": "my_file.js"
}
</code></p>

<p>In <code>my_file.js</code>, a function is returned through the <code>main</code> property on the <code>exports</code> object. This function <a href="https://github.com/openwhisk/openwhisk/blob/master/docs/actions.md#creating-and-invoking-javascript-actions">implements the Action interface.</a></p>

<p><code>javascript my_file.js
exports.main = function (params) {
  return {result: "Hello World"};
};
</code></p>

<p>Creating a zip file from the current directory, we can deploy this Action through the command-line utility.</p>

<p><code>sh
$ zip -r action.zip *
$ wsk action create hello_world --kind nodejs:default action.zip
</code></p>

<p>When this Action is invoked, the archive will be unzipped into a temporary directory. OpenWhisk loads the directory as a Node.js module and invokes the function property on the module for each invocation.</p>

<p>``` sh
$ wsk action invoke hello_world --result
{</p>

<pre><code>"result": "Hello world"
</code></pre>

<p>}
```</p>

<h2>Using NPM Dependencies</h2>

<p>Let's look a more complicated example which uses an external <a href="https://www.npmjs.com/">NPM module</a> in our Action.</p>

<p>``` javascript index.js
const leftPad = require("left-pad")</p>

<p>function myAction(args) {</p>

<pre><code>const lines = args.lines || [];
return { padded: lines.map(l =&gt; leftPad(l, 30, ".")) }
</code></pre>

<p>}</p>

<p>exports.main = myAction;
```</p>

<p>This module uses the <a href="http://qz.com/646467/how-one-programmer-broke-the-internet-by-deleting-a-tiny-piece-of-code/">extremely popular</a> <a href="https://www.npmjs.com/package/left-pad">left-pad</a> module to process an array of strings, passed through a request parameter. The resulting output is returned in the response.</p>

<p>Before using this module, we need to install the dependencies listed in <code>package.json</code>.</p>

<p>``` json
{
  "name": "my-action",
  "version": "1.0.0",
  "main": "index.js",
  "dependencies" : {</p>

<pre><code>"left-pad" : "1.1.3"
</code></pre>

<p>  }
}
```</p>

<p><strong>OpenWhisk does not automatically install dependencies listed in <code>package.json</code> in the runtime environment.</strong></p>

<p>The developer has to run <code>npm install</code> locally and include the <code>node_modules</code> directory in the zip file.</p>

<ul>
<li>Install NPM dependencies locally.</li>
</ul>


<p><code>sh
$ npm install
</code></p>

<ul>
<li>Create a <code>.zip</code> archive containing all files.</li>
</ul>


<p><code>sh
$ zip -r action.zip *
</code></p>

<ul>
<li>Create the action using command-line utility.</li>
</ul>


<p><code>sh
$ wsk action create packageAction --kind nodejs:default action.zip
</code></p>

<p>Now we can test out our action to check it worksâ€¦.</p>

<p>``` sh
$ wsk action invoke --blocking --result packageAction --param lines "[\"and now\", \"for something completely\", \"different\" ]"
{</p>

<pre><code>"padded": [
    ".......................and now",
    "......for something completely",
    ".....................different"
]
</code></pre>

<p>}
```</p>

<h2>Native Module Dependencies</h2>

<p>Node.js provides a mechanism for JavaScript modules to <a href="https://nodejs.org/api/addons.html">include native platform code</a> as if they were ordinary modules. This is often used to improve performance by deferring operations to native C/C++ libraries. NPM handles compiling native code during the dependency install process.</p>

<p><strong>Using modules with native dependencies in Actions requires the native code to be compiled for the platform runtime.</strong></p>

<h3>Compiling dependencies with Docker</h3>

<p>One solution to this problem uses Docker to simulate the same runtime environment.</p>

<p>OpenWhisk uses Docker to manage the runtime environments for Actions. The <a href="https://github.com/docker-library/buildpack-deps/blob/af914a5bde2a749884177393c8140384048dc5f9/trusty/curl/Dockerfile"><em>buildpack-deps:trusty-curl</em></a> image is used as the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/nodejsActionBase/Dockerfile">base image for all Node.js Actions</a>.</p>

<p>Running a local container from this image will give access to the same runtime environment. Running <code>npm install</code> within this container will produce the <code>node_modules</code> directory with native code compiled for the correct architecture.</p>

<h3>Action With Native Modules</h3>

<p>Let's look at an exampleâ€¦</p>

<p>``` javascript index.js
const SHA3 = require('sha3');</p>

<p>function SHA(args) {
  const d = new SHA3.SHA3Hash();
  d.update(args.payload);
  return { sha: d.digest('hex') };
}</p>

<p>exports.main = SHA;
```</p>

<p>This module returns a function that calculates a SHA3 cryptographic hash for the invocation payload. The hex string for the hash is returned as the function response.</p>

<p>The NPM module (<a href="https://www.npmjs.com/package/sha3">sha3</a>) used to calculate the digest uses a C++ extension for the hashing algorithm.</p>

<p>``` json package.json
{
  "name": "hashing-service",
  "version": "1.0.0",
  "main": "index.js",
  "dependencies": {</p>

<pre><code>"sha3": "^1.2.0"
</code></pre>

<p>  }
}
```</p>

<h3>Action Runtime Environments</h3>

<p>OpenWhisk uses a <a href="https://github.com/docker-library/buildpack-deps/blob/af914a5bde2a749884177393c8140384048dc5f9/trusty/curl/Dockerfile">public Docker image</a> as the base image for the Action environments. It then <a href="https://github.com/openwhisk/openwhisk/blob/master/core/nodejs6Action/Dockerfile">builds a custom image</a> by installing Node.js and NPM for the particular runtime version.</p>

<p>Rather than building this image ourselves, we can use existing images published on <a href="https://hub.docker.com/">Docker Hub</a>.</p>

<p><a href="https://nodesource.com/">NodeSource</a> provides <a href="https://hub.docker.com/u/nodesource/">public Docker images pre-installed with different Node.js versions</a>. Provided the base image (Ubuntu Trusty) and Node.js version (6.7) matches, the runtime environment will be the same.</p>

<p>Starting a local container from this image, we can use Docker's <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">host volume support</a> to mount the local directory into the host container.</p>

<p><code>sh
$ docker run -it -v "/action:/usr/src/app" nodesource/trusty:6.7 /bin/sh
</code></p>

<p>Running <code>npm install</code> in the container, the <code>sha3</code> dependency is compiled and installed.</p>

<p>``` sh</p>

<h1>npm install</h1>

<blockquote><p>sha3@1.2.0 install /usr/src/app/node_modules/sha3                                                                 <br/>
node-gyp rebuild</p></blockquote>

<p>make: Entering directory <code>/usr/src/app/node_modules/sha3/build'                                                       
make: Warning: File</code>sha3.target.mk' has modification time 0.19 s in the future                                     <br/>
  CXX(target) Release/obj.target/sha3/src/addon.o                                                                   <br/>
  CXX(target) Release/obj.target/sha3/src/displayIntermediateValues.o                                               <br/>
  CXX(target) Release/obj.target/sha3/src/KeccakF-1600-reference.o                                                  <br/>
  CXX(target) Release/obj.target/sha3/src/KeccakNISTInterface.o                                                     <br/>
  CXX(target) Release/obj.target/sha3/src/KeccakSponge.o                                                            <br/>
  SOLINK_MODULE(target) Release/obj.target/sha3.node                                                                <br/>
  COPY Release/sha3.node                                                                                            <br/>
make: warning:  Clock skew detected.  Your build may be incomplete.                                                 <br/>
make: Leaving directory <code>/usr/src/app/node_modules/sha3/build'                                                        
my-action@1.0.0 /usr/src/app                                                                                          
</code>-- sha3@1.2.0                                                                                                      <br/>
  `-- nan@2.4.0</p>

<p>```</p>

<p>The <code>node_modules</code> directory will be available on the host system after exiting the container. Repeat the steps above to archive the source files and deploy our serverless function.</p>

<p><code>sh
$ zip -r action.zip *
$ wsk action create packageAction --kind nodejs:6 action.zip  
ok: created action packageAction          
</code></p>

<p>Invoking the Action will now use the native code to produce hash values for the invocation parameters.</p>

<p>``` sh
$ wsk action invoke packageAction -b -p payload "Hello" --result                            <br/>
{</p>

<pre><code>"sha": "c33fede18a1ae53ddb8663710f8054866beb714044fce759790459996196f101d94dfc7bd8268577f7ee3d2f8ff0cef4004a963222
</code></pre>

<p>7db84df62d2b40682d69e2"                                                                                             <br/>
}                     <br/>
```</p>

<h2>Action Package Details</h2>

<p>Upon invocation, OpenWhisk extracts the action's zip file to a temporary directory in the runtime environment. It then <a href="https://nodejs.org/api/modules.html#modules_all_together">loads the directory as a standard Node.js module</a>, using <code>require</code>.</p>

<p>Node.js expects the directory to have a valid <code>package.json</code> file. The <code>main</code> property is used to define which JavaScript file is evaluated when the module is loaded. This file can assign values to the global <code>exports</code> object. These references are then returned when <code>require</code> is called for this module.</p>

<p><strong>OpenWhisk expects the returned module object to have a property called <code>main</code> which references a function. This function will be executed for each invocation request.</strong></p>

<p>Request parameters are passed as object properties on the first function argument. The function must return an object for the invocation response.</p>

<p>Other files included in the archive will be available in the current working directory. These can also be loaded as modules or read directly from the file-system.</p>

<h2>Conclusions</h2>

<p>OpenWhisk support for Action packages is a huge step forward for the platform. Node.js has an enormous ecosystem of third-party modules. Developers can now easily use any of these modules within their Actions.</p>

<p>This feature can also be used to include non-JS files within the runtime environment. It would be possible to use configuration files in JSON or static assets like HTML or CSS files.</p>

<p><strong><em>The team are now working on providing support for other runtimes, watch this spaceâ€¦</em></strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Serverless Logs With Elasticsearch]]></title>
    <link href="http://jamesthom.as/blog/2016/10/31/serverless-logs-with-elasticsearch/"/>
    <updated>2016-10-31T10:39:00+00:00</updated>
    <id>http://jamesthom.as/blog/2016/10/31/serverless-logs-with-elasticsearch</id>
    <content type="html"><![CDATA[<p><a href="http://martinfowler.com/articles/serverless.html">Serverless platforms</a> can seem like magic.</p>

<p>Taking your code and turning it into scalable microservices in the cloud without having to set up or manage any infrastructure.</p>

<p><em>No provisioning VMs. No configuring Linux environments. No upgrading middleware packages.</em></p>

<p>Which is wonderful until something goes wrong with your microservices in productionâ€¦</p>

<p><em>"Let me just log into the machine."</em></p>

<p><strong>Serverless platforms do not allow this.</strong></p>

<p><em>No tracing system calls. No running top. No connecting a debugger to the process. You can't even grep through the logs!</em></p>

<p>Many of the tools and techniques we use to diagnose bugs rely on having access to the environment.</p>

<p><em>Fortunately, we do still have access to logging output generated by our serverless functions. Phew.</em></p>

<p><strong>Storing, searching and analysing these logs is crucial to efficiently diagnosing and fixing issues on serverless platforms.</strong></p>

<p>In this blog post, we're going to look at using a popular open-source solution to manage the logs being generated by our serverless functions. This solution is also known as "<a href="https://www.oreilly.com/ideas/understanding-the-elk-stack">The ELK Stack</a>".</p>

<p><strong><em>TLDR: There is now a Logstash input plugin for OpenWhisk. This will automatically index serverless application logs into Elasticsearch. See here for usage instructions: <a href="https://github.com/jthomas/logstash-input-openwhisk">https://github.com/jthomas/logstash-input-openwhisk</a></em></strong></p>

<h2>Elasticsearch, Logstash and Kibana</h2>

<p>â€¦are the three open-source projects that, when combined, are known as The ELK Stack. It provides a scalable search engine for indexed documents.</p>

<p><a href="https://github.com/elastic/elasticsearch">Elasticsearch</a> <em>"is a search engine based on Lucene. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents."</em></p>

<p><a href="https://github.com/elastic/logstash">Logstash</a> is a tool for managing events and logs. You can use it to collect logs, parse them, and store them for later use (like, for searching). If you store them in Elasticsearch, you can view and analyze them with Kibana.</p>

<p><a href="https://github.com/elastic/kibana">Kibana</a> is an open source analytics and visualization platform designed to work with Elasticsearch. You use Kibana to search, view, and interact with data stored in Elasticsearch.</p>

<p>The ELK Stack is a perfect solution for managing logs from our serverless functions.</p>

<p><strong>But how do we configure this solution to automatically index logs from our serverless platform?</strong></p>

<p><em>Let's start by looking serverless platform we are usingâ€¦</em></p>

<h2>OpenWhisk</h2>

<p><a href="https://github.com/openwhisk/openwhisk">OpenWhisk</a> is an open-source serverless platform developed by IBM. Developers <a href="https://github.com/openwhisk/openwhisk/blob/master/docs/actions.md">deploy functions</a> to execute in response to <a href="https://github.com/openwhisk/openwhisk/blob/master/docs/triggers_rules.md">external events</a>, e.g. database updates, messages on a queue or HTTP requests. The platform invokes these functions on-demand in milliseconds, rather than having services sat idle waiting for requests to arrive.</p>

<p><em>Let's walk through an example.</em></p>

<h3>Serverless Functions</h3>

<p>Here's a sample serverless function which returns a greeting to the user. The code logs the invocation parameters and response message.</p>

<p>``` javascript logs.js
function main (params) {
  console.log('invoked with parameters:', params)</p>

<p>  const user = params.user || 'Donald Trump'
  const response = { greeting: <code>Hello ${user}</code> }</p>

<p>  console.log('returns: ', response)
  return response
}
```</p>

<p>Deploying this serverless function to OpenWhisk and invoking it generates an activation record.</p>

<p>``` sh
$ wsk action create logs logs.js
ok: created action logs
$ wsk action invoke logs -b -r -p user 'Bernie Sanders'
{</p>

<pre><code>"greeting": "Hello Bernie Sanders"
</code></pre>

<p>}
$ wsk activation list
activations
2adbbbcc0242457f80dc51944dcd2039                 logs
...
```</p>

<p>OpenWhisk activation records are available through the <a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/openwhisk/openwhisk/master/core/controller/src/main/resources/whiskswagger.json">platform API</a>. Each record contains the stdout and stderr logs generated during the serverless function invocation.</p>

<h3>Serverless Logs</h3>

<p>Retrieving the activation record for the previous invocation, we can see the output generated by the calls to <code>console.log</code>.</p>

<p>``` sh
$ wsk activation get 2adbbbcc0242457f80dc51944dcd2039
ok: got activation 2adbbbcc0242457f80dc51944dcd2039
{</p>

<pre><code>"namespace": "james.thomas@uk.ibm.com",
"name": "logs",
"version": "0.0.3",
"publish": false,
"subject": "james.thomas@uk.ibm.com",
"activationId": "2adbbbcc0242457f80dc51944dcd2039",
"start": 1477925373990,
"end": 1477925374063,
"response": {
    "status": "success",
    "statusCode": 0,
    "success": true,
    "result": {
        "greeting": "Hello Bernie Sanders"
    }
},
"logs": [
    "2016-10-31T14:49:34.059745626Z stdout: invoked with parameters: {}",
    "2016-10-31T14:49:34.061228724Z stdout: returns:  { greeting: 'Hello Donald Trump' }"
],
...
</code></pre>

<p>}
```</p>

<p>OpenWhisk stores these records indefinitely, making them available for <a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/openwhisk/openwhisk/master/core/controller/src/main/resources/whiskswagger.json#!/Activations/getActivationById">retrieval by the activation id</a>.</p>

<p>However, developers need more than being able to retrieve logs to be effective at diagnosing and resolving issues with serverless functions.</p>

<p>Forwarding these logs to Elasticsearch will enable us to run full-text search across all logs generated, quickly retrieve all output for a particular serverless function, set up monitoring dashboards and much moreâ€¦</p>

<p>Using Logstash will allow us to ingest and transform OpenWhisk logs into Elasticsearch documents.</p>

<h2>Logstash Input Plugins</h2>

<p>Logstash supports a huge variety of event sources through the use of a <a href="https://www.elastic.co/guide/en/logstash/current/working-with-plugins.html">plugin mechanism</a>. These plugins handle retrieving the external events and converting them to Elasticsearch documents.</p>

<p>Logstash has a huge repository of <a href="https://www.elastic.co/guide/en/logstash/current/input-plugins.html">official and community supported input plugins</a>. These plugins ingest everything from log files, syslog streams, databases, message queues, websockets and much more.</p>

<h3>HTTP Polling Input Plugin</h3>

<p>Logstash already has an input plugin for <a href="https://github.com/logstash-plugins/logstash-input-http_poller">pulling events from a HTTP URL by polling</a>. Users provide the URL in the logstash configuration, along with the polling schedule. Logstash will automatically retrieve and ingest the JSON response as an event stream.</p>

<p>```
input {
  http_poller {</p>

<pre><code>urls =&gt; {
  "my_events" =&gt; "http://localhost:8000/events"
}
# Poll site every 10s
interval =&gt; 10
request_timeout =&gt; 60
codec =&gt; "json"
</code></pre>

<p>  }
}
```</p>

<p><em>Great, so we can configure this plugin to call OpenWhisk API for retrieving activation records and automatically ingest them into Elasticsearch?</em></p>

<p>Unfortunately not...</p>

<h3>Polling OpenWhisk Logs?</h3>

<p>Each time the client calls the API to retrieve the activation records, we want to retrieve only those records that have occurred since the last poll. This ensures we are not ingesting the same records more than once.</p>

<p>The <a href="http://petstore.swagger.io/?url=https://raw.githubusercontent.com/openwhisk/openwhisk/master/core/controller/src/main/resources/whiskswagger.json#!/Activations/getActivations">OpenWhisk API for retrieving activation records</a> supports a query parameter (<code>since</code>) which restricts results to those that occurred after the parameter value's timestamp.</p>

<p>Using this parameter in the polling URL, updated to the value of the last polling time, will allow us to ensure we only retrieve new activation records.</p>

<p><strong>Unfortunately, the HTTP input plugin does not support setting dynamic query string parameters.</strong></p>

<p>This means we cannot use the existing plugin to efficiently ingest OpenWhisk logs into Elasticsearch.</p>

<p><em>So we started work on a new plugin to support this behaviourâ€¦</em></p>

<h3>OpenWhisk Input Plugin</h3>

<p>This <a href="https://github.com/jthomas/logstash-input-openwhisk">input plugin</a> drains logs from OpenWhisk into Elasticsearch.</p>

<p>Install the plugin with the following command.</p>

<p><code>sh
$ bin/logstash-plugin install logstash-input-openwhisk
</code></p>

<p>Once the plugin is installed, you need to configure Logstash with your platform endpoint and user credentials.</p>

<p>This sample configuration will poll the OpenWhisk platform for new logs every fifteen minutes and index them into Elasticsearch. Each activation record will be a separate document.</p>

<p>```
input {
  openwhisk {</p>

<pre><code># Mandatory Configuration Parameters
hostname =&gt; "openwhisk.ng.bluemix.net"
username =&gt; "sample_user@email.com"
password =&gt; "some_password"
# Supports "cron", "every", "at" and "in" schedules by rufus scheduler
schedule =&gt; { "every" =&gt; "15m"}
</code></pre>

<p>  }
}</p>

<p>output {
  elasticsearch {</p>

<pre><code>hosts =&gt; ["localhost:9200"]
</code></pre>

<p>  }
}
```</p>

<p>The plugin supports the same configuration values for the <code>schedule</code> parameter as the <a href="https://github.com/logstash-plugins/logstash-input-http_poller">HTTP input plugin</a>.</p>

<p>More examples of using the plugin are available in the <a href="https://github.com/jthomas/logstash-input-openwhisk/tree/master/examples">examples</a> directory in the project repository.</p>

<h2>Demonstration</h2>

<p>Here's a demonstration of the OpenWhisk input plugin being used in the ELK stack. As we invoke serverless functions in OpenWhisk, Kibana shows the activation records appearing in the dashboard. Logstash is polling the logs API and ingesting the records into Elasticsearch in real-time.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/9gNyrW58EqE" frameborder="0" allowfullscreen></iframe>


<h2>Conclusion</h2>

<p>Developers using serverless platforms have no access to the infrastructure environment running their code. Debugging production bugs relies on using logging output to diagnose and resolve issues.</p>

<p>Elasticsearch, Logstash and Kibana has become the scalable open-source solution for log management and analysis.</p>

<p>Using the <a href="https://github.com/jthomas/logstash-input-openwhisk">Logstash plugin for OpenWhisk</a>, serverless logs will be automatically indexed into Elasticsearch in real-time. Developers can use the Kibana frontend to easily diagnose and monitor issues in production.</p>

<p>In the next post, we'll look at using Docker to set up Elasticsearch, Logstash and Kibana with our custom OpenWhisk plugin.</p>

<p>Until then... ðŸ˜Ž</p>
]]></content>
  </entry>
  
</feed>
