<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: docker | James Thomas]]></title>
  <link href="http://jthomas.github.com/jthomas/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://jthomas.github.com/jthomas/"/>
  <updated>2018-01-11T16:17:08+00:00</updated>
  <id>http://jthomas.github.com/jthomas/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OpenWhisk and Rust]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2017/01/18/openwhisk-and-rust/"/>
    <updated>2017-01-18T09:00:00+00:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2017/01/18/openwhisk-and-rust</id>
    <content type="html"><![CDATA[<p><em>This blog post is <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">one of</a> <a href="http://jamesthom.as/blog/2017/01/17/openwhisk-and-go/">a series</a> looking at using Docker Actions in OpenWhisk to support extra runtimes.</em></p>

<p>Let's look at writing serverless functions for <a href="http://openwhisk.org/">OpenWhisk</a> using <a href="https://rust-lang.org">Rust</a>.</p>

<p><blockquote><p>Rust is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety.</p></blockquote></p>

<p>Rust has been growing in popularity since it launched in 2010. Rust is a popular language for writing microservices due to the focus on the attention to safety and strong concurrency support.</p>

<p>None of the major serverless platform natively support Rust at the moment. OpenWhisk does not include this as a default runtime. However, <a href="https://www.ibm.com/blogs/bluemix/2017/01/docker-bluemix-openwhisk/">recent updates</a> to OpenWhisk provide a path for writing serverless functions with Rust.</p>

<p>Let's re-write <a href="http://jamesthom.as/blog/2017/01/17/openwhisk-and-go/">the example</a> from the previous post in Rust and see how to get it running using this new approachâ€¦</p>

<p><strong><em>Have you seen <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">this post</a> explaining how Docker-based Actions work? This post assumes you have already read that first.</em></strong></p>

<h2>Rust Language Actions</h2>

<p>Rust has a <a href="http://doc.crates.io/guide.html">build system</a> that supports creating static binaries. These binaries contain the application source code and dependent libraries.</p>

<p>Using the same approach as the <a href="http://jamesthom.as/blog/2017/01/17/openwhisk-and-go/">Go-based example</a>, bundling this binary into a zip file allows us to overwrite the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/stub.sh">runtime stub</a> prior to invocation.</p>

<p>Runtime binaries will be executed by the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py">Python-based invoker</a> for each invocation. Request parameters will be passed as a JSON string using the first command-line argument. The invoker expects the Action result to be written to standard output as a JSON string.</p>

<h3>Action Source Code</h3>

<p>Here's a simple Rust function that returns a greeting string from an input parameter. It parses the JSON string provided on the command-line to look for a <code>name</code> parameter. If this isn't present, it defaults to <code>stranger</code>. It returns a JSON object with the greeting string (<code>msg</code>) by writing to the console.</p>

<p>``` rust
extern crate rustc_serialize;
use rustc_serialize::json;
use rustc_serialize::json::Json;
use std::env;</p>

<h1>[derive(RustcDecodable, RustcEncodable)]</h1>

<p>pub struct Greeting {</p>

<pre><code>message: String
</code></pre>

<p>}</p>

<p>fn main() {</p>

<pre><code>let mut name = "stranger".to_string();

// first arg contains JSON parameters
if let Some(arg1) = env::args().nth(1) {
    // parse JSON and extract 'name' field
    let params = Json::from_str(&amp;arg1).unwrap();
    if let Some(params_obj) = params.as_object() {
        if let Some(params_name) = params_obj.get("name") {
            name = params_name.as_string().unwrap().to_string();
        }
    }
};

let greeting = Greeting {
    message: format!("Hello, {}!", name),
};

println!("{}", json::encode(&amp;greeting).unwrap());
</code></pre>

<p>}
```</p>

<h3>Set Up Project</h3>

<p>Using Rust's package management tool, create a new project for our serverless function.</p>

<p>Add the source code above into the <code>src/main.rs</code> file.</p>

<p>```sh
$ cargo new action; cd action</p>

<pre><code> Created library `action` project
</code></pre>

<p>$ mv src/lib.rs src/main.rs
$ vim src/main.rs
$ tree .
.
â”œâ”€â”€ Cargo.toml
â””â”€â”€ src</p>

<pre><code>â””â”€â”€ main.rs
</code></pre>

<p>1 directory, 2 files
```</p>

<p>This function uses the <code>rustc-serialize</code> crate to handle parsing and producing JSON.</p>

<p>Add this identifier to the project's dependencies listed in <code>Cargo.toml</code>.</p>

<p>``` sh
[package]
name = "action"
version = "0.1.0"
authors = ["Me <a href="&#109;&#x61;&#x69;&#x6c;&#116;&#111;&#x3a;&#x6d;&#101;&#64;&#x65;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#x6f;&#109;">&#109;&#101;&#x40;&#x65;&#109;&#97;&#x69;&#x6c;&#46;&#99;&#111;&#109;</a>"]</p>

<p>[dependencies]
rustc-serialize = "0.3"
```</p>

<p>Build and run the binary to test it works as expected.</p>

<p>```go
$ cargo run</p>

<pre><code>Updating registry `https://github.com/rust-lang/crates.io-index`
</code></pre>

<p>   Compiling rustc-serialize v0.3.22
   Compiling action v0.1.0 (file:///private/tmp/test/action)</p>

<pre><code>Finished debug [unoptimized + debuginfo] target(s) in 7.0 secs
 Running `target/debug/action`
</code></pre>

<p>{"message":"Hello, stranger!"}
$ cargo run '{"name": "James"}'</p>

<pre><code>Finished debug [unoptimized + debuginfo] target(s) in 0.0 secs
 Running `target/debug/action {\"name\":\ \"James\"}`
</code></pre>

<p>{"message":"Hello, James!"}
```</p>

<p><em>Before we can deploy this binary to OpenWhisk, it must be compiled for the platform architecture.</em></p>

<h3>Cross-Compiling Locally</h3>

<p>Rust's compiler uses LLVM under the covers, making it possible to generate machine code for different architectures. Cross-compiling for different platforms requires having the correct compiler, linker and libraries for that architecture installed.</p>

<p>Rust <a href="https://blog.rust-lang.org/2016/05/13/rustup.html">recently released</a> a <a href="https://rustup.rs/">toolchain manager</a> to simplify this process.</p>

<p>Install the Rust toolchain for the <code>x86_64-unknown-linux-musl</code> runtime.</p>

<p><code>sh
$ rustup target add x86_64-unknown-linux-musl
info: downloading component 'rust-std' for 'x86_64-unknown-linux-musl'
info: installing component 'rust-std' for 'x86_64-unknown-linux-musl'
</code></p>

<p>Add the configuration file to set the correct linker for the runtime.</p>

<p><code>sh
$ cat .cargo/config
[target.x86_64-unknown-linux-musl]
linker = "x86_64-linux-musl-gcc"
</code></p>

<p>We can now cross-compile the binary for the correct environment.</p>

<p>``` sh
$ cargo build --target=x86_64-unknown-linux-musl --release
   Compiling rustc-serialize v0.3.22
   Compiling action v0.1.0 (file:///Users/james/code/bluemix/openwhisk-languages/rust/action)</p>

<pre><code>Finished release [optimized] target(s) in 9.30 secs
</code></pre>

<p>```</p>

<p>Checking the file type demonstrates we have built a static binary for the Linux x86_64 platform.</p>

<p><code>sh
$ file target/x86_64-unknown-linux-musl/release/action
target/x86_64-unknown-linux-musl/release/action: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, not stripped
</code></p>

<h3>Cross-Compiling Using Docker</h3>

<p>If you don't want to install the Rust development toolchain, Docker can be used to start a container with the <a href="https://github.com/emk/rust-musl-builder">environment set up</a>.</p>

<p>```sh
$ docker pull ekidd/rust-musl-builder
$ docker run -it -v $(pwd):/home/rust/src ekidd/rust-musl-builder cargo build --release</p>

<pre><code>Updating registry `https://github.com/rust-lang/crates.io-index`
</code></pre>

<p> Downloading rustc-serialize v0.3.22
   Compiling action v0.1.0 (file:///home/rust/src)</p>

<pre><code>Finished release [optimized] target(s) in 1.80 secs
</code></pre>

<p>$ file target/x86_64-unknown-linux-musl/release/action
target/x86_64-unknown-linux-musl/release/action: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), statically linked, not stripped
```</p>

<h3>Create &amp; Deploy Archive</h3>

<p>Add the binary to a zip file, ensuring the file is named <code>exec</code> in the archive.</p>

<p>Use the <code>wsk</code> command-line to create a new Docker Action using this archive.</p>

<p><code>sh
$ cp target/x86_64-unknown-linux-musl/release/action exec
$ zip action.zip exec
  adding: exec (deflated 64%)
$ wsk action create rust_test action.zip --docker
ok: created action rust_test
</code></p>

<h3>Invoking Action</h3>

<p>Test the action from the command-line to verify it works.</p>

<p>```sh
$ wsk action invoke rust_test --blocking --result
{</p>

<pre><code>"msg": "Hello, Stranger!"
</code></pre>

<p>}
$ wsk action invoke rust_test --blocking --result --param name James
{</p>

<pre><code>"msg": "Hello, James!"
</code></pre>

<p>}
```</p>

<p>Success ðŸ˜Ž.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Openwhisk and Go]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2017/01/17/openwhisk-and-go/"/>
    <updated>2017-01-17T09:00:00+00:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2017/01/17/openwhisk-and-go</id>
    <content type="html"><![CDATA[<p><a href="http://jamesthom.as/blog/2016/06/21/serverless-go-actions/">In an earlier blog post</a>, I explained how to use Go language binaries on OpenWhisk using Docker-based Actions. It relied on building Docker images for each serverless function and hosting them on Docker Hub.</p>

<p><a href="https://www.ibm.com/blogs/bluemix/2017/01/docker-bluemix-openwhisk/">Recent updates</a>  to Docker-based Actions have made this process much simpler. Developers don't need to build and expose public images anymore.</p>

<p>Let's re-visit the example from the previous post and see how to get it running using this new approachâ€¦</p>

<p><strong><em>Have you seen <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">this post</a> explaining how Docker-based Actions work? This post assumes you have already read that first.</em></strong></p>

<h2>Go Language Actions</h2>

<p>Go's <a href="https://golang.org/pkg/go/build/">build system</a> combines application source code and dependencies into a single execution binary. Bundling this binary into a zip file allows us to overwrite the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/stub.sh">runtime stub</a> prior to invocation.</p>

<p>Runtime binaries will be executed by the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py">Python-based invoker</a> for each invocation. Request parameters will be passed as a JSON string using the first command-line argument. The invoker expects the Action result to be written to standard output as a JSON string.</p>

<h3>Action Source Code</h3>

<p>Here's a simple Go function that returns a greeting string from an input parameter. It parses the JSON string provided on the command-line to look for a <code>name</code> parameter. If this isn't present, it defaults to <code>Stranger</code>. It returns a JSON object with the greeting string (<code>msg</code>) by writing to the console.</p>

<p>``` go
package main</p>

<p>import "encoding/json"
import "fmt"
import "os"</p>

<p>func main() {</p>

<pre><code>// native actions receive one argument, the JSON object as a string
arg := os.Args[1]

// unmarshal the string to a JSON object
var obj map[string]interface{}
json.Unmarshal([]byte(arg), &amp;obj)
name, ok := obj["name"].(string)
if !ok {
    name = "Stranger"
}
msg := map[string]string{"msg": ("Hello, " + name + "!")}
res, _ := json.Marshal(msg)
fmt.Println(string(res))
</code></pre>

<p>}
```</p>

<p>Building this locally allows us to test it works.</p>

<p><code>go
$ go run test.go '{"name": "James"}'
{"msg":"Hello, James!"}
</code></p>

<p><em>Before we can deploy this binary to OpenWhisk, it must be compiled for the platform architecture.</em></p>

<h3>Cross-Compiling Locally</h3>

<p>Go 1.5 <a href="https://dave.cheney.net/2015/08/22/cross-compilation-with-go-1-5">introduced much improved</a> support for cross-compilation.</p>

<p>If you have the development environment installed locally, you can compile the binary for another platform by setting environment variables. The full list of supported architectures is available <a href="https://golang.org/doc/install/source#environment">here</a>.</p>

<p><em>OpenWhisk uses an <a href="https://hub.docker.com/_/alpine/">Alpine Linux-based</a> environment to execute Actions.</em></p>

<p><code>sh
$ env GOOS=linux GOARCH=amd64 go build exec.go
</code></p>

<p>Checking the file type demonstrates we have built a static binary for the Linux x86_64 platform.</p>

<p><code>sh
$ file exec
exec: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped
</code></p>

<h3>Cross-Compiling Using Docker</h3>

<p>If you don't want to install the Go development toolchain, Docker can be used to start a container with the environment set up.</p>

<p><code>sh
$ docker pull golang
$ docker run -it -v $(pwd):/go/src golang
root@0a2f1655eece:/go# cd src/
root@0a2f1655eece:/go/src# go build exec.go
root@0a2f1655eece:/go/src# ls
exec  exec.go
$ file exec
exec: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped
</code></p>

<h3>Create &amp; Deploy Archive</h3>

<p>Add the binary to a zip file, ensuring the file is named <code>exec</code> in the archive.</p>

<p>Use the <code>wsk</code> command-line to create a new Docker Action using this archive.</p>

<p><code>sh
$ zip action.zip exec
  adding: exec (deflated 66%)
$ wsk action create go_test action.zip --docker
ok: created action go_test
</code></p>

<h3>Invoking Action</h3>

<p>Test the action from the command-line to verify it works.</p>

<p>```sh
$ wsk action invoke go_test --blocking --result
{</p>

<pre><code>"msg": "Hello, Stranger!"
</code></pre>

<p>}
$ wsk action invoke go_test --blocking --result --param name James
{</p>

<pre><code>"msg": "Hello, James!"
</code></pre>

<p>}
```</p>

<p>Success ðŸ˜Ž.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenWhisk Docker Actions]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2017/01/16/openwhisk-docker-actions/"/>
    <updated>2017-01-16T11:05:00+00:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2017/01/16/openwhisk-docker-actions</id>
    <content type="html"><![CDATA[<p><a href="http://openwhisk.org/">OpenWhisk</a> recently announced the <a href="https://www.ibm.com/blogs/bluemix/2017/01/docker-bluemix-openwhisk/">following changes</a> to Docker-based Actions.</p>

<p>Developers can now deploy runtime files to the Action environment prior to invocation.</p>

<p>This makes it much easier to support (<em>almost</em>) any programming language in OpenWhisk. Awesome!</p>

<p>Let's start by explaining how this new feature works...</p>

<h2>Docker Actions</h2>

<p>Docker Actions in OpenWhisk are <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/Dockerfile">built</a> from the following <a href="https://github.com/openwhisk/openwhisk/tree/master/core/actionProxy">repository</a> using the <a href="https://github.com/docker-library/python/blob/693a75332e8ae5ad3bfae6e8399c4d7cc3cb6181/2.7/alpine/Dockerfile">python:2.7.12-alpine</a> base image. This image is available on Docker Hub as <a href="https://hub.docker.com/r/openwhisk/dockerskeleton/"><code>openwhisk/dockerskeletion</code></a>.</p>

<p>The image includes a Python application which <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py">implements the HTTP API</a> used to handle platform requests, e.g. <em>invoke the action with these parameters</em>.</p>

<p>This service executes a file (<code>/action/exec</code>) for each invocation. Replacing this file allows us to control the runtime environment.</p>

<p>Request parameters are passed, using a JSON string, as the first command-line argument. Response values are interpreted as JSON written to <code>stdout</code>.</p>

<p>Developers can now include a zip file when creating Docker-based Actions. This archive will be extracted into the <code>/action</code> directory prior to invocations. If the archive contains a file named <code>exec</code> this will replace the exectuable file called by the invocation handler.</p>

<h3>Testing It Out</h3>

<p>Using the <code>wsk</code> command-line, developers can create Actions using this Docker image.</p>

<p>If the archive file is missing, the <code>/action/exec</code> path contains the the following <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/stub.sh">stub file</a>.</p>

<p><code>sh
$ wsk action create skeleton --docker openwhisk/dockerskeleton
ok: created action skeleton
$ wsk action invoke skeleton --blocking --result
{ "error": "This is a stub action. Replace it with custom logic." }
</code></p>

<p>Let's update this stub file to return a custom greeting.</p>

<p>``` sh
$ cat exec</p>

<h1>!/bin/bash</h1>

<p>echo "{ \"hello\": \"ran without a docker pull!\" }"
$ ./exec
{ "hello": "ran without a docker pull!" }
$ zip exec.zip exec
  adding: exec (stored 0%)
$ wsk action create custom_docker_action exec.zip --docker
ok: created action custom_docker_action
$ wsk action invoke custom_docker_action --blocking --result
{ "hello": "ran without a docker pull!" }
```</p>

<p>The archive file could include a static binary, or even a complete runtime, to replace the <code>exec</code> stub.</p>

<p>All files in the archive file will be available under the <code>/action</code> directory.</p>

<h2>Running Locally</h2>

<p>The <code>openwhisk/dockerskeleton</code> image exposes a Python-based HTTP server on port 8080.</p>

<p>Pulling the <code>openwhisk/dockerskeleton</code> image from Docker Hub allows us to run it locally for development.</p>

<p><code>sh
$ docker pull openwhisk/dockerskeleton
$ docker run -it -p 8080:8080 openwhisk/dockerskeleton
</code></p>

<p>The platform uses the following HTTP endpoints to initialise and invoke Actions.</p>

<ul>
<li><code>POST /init</code> -> Set up Action source from JSON payload.</li>
<li><code>POST /run</code> -> Invoke Action</li>
</ul>


<h3>Initialising The Environment</h3>

<p>Before invoking Actions using this image, we need to deploy and unpack the archive file into the <code>/action</code> directory.</p>

<p>Reviewing the <a href="https://github.com/openwhisk/openwhisk/blob/master/core/actionProxy/actionproxy.py#L47-L80">Python source code</a>, the platform triggers this by sending a HTTP POST with the following JSON to <code>/init</code> endpoint.</p>

<p>``` json
{
  "value": {</p>

<pre><code>"binary": true,
"code": "..."
</code></pre>

<p>  }
}
```</p>

<p><code>code</code> contains the archive file as a base64 encoded string.</p>

<p>Let's try this out using the action archive we created above.</p>

<p>``` sh
$ base64 exec.zip  | echo "\"$(cat)\"" | jq '{value: {binary: true, code: .}}' > init.json
$ cat init.json
{
  "value": {</p>

<pre><code>"binary": true,
"code": "UEsDBAoAAAAAAOlqMEr1+JNAQQAAAEEAAAAEABwAZXhlY1VUCQADRcl8WFDJfFh1eAsAAQT1AQAABBQAAAAjIS9iaW4vYmFzaAplY2hvICJ7IFwiaGVsbG9cIjogXCJyYW4gd2l0aG91dCBhIGRvY2tlciBwdWxsIVwiIH0iClBLAQIeAwoAAAAAAOlqMEr1+JNAQQAAAEEAAAAEABgAAAAAAAEAAADtgQAAAABleGVjVVQFAANFyXxYdXgLAAEE9QEAAAQUAAAAUEsFBgAAAAABAAEASgAAAH8AAAAAAA=="
</code></pre>

<p>  }
}
```</p>

<p>Now we can issue the HTTP request to push this archive into the container.</p>

<p>``` sh
$ http post localhost:8080/init &lt; init.json
HTTP/1.1 200 OK
Content-Length: 2
Content-Type: text/html; charset=utf-8
Date: Mon, 16 Jan 2017 14:11:04 GMT</p>

<p>OK
```</p>

<p>Accessing the container filesystem allows us to verify the archive has been extracted correctly.</p>

<p>``` sh
$ docker ps
CONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS              PORTS                    NAMES
b37a7dc1cab1        openwhisk/dockerskeleton      "/bin/bash -c 'cd ..."   About an hour ago   Up About an hour    0.0.0.0:8080->8080/tcp   relaxed_davinci
$ docker exec -it b37a7dc1cab1 /bin/sh
/ # cd /action
/action # ls
exec
/action # cat exec</p>

<h1>!/bin/bash</h1>

<p>echo "{ \"hello\": \"ran without a docker pull!\" }"
```</p>

<h3>Invocation Requests</h3>

<p>Action invocations are triggered by sending a HTTP POST to the <code>/run</code> endpoint.</p>

<p>This endpoint expects the following JSON body.</p>

<p>```
{
  "value": {</p>

<pre><code>"foo": "bar"
</code></pre>

<p>  }
}
```</p>

<p>The inner object parameters under the <code>value</code> property are passed, as a JSON string, to the executable as the first command-line argument.</p>

<p>Sending this request to our container will trigger the shell script from our archive and return the JSON response.</p>

<p>``` sh
$ echo "{}" | jq '{value: .}' | http post localhost:8080/run
HTTP/1.1 200 OK
Content-Length: 44
Content-Type: application/json
Date: Mon, 16 Jan 2017 14:17:15 GMT</p>

<p>{</p>

<pre><code>"hello": "ran without a docker pull!"
</code></pre>

<p>}
```</p>

<h2>Conclusion</h2>

<p>Recent updates to Docker-based Actions in OpenWhisk make it much easier to customise the runtime environment.</p>

<p>Being able to deploy arbitrary files into the runtime container, prior to invocation, simplifies the process of supporting new runtimes.</p>

<p>Hopefully this blog post has shown you how to get started with this feature.</p>

<p>Over the next few weeks, we're going to show you how to use this approach to run lots of new programming languages on the platform. Stay tuned for updates...</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Node-RED Docker Images]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2016/07/27/node-red-docker-images/"/>
    <updated>2016-07-27T15:24:00+01:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2016/07/27/node-red-docker-images</id>
    <content type="html"><![CDATA[<p>This week, I've been helping create and publish official <a href="https://www.docker.com/">Docker</a> images for the
<a href="http://nodered.org/">Node-RED</a> project. Users can start Node-RED instances from these images using the following command.</p>

<p><code>
docker run -it -p 1880:1880 nodered/node-red-docker
</code></p>

<p>Node-RED is now publishing the <a href="https://hub.docker.com/r/nodered/node-red-docker/">following images to Docker Hub</a> for each new release.</p>

<ul>
<li><strong><a href="https://github.com/node-red/node-red-docker/tree/master/latest">latest</a></strong> - uses <a href="https://hub.docker.com/_/node/">official Node.JS v4 base image</a>.</li>
<li><strong><a href="https://github.com/node-red/node-red-docker/tree/master/slim">slim</a></strong> - uses <a href="https://hub.docker.com/r/mhart/alpine-node/">Alpine Linux base image</a>.</li>
<li><strong><a href="https://github.com/node-red/node-red-docker/tree/master/rpi">rpi</a></strong> - uses <a href="https://hub.docker.com/r/hypriot/rpi-node/">RPi-compatible base image</a>.</li>
</ul>


<p>When a new version is <a href="https://www.npmjs.com/package/node-red">released on NPM</a>, an <a href="https://travis-ci.org/node-red/node-red-docker">automated CI service</a> will build, test and
publish new images with the <a href="https://hub.docker.com/r/nodered/node-red-docker/tags/">updated version tags</a>.</p>

<p>The source repository for the Docker images is available at <a href="https://github.com/node-red/node-red-docker">https://github.com/node-red/node-red-docker</a>.</p>

<h2>Background</h2>

<p>There was a <a href="https://github.com/node-red/node-red/issues/603">long-standing issue</a> open with the project
to provide official Docker images for the tool. Many users had <a href="https://hub.docker.com/r/cpswan/node-red/">already</a> <a href="https://github.com/jamesbrink/docker-node-red">been</a>
<a href="http://ivyco.blogspot.co.uk/2015/03/docker-awesomeness.html">experimenting</a> with Node-RED and Docker.</p>

<p><em>Reviewing the community's efforts, we wanted to create official images that
made it simple for users to start Node-RED as Docker containers with minimal
configuration whilst allowing for easy customisation, i.e. adding new nodes.</em></p>

<p>Docker images are created using a configuration file (<a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a>) that lists the
commands to build that image and can start by <a href="https://docs.docker.com/engine/reference/builder/#/from">using another image as the 'base'</a>.</p>

<p>Node-RED is a Node.js application, published as an <a href="https://www.npmjs.com/package/node-red">NPM module</a>.
The Node.js project publishes <a href="https://hub.docker.com/_/node/">official Docker images</a> which we used as our base image.
These images provide an environment with the correct versions of Node.js and
NPM installed.</p>

<p>Rather than manually copying the Node-RED source code into the container image,
we used NPM to install the source code by defining a custom <a href="https://docs.npmjs.com/files/package.json">package.json</a>
which includes Node-RED as dependency.</p>

<p>``` json package.json
{</p>

<pre><code>"name": "node-red-docker",
"version": "0.14.5",
"description": "Docker images for Node-RED",
"main": "node_modules/node-red/red/red.js",
"scripts": {
    "start": "node-red"
},
...
"dependencies": {
    "node-red": "0.14.5"
},
"engines": {
    "node": "4.*.*"
}
</code></pre>

<p>}
```</p>

<p>Adding this file into the container image and then running <a href="https://docs.npmjs.com/cli/install">NPM install</a>, using
the <a href="https://docs.docker.com/engine/reference/builder/#/add">ADD</a> and <a href="https://docs.docker.com/engine/reference/builder/#/run">RUN</a> commands, will retrieve the correct Node-RED version and build
that into the container image.</p>

<p>Docker images define a <a href="https://docs.docker.com/engine/reference/builder/#/cmd">default start command</a> to run when the container is
created. Using <em>npm start</em> for this image will parse the start script
listed in the package.json file, which has been set to
<em>node-red</em>.</p>

<h2>Adding New Nodes</h2>

<p>Node-RED has a <a href="http://flows.nodered.org/">huge community</a> which produces custom nodes for everything from
accessing data from a <a href="http://flows.nodered.org/node/node-red-contrib-gpio">Raspberry Pi's sensors</a> to a <a href="http://flows.nodered.org/node/node-red-contrib-teslams">Tesla car</a>.</p>

<p>Additional nodes <a href="http://nodered.org/docs/getting-started/adding-nodes">can be installed</a> by putting the files into your user
directory, which defaults to <em>$HOME/.node-red</em>.</p>

<p>Allowing users to install additional nodes without building new images is
possible using <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">Docker's volume support</a>. Docker data volumes can be used to
share files between the container and the host system, by <a href="https://docs.docker.com/engine/tutorials/dockervolumes/#/mount-a-host-directory-as-a-data-volume">mounting a directory on the host as a data volume within the container</a>.</p>

<p>Exposing the Node-RED user directory within the container as a data volume
means users can mount this on the host system. Nodes installed into this
directory, using NPM on the host system, will automatically be registered when
Node-RED starts.</p>

<p>Within the Dockerfile for the Node-RED image, the /data directory is configured
as the user directory and <a href="https://github.com/node-red/node-red-docker/blob/master/latest/Dockerfile#L23">exported as a data volume</a>.</p>

<p>Users can mount their local user directory into the container with the
following command.</p>

<p><code>sh
docker run -it -p 1880:1880 -v ~/.node-red:/data nodered/node-red-docker
</code></p>

<h2>Environment Parameters</h2>

<p>Docker <a href="http://stackoverflow.com/questions/30494050/how-to-pass-environment-variables-to-docker-containers">supports injecting environment parameter</a> values into running containers,
using command-line options on the host system. This is often used to configure
runtime options without users having to build new container images. Node-RED's
Docker images support the following environment parameters.</p>

<h3>Flows Configuration</h3>

<p>User flow configurations are <a href="http://nodered.org/docs/getting-started/running">stored in a JSON file under the user directory</a>. This defaults to
<em>flows.json</em> but can be configured using an environment parameter
(<strong>FLOWS</strong>) passed to the container, as shown below.</p>

<p><code>
docker run -it -p 1880:1880 -e FLOWS=my_flows.json nodered/node-red-docker
</code></p>

<h3>Node Options</h3>

<p>Node.js runtime arguments can be passed to the container using an environment
parameter (<strong>NODE_OPTIONS</strong>). For example, to <a href="https://github.com/nodejs/node/issues/2738">fix the heap size</a> used by the Node.js
garbage collector you would use the following command.</p>

<p><code>
docker run -it -p 1880:1880 -e NODE_OPTIONS="--max_old_space_size=128" nodered/node-red-docker
</code></p>

<h2>Alpine Linux Image</h2>

<p>The official Node.js Docker image uses the <a href="https://hub.docker.com/_/debian/">Debian Jessie base image</a>. This image
provides a full Linux install, which means dependent Docker images can be
hundreds of megabytes in size. Node-RED's Docker image, using this base image,
is nearly 300 MB.</p>

<p>Reducing Docker image sizes can <a href="http://jasonwilder.com/blog/2014/08/19/squashing-docker-images/">dramatically reduce build and deployment times</a>.</p>

<p><a href="https://www.alpinelinux.org/">Alpine Linux</a> is a lightweight Linux distribution, focused on security and
performance. A <a href="https://hub.docker.com/_/alpine/">minimal Docker image</a> based on Alpine Linux is only 5 MB in
size!</p>

<p>Using the <a href="https://hub.docker.com/r/mhart/alpine-node/">alpine-node</a> base
image, which provides an Alpine Linux environment with Node.js &amp; NPM, in our
Dockerfiles reduces the resulting image file to under 50 MB.</p>

<p>Alpine Linux does make it <a href="http://stackoverflow.com/questions/36202095/node-serialport-failing-on-alpine-linux">more difficult to install NPM modules with native dependencies</a>, due to missing common libraries and tools needed to build them.</p>

<p>Therefore, we're publishing the Alpine Linux image as a seperate tag (<em>slim</em>), rather
than using this base image throughout our Dockerfiles.</p>

<p>This version should provide an extremely lightweight Node-RED image that works
for most users.</p>

<p><code>
docker run -it -p 1880:1880 nodered/node-red-docker:slim
</code></p>

<h2>Raspberry Pi Image</h2>

<p>Node-RED is an incredibly popular tool for hacking on the <a href="https://www.raspberrypi.org/">Raspberry Pi</a>. Using a
<a href="http://blog.hypriot.com/getting-started-with-docker-on-your-arm-device/">custom Raspberry Pi image</a>, developers can also have a full Docker system
running in the Linux environment on their device.</p>

<p><strong>So, can we use Docker to start Node-RED on the Raspberry Pi?</strong></p>

<p>Due to the platform architecture, ARM rather than x86/x64 by Intel or AMD,
Docker images must be packaged specifically for that platform. The existing
Docker images created for Node-RED will not work.</p>

<p>Fortunately, there's an <a href="https://hub.docker.com/r/hypriot/rpi-node/">existing RPi-compatible Docker image</a>
with Node.js and NPM.</p>

<p>Using this base image to build a new Raspberry Pi-specific Node-RED image,
published with the <em>rpi</em> tag, means users can now start Node-RED on the Raspberry Pi using Docker.</p>

<p><code>
docker run -it -p 1880:1880 nodered/node-red-docker:rpi
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debugging Live Containers on IBM Bluemix]]></title>
    <link href="http://jthomas.github.com/jthomas/blog/2016/01/22/debugging-live-containers-on-ibm-bluemix/"/>
    <updated>2016-01-22T16:57:00+00:00</updated>
    <id>http://jthomas.github.com/jthomas/blog/2016/01/22/debugging-live-containers-on-ibm-bluemix</id>
    <content type="html"><![CDATA[<p>For the last few months, I've been using the <a href="https://www.elastic.co/webinars/introduction-elk-stack">ELK stack</a> to <a href="https://docs.cloudfoundry.org/devguide/services/log-management.html">collect logs</a> from my
Cloud Foundry applications. This service has been deployed on IBM Bluemix using
a Docker container, previously detailed in <a href="jamesthom.as/blog/2015/07/08/making-logs-awesome-with-elasticsearch-and-docker/">this blog post</a>, and running happily
until it ran into issues this week.</p>

<p>Trying to load the Kibana web application, the server was returning <em>connection
refused</em> errors. Looking at the container in the <a href="http://bluemix.net">IBM Bluemix</a> dashboard showed
no obvious signs of issues. Reviewing the <a href="https://www.ng.bluemix.net/docs/containers/container_ml_ov.html">container log output</a> uncovered nothing
indicating what had failed.</p>

<p>Hmmm...</p>

<p><strong>Fixing this issue would require me to start debugging from within the live
container, but how?</strong></p>

<p>This container image had not included an SSH daemon that would allow remote
access over SSH.</p>

<p>Looking over the <a href="https://www.ng.bluemix.net/docs/containers/container_index.html">documentation</a> for the <a href="https://www.ng.bluemix.net/docs/containers/container_cli_ov.html#container_cli_cfic">IBM Containers plugin</a> for the Cloud
Foundry CLI, I noticed the <em>exec</em> command.</p>

<p><blockquote><p>Docker exec allows a user to spawn a process inside their Docker container via<br/>the Docker API and CLI.</p></blockquote></p>

<p>Since Docker 1.3, released in October 2014, the <a href="https://docs.docker.com/engine/reference/commandline/exec/"><em>exec</em> command</a> has allowed users to
run new commands within existing containers.</p>

<p>The IBM Containers implementation now <a href="https://www.ng.bluemix.net/docs/containers/container_cli_reference_native-docker.html">supports this Docker command</a>.</p>

<p>Using the IBM Containers plugin for the Cloud Foundry CLI, I can find the
container id for the instance I want to debug and then start a bash shell to
start resolving my issue.</p>

<p><code>sh
$ cf ic ps
$ cf ic exec -it &lt;container_id&gt; /bin/bash
</code></p>

<p>Having a live shell to my container allowed me to resolve the issue within a
few minutes, without having to affect the running state of the container. This
command also removes the need to keep an SSH daemon running on containers for
remote access.</p>

<p>For more information on the subset of Docker commands supported by IBM
Containers, see the following <a href="https://www.ng.bluemix.net/docs/containers/container_cli_reference_native-docker.html">documentation</a>.</p>
]]></content>
  </entry>
  
</feed>
