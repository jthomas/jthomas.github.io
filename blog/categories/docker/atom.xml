<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: docker | James Thomas]]></title>
  <link href="http://jamesthom.as/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://jamesthom.as/"/>
  <updated>2016-09-08T16:36:12+01:00</updated>
  <id>http://jamesthom.as/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Node-RED Docker Images]]></title>
    <link href="http://jamesthom.as/blog/2016/07/27/node-red-docker-images/"/>
    <updated>2016-07-27T15:24:00+01:00</updated>
    <id>http://jamesthom.as/blog/2016/07/27/node-red-docker-images</id>
    <content type="html"><![CDATA[<p>This week, I've been helping create and publish official <a href="https://www.docker.com/">Docker</a> images for the
<a href="http://nodered.org/">Node-RED</a> project. Users can start Node-RED instances from these images using the following command.</p>

<p><code>
docker run -it -p 1880:1880 nodered/node-red-docker
</code></p>

<p>Node-RED is now publishing the <a href="https://hub.docker.com/r/nodered/node-red-docker/">following images to Docker Hub</a> for each new release.</p>

<ul>
<li><strong><a href="https://github.com/node-red/node-red-docker/tree/master/latest">latest</a></strong> - uses <a href="https://hub.docker.com/_/node/">official Node.JS v4 base image</a>.</li>
<li><strong><a href="https://github.com/node-red/node-red-docker/tree/master/slim">slim</a></strong> - uses <a href="https://hub.docker.com/r/mhart/alpine-node/">Alpine Linux base image</a>.</li>
<li><strong><a href="https://github.com/node-red/node-red-docker/tree/master/rpi">rpi</a></strong> - uses <a href="https://hub.docker.com/r/hypriot/rpi-node/">RPi-compatible base image</a>.</li>
</ul>


<p>When a new version is <a href="https://www.npmjs.com/package/node-red">released on NPM</a>, an <a href="https://travis-ci.org/node-red/node-red-docker">automated CI service</a> will build, test and
publish new images with the <a href="https://hub.docker.com/r/nodered/node-red-docker/tags/">updated version tags</a>.</p>

<p>The source repository for the Docker images is available at <a href="https://github.com/node-red/node-red-docker">https://github.com/node-red/node-red-docker</a>.</p>

<h2>Background</h2>

<p>There was a <a href="https://github.com/node-red/node-red/issues/603">long-standing issue</a> open with the project
to provide official Docker images for the tool. Many users had <a href="https://hub.docker.com/r/cpswan/node-red/">already</a> <a href="https://github.com/jamesbrink/docker-node-red">been</a>
<a href="http://ivyco.blogspot.co.uk/2015/03/docker-awesomeness.html">experimenting</a> with Node-RED and Docker.</p>

<p><em>Reviewing the community's efforts, we wanted to create official images that
made it simple for users to start Node-RED as Docker containers with minimal
configuration whilst allowing for easy customisation, i.e. adding new nodes.</em></p>

<p>Docker images are created using a configuration file (<a href="https://docs.docker.com/engine/reference/builder/">Dockerfile</a>) that lists the
commands to build that image and can start by <a href="https://docs.docker.com/engine/reference/builder/#/from">using another image as the 'base'</a>.</p>

<p>Node-RED is a Node.js application, published as an <a href="https://www.npmjs.com/package/node-red">NPM module</a>.
The Node.js project publishes <a href="https://hub.docker.com/_/node/">official Docker images</a> which we used as our base image.
These images provide an environment with the correct versions of Node.js and
NPM installed.</p>

<p>Rather than manually copying the Node-RED source code into the container image,
we used NPM to install the source code by defining a custom <a href="https://docs.npmjs.com/files/package.json">package.json</a>
which includes Node-RED as dependency.</p>

<p>``` json package.json
{</p>

<pre><code>"name": "node-red-docker",
"version": "0.14.5",
"description": "Docker images for Node-RED",
"main": "node_modules/node-red/red/red.js",
"scripts": {
    "start": "node-red"
},
...
"dependencies": {
    "node-red": "0.14.5"
},
"engines": {
    "node": "4.*.*"
}
</code></pre>

<p>}
```</p>

<p>Adding this file into the container image and then running <a href="https://docs.npmjs.com/cli/install">NPM install</a>, using
the <a href="https://docs.docker.com/engine/reference/builder/#/add">ADD</a> and <a href="https://docs.docker.com/engine/reference/builder/#/run">RUN</a> commands, will retrieve the correct Node-RED version and build
that into the container image.</p>

<p>Docker images define a <a href="https://docs.docker.com/engine/reference/builder/#/cmd">default start command</a> to run when the container is
created. Using <em>npm start</em> for this image will parse the start script
listed in the package.json file, which has been set to
<em>node-red</em>.</p>

<h2>Adding New Nodes</h2>

<p>Node-RED has a <a href="http://flows.nodered.org/">huge community</a> which produces custom nodes for everything from
accessing data from a <a href="http://flows.nodered.org/node/node-red-contrib-gpio">Raspberry Pi's sensors</a> to a <a href="http://flows.nodered.org/node/node-red-contrib-teslams">Tesla car</a>.</p>

<p>Additional nodes <a href="http://nodered.org/docs/getting-started/adding-nodes">can be installed</a> by putting the files into your user
directory, which defaults to <em>$HOME/.node-red</em>.</p>

<p>Allowing users to install additional nodes without building new images is
possible using <a href="https://docs.docker.com/engine/tutorials/dockervolumes/">Docker's volume support</a>. Docker data volumes can be used to
share files between the container and the host system, by <a href="https://docs.docker.com/engine/tutorials/dockervolumes/#/mount-a-host-directory-as-a-data-volume">mounting a directory on the host as a data volume within the container</a>.</p>

<p>Exposing the Node-RED user directory within the container as a data volume
means users can mount this on the host system. Nodes installed into this
directory, using NPM on the host system, will automatically be registered when
Node-RED starts.</p>

<p>Within the Dockerfile for the Node-RED image, the /data directory is configured
as the user directory and <a href="https://github.com/node-red/node-red-docker/blob/master/latest/Dockerfile#L23">exported as a data volume</a>.</p>

<p>Users can mount their local user directory into the container with the
following command.</p>

<p><code>sh
docker run -it -p 1880:1880 -v ~/.node-red:/data nodered/node-red-docker
</code></p>

<h2>Environment Parameters</h2>

<p>Docker <a href="http://stackoverflow.com/questions/30494050/how-to-pass-environment-variables-to-docker-containers">supports injecting environment parameter</a> values into running containers,
using command-line options on the host system. This is often used to configure
runtime options without users having to build new container images. Node-RED's
Docker images support the following environment parameters.</p>

<h3>Flows Configuration</h3>

<p>User flow configurations are <a href="http://nodered.org/docs/getting-started/running">stored in a JSON file under the user directory</a>. This defaults to
<em>flows.json</em> but can be configured using an environment parameter
(<strong>FLOWS</strong>) passed to the container, as shown below.</p>

<p><code>
docker run -it -p 1880:1880 -e FLOWS=my_flows.json nodered/node-red-docker
</code></p>

<h3>Node Options</h3>

<p>Node.js runtime arguments can be passed to the container using an environment
parameter (<strong>NODE_OPTIONS</strong>). For example, to <a href="https://github.com/nodejs/node/issues/2738">fix the heap size</a> used by the Node.js
garbage collector you would use the following command.</p>

<p><code>
docker run -it -p 1880:1880 -e NODE_OPTIONS="--max_old_space_size=128" nodered/node-red-docker
</code></p>

<h2>Alpine Linux Image</h2>

<p>The official Node.js Docker image uses the <a href="https://hub.docker.com/_/debian/">Debian Jessie base image</a>. This image
provides a full Linux install, which means dependent Docker images can be
hundreds of megabytes in size. Node-RED's Docker image, using this base image,
is nearly 300 MB.</p>

<p>Reducing Docker image sizes can <a href="http://jasonwilder.com/blog/2014/08/19/squashing-docker-images/">dramatically reduce build and deployment times</a>.</p>

<p><a href="https://www.alpinelinux.org/">Alpine Linux</a> is a lightweight Linux distribution, focused on security and
performance. A <a href="https://hub.docker.com/_/alpine/">minimal Docker image</a> based on Alpine Linux is only 5 MB in
size!</p>

<p>Using the <a href="https://hub.docker.com/r/mhart/alpine-node/">alpine-node</a> base
image, which provides an Alpine Linux environment with Node.js &amp; NPM, in our
Dockerfiles reduces the resulting image file to under 50 MB.</p>

<p>Alpine Linux does make it <a href="http://stackoverflow.com/questions/36202095/node-serialport-failing-on-alpine-linux">more difficult to install NPM modules with native dependencies</a>, due to missing common libraries and tools needed to build them.</p>

<p>Therefore, we're publishing the Alpine Linux image as a seperate tag (<em>slim</em>), rather
than using this base image throughout our Dockerfiles.</p>

<p>This version should provide an extremely lightweight Node-RED image that works
for most users.</p>

<p><code>
docker run -it -p 1880:1880 nodered/node-red-docker:slim
</code></p>

<h2>Raspberry Pi Image</h2>

<p>Node-RED is an incredibly popular tool for hacking on the <a href="https://www.raspberrypi.org/">Raspberry Pi</a>. Using a
<a href="http://blog.hypriot.com/getting-started-with-docker-on-your-arm-device/">custom Raspberry Pi image</a>, developers can also have a full Docker system
running in the Linux environment on their device.</p>

<p><strong>So, can we use Docker to start Node-RED on the Raspberry Pi?</strong></p>

<p>Due to the platform architecture, ARM rather than x86/x64 by Intel or AMD,
Docker images must be packaged specifically for that platform. The existing
Docker images created for Node-RED will not work.</p>

<p>Fortunately, there's an <a href="https://hub.docker.com/r/hypriot/rpi-node/">existing RPi-compatible Docker image</a>
with Node.js and NPM.</p>

<p>Using this base image to build a new Raspberry Pi-specific Node-RED image,
published with the <em>rpi</em> tag, means users can now start Node-RED on the Raspberry Pi using Docker.</p>

<p><code>
docker run -it -p 1880:1880 nodered/node-red-docker:rpi
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debugging Live Containers on IBM Bluemix]]></title>
    <link href="http://jamesthom.as/blog/2016/01/22/debugging-live-containers-on-ibm-bluemix/"/>
    <updated>2016-01-22T16:57:00+00:00</updated>
    <id>http://jamesthom.as/blog/2016/01/22/debugging-live-containers-on-ibm-bluemix</id>
    <content type="html"><![CDATA[<p>For the last few months, I've been using the <a href="https://www.elastic.co/webinars/introduction-elk-stack">ELK stack</a> to <a href="https://docs.cloudfoundry.org/devguide/services/log-management.html">collect logs</a> from my
Cloud Foundry applications. This service has been deployed on IBM Bluemix using
a Docker container, previously detailed in <a href="jamesthom.as/blog/2015/07/08/making-logs-awesome-with-elasticsearch-and-docker/">this blog post</a>, and running happily
until it ran into issues this week.</p>

<p>Trying to load the Kibana web application, the server was returning <em>connection
refused</em> errors. Looking at the container in the <a href="http://bluemix.net">IBM Bluemix</a> dashboard showed
no obvious signs of issues. Reviewing the <a href="https://www.ng.bluemix.net/docs/containers/container_ml_ov.html">container log output</a> uncovered nothing
indicating what had failed.</p>

<p>Hmmm...</p>

<p><strong>Fixing this issue would require me to start debugging from within the live
container, but how?</strong></p>

<p>This container image had not included an SSH daemon that would allow remote
access over SSH.</p>

<p>Looking over the <a href="https://www.ng.bluemix.net/docs/containers/container_index.html">documentation</a> for the <a href="https://www.ng.bluemix.net/docs/containers/container_cli_ov.html#container_cli_cfic">IBM Containers plugin</a> for the Cloud
Foundry CLI, I noticed the <em>exec</em> command.</p>

<p><blockquote><p>Docker exec allows a user to spawn a process inside their Docker container via<br/>the Docker API and CLI.</p></blockquote></p>

<p>Since Docker 1.3, released in October 2014, the <a href="https://docs.docker.com/engine/reference/commandline/exec/"><em>exec</em> command</a> has allowed users to
run new commands within existing containers.</p>

<p>The IBM Containers implementation now <a href="https://www.ng.bluemix.net/docs/containers/container_cli_reference_native-docker.html">supports this Docker command</a>.</p>

<p>Using the IBM Containers plugin for the Cloud Foundry CLI, I can find the
container id for the instance I want to debug and then start a bash shell to
start resolving my issue.</p>

<p><code>sh
$ cf ic ps
$ cf ic exec -it &lt;container_id&gt; /bin/bash
</code></p>

<p>Having a live shell to my container allowed me to resolve the issue within a
few minutes, without having to affect the running state of the container. This
command also removes the need to keep an SSH daemon running on containers for
remote access.</p>

<p>For more information on the subset of Docker commands supported by IBM
Containers, see the following <a href="https://www.ng.bluemix.net/docs/containers/container_cli_reference_native-docker.html">documentation</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Location-Based Cloud Foundry Applications using Nginx and Docker]]></title>
    <link href="http://jamesthom.as/blog/2015/09/11/location-based-cloud-foundry-applications-with-nginx-and-docker/"/>
    <updated>2015-09-11T10:24:00+01:00</updated>
    <id>http://jamesthom.as/blog/2015/09/11/location-based-cloud-foundry-applications-with-nginx-and-docker</id>
    <content type="html"><![CDATA[<p><img src="/images/geo_web_view.png"></p>

<p>Routing application traffic based upon the geographic location of incoming requests can
be used for a number of scenarios...</p>

<ul>
<li>Restricting access to your application outside defined geographic regions.</li>
<li>Load-balancing traffic to the closest region for improved performance.</li>
<li>Providing custom applications for different countries.</li>
</ul>


<p>IBM Bluemix allows deploying applications to different geographic regions through
hosting instances of the <a href="https://www.cloudfoundry.org/">Cloud Foundry</a> platform in <a href="https://www.ibm.com/developerworks/community/blogs/enablingwithbluemix/entry/regions_in_bluemix?lang=en">multiple locations</a>.</p>

<p>Cloud Foundry supports <a href="https://docs.cloudfoundry.org/devguide/deploy-apps/domains-routes.html">simple HTTP routing rules</a> for deployed applications.
Organisations can register domains and routes for applications. Routes can be
bound to one or more deployed applications. Incoming HTTP traffic is
load-balanced, using the <a href="https://en.wikipedia.org/wiki/Round-robin_scheduling">Round-Robin</a> policy, between the application instances bound to a route.</p>

<p><em>However, the platform does not currently support traffic routing based upon the
geographic location of incoming requests or sharing domains and routes between regions.</em></p>

<p><strong>So, say we want to deploy custom versions of an application to different regions and
automatically forward users to the correct version based upon their location. How can we
achieve this?</strong></p>

<p>Let's find out...</p>

<h2>Deploying Application To Different Regions</h2>

<p>IBM Bluemix currently provides Cloud Foundry in <a href="https://www.ng.bluemix.net/docs/overview/overview.html#ov_intro">two regions</a> for deploying applications.</p>

<ul>
<li><strong>US South</strong> (<em>api.ng.bluemix.net</em>)</li>
<li><strong>Europe</strong> (<em>api.eu-gb.bluemix.net</em>)</li>
</ul>


<p>Moving between regions is as simple as providing the different region endpoint during the
authentication command.</p>

<p>``` sh
[16:25:47 ~]$ cf login -a api.ng.bluemix.net -u james.thomas@uk.ibm.com -s dev
API endpoint: api.ng.bluemix.net</p>

<p>Password>
Authenticating...
OK</p>

<p>Targeted org james.thomas@uk.ibm.com</p>

<p>Targeted space dev</p>

<p>API endpoint:   https://api.ng.bluemix.net (API version: 2.27.0)
User:           james.thomas@uk.ibm.com
Org:            james.thomas@uk.ibm.com
Space:          dev
[16:26:44 ~]$
```</p>

<p>We're now authenticated against the US South region.</p>

<p>Let's start by deploying our sample application, which displays a web
page showing the application URL, to this region.</p>

<p>``` sh
[16:44:24 ~/code/sample]$ cf api
API endpoint: https://api.ng.bluemix.net (API version: 2.27.0)
[16:44:32 ~/code/sample]$ cf push sample-demo-app
Using manifest file /Users/james/code/sample/manifest.yml</p>

<p>Updating app sample-demo-app in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...
OK</p>

<p>...</p>

<p>Showing health and status for app sample-demo-app in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...
OK</p>

<p>requested state: started
instances: 1/1
usage: 256M x 1 instances
urls: sample-demo-app.mybluemix.net
last uploaded: Fri Sep 11 15:45:04 UTC 2015
stack: lucid64
buildpack: SDK for Node.js(TM) (node.js-4.0.0)</p>

<pre><code> state     since                    cpu    memory          disk        details
</code></pre>

<h1>0   running   2015-09-11 04:46:00 PM   0.0%   67.1M of 256M   59M of 1G</h1>

<p>[16:45:14 ~/code/sample]$
```</p>

<p>Once that has finished, we can move over to the European region and deploy our application there.</p>

<p>``` sh
[16:52:33 ~/code/sample]$ cf login -a api.eu-gb.bluemix.net -u james.thomas@uk.ibm.com -s dev
[16:52:58 ~/code/sample]$ cf push sample-demo-app
Using manifest file /Users/james/code/sample/manifest.yml</p>

<p>Updating app sample-demo-app in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...
OK</p>

<p>...</p>

<p>Showing health and status for app sample-demo-app in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...
OK</p>

<p>requested state: started
instances: 1/1
usage: 256M x 1 instances
urls: sample-demo-app.eu-gb.mybluemix.net
last uploaded: Fri Sep 11 15:53:31 UTC 2015
stack: lucid64
buildpack: SDK for Node.js(TM) (node.js-4.0.0)</p>

<pre><code> state     since                    cpu    memory          disk        details
</code></pre>

<h1>0   running   2015-09-11 04:54:17 PM   0.0%   67.4M of 256M   59M of 1G</h1>

<p>[16:54:25 ~/code/bluemix/sample]$
```</p>

<p>With the second deployment completed, there are now instances of the same application running in separate regions.</p>

<p>Each instance is available through a separate URL.</p>

<ul>
<li><a href="http://sample-demo-app.mybluemix.net">http://sample-demo-app.mybluemix.net</a></li>
<li><a href="http://sample-demo-app.eu-gb.mybluemix.net">http://sample-demo-app.eu-gb.mybluemix.net</a></li>
</ul>


<p>Now we need to set up traffic forwarding from the relevant locations to the correct region.</p>

<h2>Reverse Proxy with Region Traffic Forwarding</h2>

<p>Due to the platform not supporting multi-region traffic routing, we
need to set up a custom reverse proxy. This server will receive
requests from our external application domain and transparently forward
them onto the correct region application.</p>

<p><img src="/images/reverse_proxy.png"></p>

<p>We're going to use <a href="http://nginx.org/">Nginx</a>.</p>

<p><blockquote><p></p></p><p><p>Nginx (pronounced engine-x) is a free, open-source, high-performance HTTP server and reverse proxy, as well as an IMAP/POP3 proxy server</p></p><p><p></p><footer><strong>Nginx</strong> <cite><a href='http://wiki.nginx.org/Main'>wiki.nginx.org/Main/&hellip;</a></cite></footer></blockquote></p>

<p>Nginx comes with a <a href="http://nginx.org/en/docs/http/ngx_http_geoip_module.html">module</a> for looking up locations associated with IP
address using the <a href="http://dev.maxmind.com/geoip/">MaxMind GeoIP library</a>. The module can
resolve incoming request addresses into continents, countries and even cities. Using the variables defined by the module, we
can write traffic forwarding rules to send requests to the correct region.</p>

<h2>Nginx Configuration</h2>

<p>Nginx defines two configuration directives, <em>geoip_country</em> and <em>geoip_city</em>, to
specify locations for the MaxMind GeoIP database files.</p>

<pre>
http { 
    ...
    geoip_country /usr/share/GeoIP/GeoIP.dat;
    geoip_city /etc/nginx/geoip/GeoLiteCity.dat;
    ...
}
</pre>


<p>When configured, Nginx will expose a series of variables for each request with
geographical information.</p>

<ul>
<li><strong>$geoip_country_code</strong> - <em>two-letter country code, for example, “RU”, “US”.</em></li>
<li><strong>$geoip_country_name</strong> - <em>country name, for example, “Russian Federation”, “United States”.</em></li>
<li><strong>$geoip_city_continent_code</strong> - <em>two-letter continent code, for example, “EU”, “NA”.</em></li>
<li><strong>$geoip_city</strong> - <em>city name, for example, “Moscow”, “Washington”.</em></li>
</ul>


<p>Starting with the <a href="http://wiki.nginx.org/FullExample">default nginx configuration</a>,
there are only a few modifications needed to set up a reverse proxy based upon
location.</p>

<p>For each request, we check the <em>$geoip_city_continent_code</em> against our list of
regions. If the request is valid, setting the <em>proxy_pass</em> directive forwards
the request onto the correct region. We also overwrite the <em>Host:</em> HTTP
header with the region URL. IBM Bluemix uses this header to internally route
incoming requests to the correct application host.</p>

<p>Requests coming from outside these locations will be sent to a custom error
page.</p>

<p><em>Due to a <a href="https://www.ng.bluemix.net/docs/containers/container_troubleshoot.html">known issue</a>
with IBM Containers, we must use IP addresses rather than the host names with the proxy_pass directive.</em></p>

<p>Here is the full configuration for the <em>enabled-site/default</em> file.</p>

<pre>
server {
  listen 80 default_server;
  listen [::]:80 default_server ipv6only=on;

  root /usr/share/nginx/html;
  index index.html index.htm;
  error_page 404 /404.html;

# Make site accessible from http://localhost/
  server_name localhost;

  location = /404.html {
    internal;
  }

  location / {
    set $host_header "unknown";

    if ($geoip_city_continent_code = "EU") { 
      proxy_pass http://5.10.124.141;
      set $host_header "sample-demo-app.eu-gb.mybluemix.net";
    }

    if ($geoip_city_continent_code = "NA") { 
      proxy_pass http://75.126.81.66;
      set $host_header "sample-demo-app.mybluemix.net";
    }

    if ($host_header = "unknown") {
      return 404;
    }

    proxy_set_header Host $host_header;
  }
}
</pre>


<p>With the reverse proxy server configured, we need to provision a new
production server, install Linux and Nginx, configure networking, security updates
and backup services...</p>

<p><em>...or we can use Docker.</em></p>

<h2>Running Nginx using Docker</h2>

<p>There are <a href="https://hub.docker.com/search/?q=nginx&amp;page=1&amp;isAutomated=0&amp;isOfficial=0&amp;starCount=0&amp;pullCount=0">thousands</a>
of repositories on Docker Hub providing Nginx, including
the official image. Unfortunately, the <a href="http://wiki.nginx.org/FullExample">official image</a> provides a version of Nginx
that is not built with the <em>geo_ip</em> module.</p>

<p>Ubuntu's default package repository for Nginx does provide a build including
the <em>geo_ip</em> module. By modifying the Dockerfile for the official image, we can
build a new image from Ubuntu with the required version of Nginx and include
our custom configuration files.</p>

<pre>
FROM ubuntu
RUN apt-get -y install nginx

# copy custom configuration
COPY nginx.conf /etc/nginx/nginx.conf
COPY default /etc/nginx/sites-available/
COPY geoip /etc/nginx/geoip
COPY 404.html /usr/share/nginx/html/

# forward request and error logs to docker log collector
RUN ln -sf /dev/stdout /var/log/nginx/access.log
RUN ln -sf /dev/stderr /var/log/nginx/error.log

# expose HTTP and HTTP ports
EXPOSE 80 443

CMD ["nginx", "-g", "daemon off;"]
</pre>


<p>Building and running this container locally, we can test that Nginx is configured correctly. The repository containing the Dockerfile
and build artificats is located <a href="https://github.com/jthomas/geo_ip">here</a>.</p>

<p><code>sh
[16:58:40 ~/code/final]$ docker build -t geo_ip .
Sending build context to Docker daemon 15.88 MB
Step 0 : FROM ubuntu
 ---&gt; 91e54dfb1179
...
Step 9 : CMD nginx -g daemon off;
 ---&gt; Using cache
 ---&gt; 7bb6dbaafe3e
Successfully built 7bb6dbaafe3e
[16:58:50 ~/code/final]$ docker run -Pti geo_ip
</code>
<em>With the custom image ready, we just need to deploy it somewhere...</em></p>

<h2>Running Nginx on IBM Containers</h2>

<p>IBM Bluemix supports deploying Docker containers alongside Cloud Foundry
applications, allowing us to use the same cloud platform for running our custom
region applications as providing the reverse proxy</p>

<p>Pushing pre-built images to the IBM Containers service is really as simple as creating a new tag and typing <em>docker push</em>.</p>

<p><em>Please read and follow the <a href="https://www.ng.bluemix.net/docs/containers/container_cli_ov.html">documentation</a>
about installing the command-line container management tools and authenticating
with the remote service before attempting the commands below.</em></p>

<p><code>sh
[14:10:52 ~]$ docker tag geo_ip registry.ng.bluemix.net/jthomas/geo_ip
[14:10:59 ~]$ docker images
REPOSITORY                               TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
geo_ip                                   latest              7bb6dbaafe3e        3 days ago          222.3 MB
registry.ng.bluemix.net/jthomas/geo_ip   latest              7bb6dbaafe3e        3 days ago          222.3 MB
[14:11:07 ~]$ cf ic login
** Retrieving client certificates from IBM Containers
** Storing client certificates in /Users/james/.ice/certs
Successfully retrieved client certificates
** Authenticating with registry at registry.eu-gb.bluemix.net
Successfully authenticated with registry
[14:24:25 ~]$ docker push registry.ng.bluemix.net/jthomas/geo_ip
The push refers to a repository [registry.ng.bluemix.net/jthomas/geo_ip] (len: 1)
Sending image list
Pushing repository registry.ng.bluemix.net/jthomas/geo_ip (1 tags)
...
Pushing tag for rev [7bb6dbaafe3e] on {https://registry.ng.bluemix.net/v1/repositories/jthomas/geo_ip/tags/latest}
[14:25:39 ~]$ cf ic images
REPOSITORY                                        TAG                 IMAGE ID            CREATED              VIRTUAL SIZE
registry.ng.bluemix.net/jthomas/geo_ip            latest              7b1865be-778        About a minute ago   0 B
registry.ng.bluemix.net/ibmliberty                latest              2209a9732f35        3 weeks ago          263.6 MB
registry.ng.bluemix.net/ibmnode                   latest              8f962f6afc9a        3 weeks ago          178.9 MB
registry.ng.bluemix.net/ibm-mobilefirst-starter   latest              97513e56aaa7        3 weeks ago          464.9 MB
[14:26:43 ~]$
</code></p>

<p>We can now use the IBM Bluemix dashboard to start a new container from our custom image,
binding a public IP address and exposing ports.</p>

<p><img src="/images/deploy_container.png"></p>

<p>Once the container starts, accessing the bound IP address shows the
web page coming back with the region-specific application route.</p>

<p><img src="/images/container_ip_address.png"></p>

<p>Using DNS <a href="https://en.wikipedia.org/wiki/List_of_DNS_record_types#A">A records</a>, we can now
map our external URL to the IP address of the container. Users visiting this
URL will be sent to the reverse proxy server which will then forward the
request onto the correct region application.</p>

<h2>Testing it all out...</h2>

<p>Testing out the forwarding rules requires us to send HTTP requests from multiple regions.
<a href="http://geowebview.com">GeoWebView</a> will run web browsers located in different geographies and show you the rendered page output.</p>

<p>Running the tool with our application's <a href="http://geo_ip.jamesthom.as">web address</a>, shows the following rendered page images.</p>

<p><img src="/images/geo_web_view.png"></p>

<p>We can see the browsers from the United States and Europe are sent to the correct region. The browser from South Africa is shown the custom error page.</p>

<p><em>Using Nginx we've configured a reverse proxy to route users, based upon their location, to applications running in different IBM Bluemix regions. We're hosting
the service on the same platform as our applications, using Docker. Most importantly, the whole process is transparent to the user, they aren't forced to visit
country-specific URLs.</em></p>

<p><strong>Success!</strong></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debugging Cloud Foundry Stack Issues]]></title>
    <link href="http://jamesthom.as/blog/2015/07/10/debugging-cloud-foundry-stack-issues/"/>
    <updated>2015-07-10T15:27:00+01:00</updated>
    <id>http://jamesthom.as/blog/2015/07/10/debugging-cloud-foundry-stack-issues</id>
    <content type="html"><![CDATA[<p>Recent <a href="https://groups.google.com/a/cloudfoundry.org/forum/#!topic/vcap-dev/gU7rpD8MSC4">changes</a> to the Cloud Foundry stacks supported by IBM Bluemix have led to a number of <a href="http://stackoverflow.com/questions/31057357/static-buildpack-deploy-now-failing-due-to-unsupported-stack">issues</a> <a href="http://stackoverflow.com/questions/31085626/fail-to-push-static-site-to-bluemix-using-third-party-buildpack/31089127#31089127">for</a> <a href="http://stackoverflow.com/questions/31268155/bluemix-libstdc-so-6-version-glibcxx-3-4-20-not-found/31288182#31288182">users</a>. I've helped users diagnose and fix issues
that have occurred due to a mistmatches between the platform stack, applications and the buildpack. Learning a number of techniques for helping to discover and resolve these
issues and I wanted to share them with everyone else.</p>

<p>Running on Cloud Foundry's <em>Platform-as-a-Service</em> solution, we take for granted that low-level concepts like operating systems are abstracted away from the developer.</p>

<p>However, when we
run into issues it can be necessary to jump into the weeds and find out what's going on under the hood...</p>

<h2>What are Cloud Foundry "stacks"?</h2>

<p>According to the <a href="https://docs.cloudfoundry.org/concepts/stacks.html">documentation</a>...</p>

<p><blockquote><p>A stack is a prebuilt root filesystem (rootfs) which works in tandem with a buildpack and is used to support running applications.</p><footer><strong>Cloud Foundry Concepts</strong> <cite><a href='https://docs.cloudfoundry.org/concepts/stacks.html'>docs.cloudfoundry.org/concepts/&hellip;</a></cite></footer></blockquote></p>

<p>Think of the <em>stack</em> as the underlying operating-system running your application. This will be combined with the buildpack to instantiate the runtime
environment.</p>

<p>Most users don't have to care which <em>stack</em> they are running on.</p>

<p>However, if your application needs a specific version of a system library or you want to verify a specific command line application is installed, you
may need to dig deeper...</p>

<h2>What "stacks" does my platform support?</h2>

<p>Using the Cloud Foundry CLI, issue the following command to see what <em>stacks</em> are available on the platform.</p>

<p>``` sh
[16:27:30 ~]$ cf stacks
Getting stacks in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...
OK</p>

<p>name         description
lucid64      Ubuntu 10.04
seDEA        private
cflinuxfs2   Ubuntu 14.04.2 trusty
```</p>

<p>Stack information contains the unique name for each stack and the underlying operating system version.</p>

<h2>Which "stack" is my application running on?</h2>

<p>Since <a href="https://github.com/cloudfoundry/cli/releases/tag/v6.11.0">v6.11.0</a>, the <em>stack</em> for an application has been shown in the CLI application info output.</p>

<p>``` sh
[16:34:39 ~]$ cf app debug-testing
Showing health and status for app debug-testing in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...
OK</p>

<p>requested state: started
instances: 1/1
usage: 512M x 1 instances
urls: debug-testing.mybluemix.net
last uploaded: Tue Jun 16 15:47:21 UTC 2015
stack: lucid64
buildpack: SDK for Node.js(TM)</p>

<pre><code> state     since                    cpu    memory           disk           details
</code></pre>

<h1>0   running   2015-06-30 08:53:57 PM   0.0%   242.5M of 512M   196.8M of 1G</h1>

<p>```</p>

<h2>How can I choose the "stack" my application runs on?</h2>

<p>Users can set the <em>stack</em> for an application using the <em>-s</em> command-line parameter during deployment.
The stack identifier should match one of the names shown in the output from the <em>cf stacks</em> command.</p>

<p><code>sh
$ cf push -s stack_identifier
</code></p>

<h2>How are the "stacks" defined?</h2>

<p>This <a href="https://github.com/cloudfoundry/stacks">Github repository</a> contains the source files for building the <em>stacks</em>. There's a
<a href="https://docs.docker.com/reference/builder/">Dockerfile</a> for the current <a href="https://github.com/cloudfoundry/stacks/blob/master/cflinuxfs2/Dockerfile">cflinuxfs2</a> stack
to build the image used in Cloud Foundry.</p>

<h2>How can I poke around inside a "stack" locally?</h2>

<p>Using Docker, we can easily pull down the same "base" operating system used for a specifc "stack" and run locally.</p>

<p>For the <em>cflinuxfs2</em> stack, we can pull down the <a href="http://releases.ubuntu.com/14.04/">Ubuntu Trusty</a> image and run a terminal inside it.</p>

<p><code>sh
$ docker pull ubuntu:trusty
$ docker run -i -t ubuntu:trusty /bin/bash
</code></p>

<h2>How can I easily migrate existing applications to a new stack?</h2>

<p>Rather than having to re-deploy each application separately, there's a great <a href="https://github.com/simonleung8/cli-stack-changer">CF CLI plugin</a> to automatically migrate all your applications from <em>lucid64</em> to <em>cflinuxfs2</em>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making Logs Awesome - Elasticsearch in the Cloud using Docker]]></title>
    <link href="http://jamesthom.as/blog/2015/07/08/making-logs-awesome-with-elasticsearch-and-docker/"/>
    <updated>2015-07-08T10:34:00+01:00</updated>
    <id>http://jamesthom.as/blog/2015/07/08/making-logs-awesome-with-elasticsearch-and-docker</id>
    <content type="html"><![CDATA[<p><img src="/images/Logs.png"></p>

<h3><strong>Logs are boring.</strong></h3>

<p>It used to be the only time you'd be looking at your application logs was when something went wrong.</p>

<p>Logs filled up disk space until they rotated out of existence.</p>

<p>...but now businesses are increasingly focused on using data to <a href="http://www.slideshare.net/mikebrittain/metrics-driven-engineering-at-etsy">drive decisions</a>.</p>

<p><em>Which advert leads to the highest click-through rates?</em></p>

<p><em>How did that last website change affect user retention?</em></p>

<p><em>What customer devices should our website support?</em></p>

<p>Guess where the answers lie?</p>

<h4><strong>Logs.</strong></h4>

<p>Storing, processing and querying logs effectively is <a href="http://www.slideshare.net/mikebrittain/take-my-logs-please">helping businesses succeed</a>.</p>

<h2>Introducing the ELK (Elasticsearch, Logstash, Kibana) stack...</h2>

<p><img src="https://www.elastic.co/assets/blt48dcfa0db3efb772/BQIielHCAAAs2So.png"></p>

<p>Five years ago, <a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a>, an open-source full-text search engine, was
released. It's now the second most popular enterprise search engine.
Complementing this project were <a href="https://www.elastic.co/products/logstash">Logstash</a> and <a href="https://www.elastic.co/products/kibana">Kibana</a>.
Logstash was a log
processing pipeline that could normalize streaming logs into a centralised
Elasticsearch cluster. Kibana was an analytics and visualisation platform for
turning those logs into actionable insights.</p>

<p>These tools were commonly used together, now known as the ELK stack, to deliver...</p>

<p><blockquote><p>"an end-to-end stack that delivers actionable insights in real time from almost any type of structured and unstructured data source."</p></blockquote></p>

<h4><strong>ELK, making logs awesome!</strong></h4>

<p><em><em>Manually installing and configuring Elasticsearch, Logstash and Kibana is not a <a href="https://gist.github.com/ashrithr/c5c03950ef631ac63c43">trivial task</a>.</em></em></p>

<p>Luckily, there is a better way...</p>

<h2>Docker </h2>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/7/79/Docker<em>(container_engine)</em>logo.png"></p>

<p><blockquote><p>"Docker allows you to pack, ship and run any application as a lightweight container".</p></blockquote></p>

<p><a href="https://www.docker.com/">Docker</a> <em>images</em> define pre-configured environments that containers
are started from.  <a href="https://hub.docker.com/">Docker Hub</a> is the public image registry, where anyone can
publish, search and retrieve new images.</p>

<p><img src="/images/Docker%20Hub.png"></p>

<p>Rather than having to install and configure individual software packages, we
can pull down one of the many existing Docker images for the <a href="https://registry.hub.docker.com/search?q=elk">ELK stack</a>.</p>

<p><em>With one command, we can spin up an entire ELK instance on any platform with no extra configuration needed.</em></p>

<p>Magic.</p>

<h2>IBM Containers</h2>

<p>IBM recently announced <a href="https://developer.ibm.com/bluemix/2015/06/22/ibm-containers-on-bluemix/">Docker support</a> for their Platform-as-a-Service cloud service, <a href="https://console.ng.bluemix.net/">IBM Bluemix</a>. Developers can now deploy and manage Docker containers on a scalable cloud platform.</p>

<p><a href="https://developer.ibm.com/bluemix/2015/06/22/ibm-containers-on-bluemix/">IBM Containers</a> provides the following services:</p>

<ul>
<li>Private image registry</li>
<li>Elastic scaling and auto-recovery</li>
<li>Persistent storage and advanced networking configuration</li>
<li>Automated security scans</li>
<li>Integration with the IBM Bluemix cloud services.</li>
</ul>


<p><em>Using this service, we can build and test a custom ELK container in our local
development environment and "web-scale" it by pushing to the IBM Bluemix cloud platform.</em></p>

<h2>Manging Application Logs</h2>

<p>Once our ELK instance is running, we can then start to push application logs
from other applications running on IBM Bluemix into the service. We'll look at
automatically setting up a log drain to forward all applications logs into a
centralised Elasticsearch service. We can then start to drive business
decisions using data rather than intuition using Kibana, the visualisation
dashboard.</p>

<p><strong><em>This blog post will explain the technical details of using Docker to create a
customised ELK service that can be hosted on a scalable cloud platform.</em></strong></p>

<h2>Running ELK instances Using Docker </h2>

<p>Docker Hub has over forty five thousands public images available. There are multiple public images we can pull
down with a pre-configured ELK stack. Looking at the options, we're going to use the <a href="https://registry.hub.docker.com/u/sebp/elk/">sebp/elk</a>
repository because it's popular and easily modifiable with a custom configuration.</p>

<p>We're going to start by pulling the image into our local machine and running a container to check it's working...</p>

<p><code>sh
$ docker pull sebp/elk
$ docker run -p 5601:5601 -p 9200:9200 -p 5000:5000 -it --name elk sebp/elk
</code></p>

<p>That last command will start a new container from the <em>sebp/elk</em> image,
exposing the ports for Kibana (5601), Elasticsearch (9200) and Logstash (5000)
for external access. The container has been started with the <em>-i</em> flag,
interactive mode, allowing us to monitor the container logs in the console.
When the instance has started, we can view the status output from command line.</p>

<p><code>sh
$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                                                                              NAMES
42d40d1fb59c        sebp/elk:latest     "/usr/local/bin/star   27 seconds ago      Up 26 seconds       0.0.0.0:5000-&gt;5000/tcp, 0.0.0.0:5601-&gt;5601/tcp, 0.0.0.0:9200-&gt;9200/tcp, 9300/tcp   elk
</code></p>

<p>Using Mac OS X for local development, we're using the <a href="http://boot2docker.io/">Boot2Docker project</a> to host a Linux VM for deploying Docker containers locally.
With the following command, we can discover the virtual IP address for the ELK container.</p>

<p><code>sh
$ boot2docker ip
192.168.59.103
</code></p>

<p>Opening a web browser, we can now visit <em>http://192.168.59.103:5601</em> to show the Kibana application.
For now, this isn't very useful because Elasticsearch has no logs!</p>

<p>Let's fix that...</p>

<h2>Draining Logs from Cloud Foundry</h2>

<p><a href="https://www.cloudfoundry.org">Cloud Foundry</a>, the open-source project powering IBM Bluemix, supports <a href="https://docs.cloudfoundry.org/devguide/services/log-management.html">setting up a syslog drain</a>
to forward all applications logs to a third-party logging service. Full details on configuring this will be <a href="#config">shown later</a>.</p>

<p>Scott Frederick has already written an <a href="http://scottfrederick.cfapps.io/blog/2014/02/20/cloud-foundry-and-logstash">amazing blog post</a> about configuring Logstash
to support the log format used by the Cloud Foundry. Logstash expects the older RFC3164 syslog formatting by default, whilst Cloud Foundry emits log lines that follow
the newer RFC5424 standard.</p>

<p>Scott provides the following configuration file that sets up the syslog input channels, running on port 5000, along with a custom filter that converts the incoming RFC5424 logs into
an acceptable format.</p>

<p>``` sh
input {
  tcp {</p>

<pre><code>port =&gt; 5000
type =&gt; syslog
</code></pre>

<p>  }
  udp {</p>

<pre><code>port =&gt; 5000
type =&gt; syslog
</code></pre>

<p>  }
}</p>

<p>filter {
  if [type] == "syslog" {</p>

<pre><code>grok {
  match =&gt; { "message" =&gt; "%{SYSLOG5424PRI}%{NONNEGINT:syslog5424_ver} +(?:%{TIMESTAMP_ISO8601:syslog5424_ts}|-) +(?:%{HOSTNAME:syslog5424_host}|-) +(?:%{NOTSPACE:syslog5424_app}|-) +(?:%{NOTSPACE:syslog5424_proc}|-) +(?:%{WORD:syslog5424_msgid}|-) +(?:%{SYSLOG5424SD:syslog5424_sd}|-|) +%{GREEDYDATA:syslog5424_msg}" }
}
syslog_pri { }
date {
  match =&gt; [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
}
if !("_grokparsefailure" in [tags]) {
  mutate {
    replace =&gt; [ "@source_host", "%{syslog_hostname}" ]
    replace =&gt; [ "@message", "%{syslog_message}" ]
  }
}
mutate {
  remove_field =&gt; [ "syslog_hostname", "syslog_message", "syslog_timestamp" ]
}
</code></pre>

<p>  }
}</p>

<p>output {
  elasticsearch { }
}
```</p>

<p>Using this configuration, Logstash will accept and index our application logs into Elasticsearch.</p>

<p><em>Note: There is also a <a href="https://www.elastic.co/guide/en/logstash/current/plugins-outputs-syslog.html">custom plugin</a> to enable RFC5424 support.</em></p>

<h2>Building Custom Docker Images</h2>

<p>Using the custom Logstash configuration relies on building a new Docker image
with this configuration baked in. We could download the Git repository
containing the image <a href="https://github.com/spujadas/elk-docker">source files</a>, modify those and rebuild from scratch.
However, an easier way uses the existing image as a <em>base</em>, applies our
modifications on top and then generates a brand new image.</p>

<p><strong>So, how do we build our own Docker images? Using a Dockerfile.</strong></p>

<p><blockquote><p>A Dockerfile is a text document that contains all the commands you would<br/>normally execute manually in order to build a Docker image.<br/></p></blockquote></p>

<p>Reviewing the <a href="https://registry.hub.docker.com/u/sebp/elk/dockerfile/">Dockerfile</a> for the <em>sebp/elk</em> image, configuration for logstash is
stored in the <em>/etc/logstash/conf.d/</em> directory. All we need to do is replace these files with our custom configuration.</p>

<p>Creating the custom configuration locally, we define a Dockerfile with instructions for building our image.</p>

<p><code>sh
$ ls
01-syslog-input.conf 10-syslog.conf       Dockerfile
$ cat Dockerfile
FROM sebp/elk
RUN rm /etc/logstash/conf.d/01-lumberjack-input.conf
ADD ./01-syslog-input.conf /etc/logstash/conf.d/01-syslog-input.conf
ADD ./10-syslog.conf /etc/logstash/conf.d/10-syslog.conf
</code></p>

<p>The Dockerfile starts with the "sebp/elk" image as a base layer. Using the RUN command, we execute a command to remove existing input configuration. After this
the ADD command copies files from our local directory into the image.</p>

<p>We can now run the Docker build system to generate our new image.</p>

<p><code>sh
$ docker build -t jthomas/elk .
Sending build context to Docker daemon 4.608 kB
Sending build context to Docker daemon
Step 0 : FROM sebp/elk
 ---&gt; 2b71e915297f
Step 1 : RUN rm /etc/logstash/conf.d/01-lumberjack-input.conf
 ---&gt; Using cache
 ---&gt; f196b6833121
Step 2 : ADD ./01-syslog-input.conf /etc/logstash/conf.d/01-syslog-input.conf
 ---&gt; Using cache
 ---&gt; 522ba2c76b00
Step 3 : ADD ./10-syslog.conf /etc/logstash/conf.d/10-syslog.conf
 ---&gt; Using cache
 ---&gt; 79256ffaac3b
Successfully built 79256ffaac3b
$ docker images jthomas/elk
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
jthomas/elk         latest              79256ffaac3b        26 hours ago        1.027 GB
</code></p>

<p><em>...and that's it! We have a customised Docker image with our configuration changes ready for running.</em></p>

<h2>Testing Our Custom Image</h2>

<p>Before pushing this image to the cloud, we need to check it's working correctly.
Let's start by starting a new container from our custom image locally.</p>

<p><code>sh
$ docker run -p 5601:5601 -p 9200:9200 -p 5000:5000 -it --name elk jthomas/elk
</code></p>

<p>Now, use the <a href="https://github.com/cloudfoundry/cli">CF CLI</a> to access recent logs for a sample application and paste the output into
a telnet connection to port 5000 on our container.</p>

<p>``` sh
$ cf logs APP_NAME --recent
Connected, dumping recent logs for app debug-testing in org james.thomas@uk.ibm.com / space dev as james.thomas@uk.ibm.com...</p>

<p>2015-07-02T17:14:47.58+0100 [RTR/1]      OUT nodered-app.mybluemix.net - [02/07/2015:16:14:47 +0000] "GET / HTTP/1.1" 200 0 7720 "-" "Java/1.7.0" 75.126.70.42:56147 x_forwarded_for:"-" vcap_request_id:1280fe18-e53a-4bd4-40a9-2aaf7c53cc54 response_time:0.003247100 app_id:f18c2dea-7649-4567-9532-473797b0818d
2015-07-02T17:15:44.56+0100 [RTR/2]      OUT nodered-app.mybluemix.net - [02/07/2015:16:15:44 +0000] "GET / HTTP/1.1" 200 0 7720 "-" "Java/1.7.0" 75.126.70.43:38807 x_forwarded_for:"-" vcap_request_id:4dd96d84-c61d-45ec-772a-289ab2f37c67 response_time:0.003848360 app_id:f18c2dea-7649-4567-9532-473797b0818d
2015-07-02T17:16:29.61+0100 [RTR/2]      OUT nodered-app.mybluemix.net - [02/07/2015:16:14:29 +0000] "GET /red/comms HTTP/1.1" 101 0 0 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.130 Safari/537.36" 75.126.70.42:54826 x_forwarded_for:"75.126.70.42" vcap_request_id:15c2d4f8-e6ba-4a20-77b7-345aafd32e95 response_time:MissingFinishedAt app_id:f18c2dea-7649-4567-9532-473797b0818d
$ telnet 192.168.59.103 5000
Trying 192.168.59.103...
Connected to 192.168.59.103.
Escape character is '<sup>]'.</sup>
// PASTE LOG LINES....
```
Starting a web browser and opening the Kibana page, port 5601, the log lines are now available in the dashboard. Success!</p>

<h2>Pushing Docker Images To The Cloud </h2>

<p>Having successfully built and tested our custom Docker image locally, we want
to push this image to our cloud platform to allow us to start new containers
based on this image.</p>

<p>Docker supports pushing local images to the <a href="http://hub.docker.com">public registry</a> using the <em>docker push</em> command.
We can choose to use a <a href="https://blog.docker.com/2013/07/how-to-use-your-own-registry/">private registry</a>
by creating a new image tag which prefixes the repository location in the name.</p>

<p><em>IBM Containers' private registry is available at the following address, <strong>registry.ng.bluemix.net</strong>.</em></p>

<p>Let's push our custom image to the IBM Containers private registry...</p>

<p><code>sh
$ docker tag jthomas/elk registry.ng.bluemix.net/jthomas/elk
$ docker images
REPOSITORY                                     TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
jthomas/elk                                   latest              79256ffaac3b        43 hours ago        1.027 GB
registry.ng.bluemix.net/jthomas/elk           latest              79256ffaac3b        43 hours ago        1.027 GB
$ docker push registry.ng.bluemix.net/jthomas/elk
The push refers to a repository [registry.ng.bluemix.net/jthomas/elk] (len: 1)
Sending image list
Pushing repository registry.ng.bluemix.net/jthomas/elk (1 tags)
511136ea3c5a Image successfully pushed
...
79256ffaac3b: Image successfully pushed
Pushing tag for rev [79256ffaac3b] on {https://registry.ng.bluemix.net/v1/repositories/jthomas/elk/tags/latest}
</code></p>

<p>Pushing custom images from a local environment can be a slow process. For the <em>elk</em> image, this means transferring over one gigabyte of data
to the external registry.</p>

<p><em>We can speed this up by using IBM Containers to create our image from the Dockerfile, rather than uploading the built image.</em></p>

<p>Doing this from the command line requires the use of the IBM Containers command-line application.</p>

<h2>Managing IBM Containers</h2>

<p>IBM Containers enables you to manage your containers from the command-line with <a href="https://www.ng.bluemix.net/docs/starters/container_cli_ov.html">two options</a>...</p>

<ul>
<li><em><a href="https://www.ng.bluemix.net/docs/starters/container_cli_ov.html#installcontainercfplugin">IBM Containers Plug-in</a> for the Cloud Foundry CLI.</em></li>
<li><em><a href="https://www.ng.bluemix.net/docs/starters/container_cli_ov_ice.html">IBM Containers Extension</a>, standalone command-line application.</em></li>
</ul>


<p>Both approaches handle the interactions between the local and remote Docker hosts, while providing
extra functionality not supported natively by Docker.</p>

<p><em>Full details on the differences and installation procedures
for the two applications are available <a href="https://www.ng.bluemix.net/docs/starters/container_cli_ov.html">here</a>.</em></p>

<h2>Building Images Using IBM Containers</h2>

<p>Building our image using the IBM Containers service uses the same syntax as <a href="https://docs.docker.com/reference/commandline/build/">Docker build</a>. Local files
from the current directory will be sent with the Dockerfile to the remote service. Once the image has
been built, we can verify it's available in the remote repository.</p>

<p><code>sh
$ ice build -t registry.ng.bluemix.net/jthomas/elk .
zipped tar size: 706
Posting 706 bytes... It may take a while...
Step 0 : FROM sebp/elk
 ---&gt; 2b71e915297f
Step 1 : RUN rm /etc/logstash/conf.d/01-lumberjack-input.conf
 ---&gt; Using cache
 ---&gt; ed13d91e0197
Step 2 : ADD ./01-syslog-input.conf /etc/logstash/conf.d/01-syslog-input.conf
 ---&gt; Using cache
 ---&gt; 808a4c7410c7
Step 3 : ADD ./10-syslog.conf /etc/logstash/conf.d/10-syslog.conf
 ---&gt; Using cache
 ---&gt; 117e4454b015
Successfully built 117e4454b015
The push refers to a repository [registry.ng.bluemix.net/jthomas/elk] (len: 1)
Sending image list
Pushing repository registry.ng.bluemix.net/jthomas/elk (1 tags)
Image 117e4454b015 already pushed, skipping
Pushing tag for rev [117e4454b015] on {https://registry.ng.bluemix.net/v1/repositories/jthomas/elk/tags/latest}
$ ice images
REPOSITORY                                TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
registry.ng.bluemix.net/jthomas/elk       latest              5454d3ec-0f3        44 hours ago        0 B
registry.ng.bluemix.net/ibmliberty        latest              3724d2e0-06d        9 days ago          0 B
registry.ng.bluemix.net/ibmnode           latest              9435349e-8b4        9 days ago          0 B
</code></p>

<p>All private repositories on IBM Bluemix have two official images for supported versions of <a href="https://www.ng.bluemix.net/docs/starters/container_cli_ov.html#container_images_node">NodeJS</a> and <a href="https://www.ng.bluemix.net/docs/starters/container_cli_ov.html#container_images_liberty">Websphere Liberty</a>.</p>

<p><em>We can now see the third image is the custom ELK stack that was built.</em></p>

<h2>Starting ELK Containers</h2>

<p>Starting containers from images in the IBM Containers registry can be done using the command-line applications or through the <a href="http://bluemix.net">IBM Bluemix UI</a>.
In this example, we'll be using the IBM Bluemix UI to start and configure a new ELK container from our pre-configured image.</p>

<p>Logging into the IBM Bluemix, the <em>Catalogue</em> page shows the list of available images used to create new containers. We have both the official
images from IBM Containers and our custom ELK service.</p>

<p><img src="/images/Container%20Images.png"></p>

<p>Selecting the <em>ELK</em> image, we can configure and run a new container from this
image. Setting up a new container with a public IP address,
memory limit to 1GB and expose the same ports as running locally (5000, 5601
and 9200).</p>

<p><img src="/images/Create%20Container.png"></p>

<p>Clicking the <em>Create</em> button, IBM Bluemix will provision and start our
new container.</p>

<p>Once the container has started, we can view the <em>Dashboard</em> page for this instance. Here we can view
details about the container instance, modify the running state and access monitoring and logs tools.</p>

<p><img src="/images/Container%20Overview.png">
<img src="/images/Container%20Monitoring.png"></p>

<p><em>...and that's it! We now have our ELK service running using IBM Containers
ready to start processing logs from our applications.</em></p>

<p>Visiting the external IP address assigned to the container on the Kibana
application port (5601) shows the Kibana web interface demonstrating our
container has started correctly.</p>

<h2><a name="config"></a>Draining Cloud Foundry Logs</h2>

<p>Cloud Foundry supports draining applications logs to a <a href="http://docs.cloudfoundry.org/devguide/services/log-management.html">third-party syslog service</a>.
The ELK container has a syslog drain configured on port 5000 of the public IP address bound to the instance.</p>

<p>Binding this custom syslog drain to Cloud Foundry applications uses a <a href="https://docs.cloudfoundry.org/devguide/services/user-provided.html">custom user-provided service</a>.
Creating user-provided services using the CF CLI, there is a special flag, <em>-l</em>, that notifies the platform this service is a syslog drain. Binding this special syslog
drain service to an application will automatically set up log forwarding. Once the application has been restarted, logs will start to flow into the external service.</p>

<p><code>sh
$ cf cups logstash-drain -l syslog://[CONTAINER_IP]:5000
$ cf bind-service [app-name] logstash-drain
$ cf restart [app-name]
</code></p>

<p><em>Cloud Foundry supports multiple syslog drains for the same application.</em></p>

<p>Testing this out is as simple as visiting our application to generate sample logs and then looking at the Kibana page to see they are showing up.
Here is a screenshot of the expected output when our ELK container is successfully processing logs from a Cloud Foundry application.</p>

<p><img src="/images/Kibana.png"></p>

<h2>Conclusion</h2>

<p>Elastic Search, Kibana and Logstash is the modern log processing framework.
Using Docker, we've been able to create a custom ELK service without manually
installing and configuring a multitude of different software packages. Pushing
this image to the IBM Containers platform means we can spin up new ELK
containers on-demand within minutes!</p>

<p><blockquote><p>Elasticsearch, Docker and IBM Containers... Making Logs Awesome.</p></blockquote></p>
]]></content>
  </entry>
  
</feed>
