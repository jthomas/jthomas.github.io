<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[James Thomas]]></title>
  <link href="http://jamesthom.as/atom.xml" rel="self"/>
  <link href="http://jamesthom.as/"/>
  <updated>2019-07-30T12:39:16+01:00</updated>
  <id>http://jamesthom.as/</id>
  <author>
    <name><![CDATA[James Thomas]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hosting Static Websites on IBM Cloud]]></title>
    <link href="http://jamesthom.as/blog/2019/07/24/hosting-static-websites-on-ibm-cloud/"/>
    <updated>2019-07-24T10:15:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/07/24/hosting-static-websites-on-ibm-cloud</id>
    <content type="html"><![CDATA[<p>This blog post explains how to host a <a href="https://en.wikipedia.org/wiki/Static_web_page">static website</a> on <a href="https://cloud.ibm.com">IBM Cloud</a>. These websites are rendered client-side by the browser from static assets, like HTML, CSS and JS files. They do not need a server-side component to create pages dynamically at runtime. Static websites are often combined with backend APIs to create <a href="https://en.wikipedia.org/wiki/Single-page_application">Single Page Applications</a>.</p>

<p>Hosting static websites on IBM Cloud uses <a href="https://www.ibm.com/cloud/object-storage">Cloud Object Storage</a> (COS) and <a href="https://www.ibm.com/cloud/cloud-internet-services">Cloud Internet Services</a> (CIS) (with <a href="https://cloud.ibm.com/docs/infrastructure/cis?topic=cis-use-page-rules">Page Rules</a> and <a href="https://cloud.ibm.com/docs/infrastructure/cis?topic=cis-edge-functions">Edge Function</a>s). These services provide the following features needed to serve static websites.</p>

<ul>
<li><strong>Auto-serving static assets from provider-managed HTTP service (Cloud Object Storage).</strong></li>
<li><strong>Custom domain support to serve content from user-controlled domain name (CIS - Page Rules).</strong></li>
<li><strong>Configurable Index and Error documents (CIS - Edge Functions).</strong></li>
</ul>


<p>Here are the steps needed to host a static website on IBM Cloud by combining those services.</p>

<h1>Serving static assets</h1>

<p>IBM Cloud Object Storage is a scalable storage solution for cloud applications. Files are managed through a <a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-compatibility-api">RESTful HTTP API</a> and stored in user-defined collections called &#8220;buckets&#8221;. Bucket files are returned as HTTP responses from <a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-compatibility-api#compatibility-api-object">HTTP GET requests</a>.</p>

<p>COS supports an optional &#8221;<em>anonymous read-only access</em>&#8221; <a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-iam-public-access">setting for buckets</a>. This means all files in the bucket will be accessible using anonymous HTTP GET requests.</p>

<p>Putting HTML, CSS and JS files in a public bucket allows static websites to be served directly by COS. Users are charged for bandwidth used and HTTP requests received for all bucket files.</p>

<h3>Create IBM Cloud Object Storage instance</h3>

<p><em>If you already have an instance of Cloud Object Storage you can skip this step&#8230;</em></p>

<ul>
<li>Provision <a href="https://cloud.ibm.com/catalog/services/cloud-object-storage">a new instance</a> of IBM Cloud Object Storage</li>
</ul>


<h3>Create IBM Cloud Object Storage Bucket</h3>

<ul>
<li>Open the COS instance from the <a href="https://cloud.ibm.com/resources">Resource List</a>.</li>
<li><a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-getting-started#gs-create-buckets">Create a new COS bucket</a> to host the static site files.

<ul>
<li>Choose a Bucket name</li>
<li>Choose the <code>Resiliency,</code> <code>Location</code> and <code>Storage Class</code> options for the bucket.</li>
</ul>
</li>
</ul>


<p><em>Any choices for these options can be used - it does not affect the static site hosting capability. For more details on what they mean, please see this <a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-classes">documentation</a>.</em></p>

<h3>Upload Static Assets To Bucket</h3>

<ul>
<li><a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-upload">Upload static file assets</a> to the new bucket.</li>
</ul>


<h3>Enable Public Access to bucket files</h3>

<ul>
<li>Click the <em>&#8220;Access Policies&#8221;</em> menu item from the bucket level menu.</li>
<li>Click the &#8221;<em>Public Access</em>&#8221; tab from the bucket access policy page.</li>
<li>Check the Access Group drop-down has &#8221;<em>Public Access</em>&#8221; option selected.</li>
<li>Click the &#8221;<em>Create access policy</em>&#8221; and then &#8221;<em>Enable</em>&#8221; on the pop menu.</li>
</ul>


<p><img src="http://jamesthom.as/images/static-site-hosting/bucket-access-policy.png" alt="Bucket access policy" /></p>

<h3>Check bucket files are accessible</h3>

<p>Bucket files should now be accessible using the service endpoint URL, bucket id and file names. COS supports providing the bucket name in the URL path or a sub-domain on the service endpoint.</p>

<ul>
<li>Open the &#8221;<em>Configuration</em>&#8221; panel on the bucket page.</li>
<li>Retrieve the <strong>public endpoint</strong> shown, e.g. <code>s3.&lt;REGION&gt;.cloud-object-storage.appdomain.cloud</code></li>
</ul>


<p><img src="http://jamesthom.as/images/static-site-hosting/public-endpoint-hostname.png" alt="Public endpoint hostname" /></p>

<p><strong>Bucket files (like <code>index.html</code>) should now be accessible by a web browser.</strong> COS supports both HTTP and HTTPS traffic. Bucket files are available using the following URLs.</p>

<h4>vhost addressing</h4>

<p><code>&lt;BUCKET_NANME&gt;.s3.eu-gb.cloud-object-storage.appdomain.cloud/index.html</code></p>

<h4>url path addressing</h4>

<p><code>s3.&lt;REGION&gt;.cloud-object-storage.appdomain.cloud/&lt;BUCKET_NANME&gt;/index.html</code></p>

<p>Bucket files can now be referenced directly in external web applications. COS buckets are often used to store large application assets like videos or images. <strong>For hosting an entire website, it is often necessary to serve content from a custom domain name, rather than the COS bucket hostname.</strong></p>

<h1>Custom domain support</h1>

<p>Cloud Internet Services Page Rules can <a href="https://cloud.ibm.com/docs/infrastructure/cis?topic=cis-resolve-override-cos">automatically configure custom domain</a> support for COS buckets.</p>

<p><a href="https://en.wikipedia.org/wiki/CNAME_recor">CNAME</a> DNS records are created to alias the custom domain to the COS bucket hostname. All traffic to the custom domain will then be forwarded to the COS service.</p>

<p>When COS serves files from bucket sub-domains, the HTTP  <code>Host</code> <a href="https://stackoverflow.com/questions/43156023/what-is-http-host-header">request header value</a> to determine the bucket name. With CNAME DNS records, this header value will still refer to the custom domain, rather than the bucket sub-domain. This field needs to be dynamically updated with the correct value.</p>

<h3>Create IBM Cloud Internet Services instance</h3>

<ul>
<li>Provision a new instance of <a href="https://cloud.ibm.com/catalog/services/internet-services">Cloud Internet Services</a>.</li>
</ul>


<h3>Register Custom Domain name with Cloud Internet Services</h3>

<ul>
<li>Follow the <a href="https://cloud.ibm.com/docs/infrastructure/cis?topic=cis-getting-started#add-configure-your-domain">documentation</a> on how to register a custom domain with Cloud Internet Services.</li>
</ul>


<p><em>This process involves delegating name server control for the domain over to IBM Cloud Internet Services.</em></p>

<h3>Configure Page Rules and DNS records (automatic)</h3>

<p>Cloud Internet Services <a href="https://cloud.ibm.com/docs/infrastructure/cis?topic=cis-resolve-override-cos">can automatically set up</a> Page Rules and DNS records needed to forward custom domain traffic to COS buckets. This automatically exposes the bucket as <code>bucket-name.your-domain.com</code>. If you want to change this default sub-domain name, follow the manual steps in the next section.</p>

<ul>
<li>Click the Performance drop-down menu and click the &#8221;<em>Page Rules</em>&#8221; link.</li>
<li>Click the &#8221;<em>Create rule</em>&#8221; button from the table.</li>
<li>Select the Rule Behaviour Setting as &#8221;<em>Resolve Override with COS</em>&#8221;</li>
<li>Select the correct COS instance and bucket.</li>
<li>Click the &#8221;<em>Create</em>&#8221; button.</li>
</ul>


<p><img src="http://jamesthom.as/images/static-site-hosting/auto-page-rule.png" alt="Auto Page Rules" /></p>

<p><strong>Once DNS records have propagated, bucket files should be accessible using the custom domain</strong>:  <code>http(s)://&lt;CUSTOM_DOMAIN&gt;/index.html</code>.</p>

<h3>Configure Page Rules and DNS records (manual)</h3>

<p><em>These steps only need following if you haven&#8217;t done the section above‚Ä¶.</em></p>

<p>Create the Page Rule to modify the HTTP host header.</p>

<ul>
<li>Click the Performance drop-down menu and select the &#8221;<em>Page Rules</em>&#8221; link.</li>
<li>Click the &#8221;<em>Create rule</em>&#8221; button from the table.</li>
<li>Set the URL match field to be <code>&lt;SUB_DOMAIN&gt;.&lt;CUSTOM_DOMAIN&gt;/*</code></li>
<li>Select the Rule Behaviour Setting as &#8221;<em>Host Header Override</em>&#8221; as the custom bucket sub-domain:<code>&lt;BUCKET_NANME&gt;.&lt;REGION&gt;.eu-gb.cloud-object-storage.appdomain.cloud</code></li>
</ul>


<p>Create the DNS CNAME record to forward traffic to COS.</p>

<ul>
<li>Click the Reliability drop-down menu and click the &#8221;<em>DNS</em>&#8221; menu entry.</li>
<li>Add a new DNS record with the following values.

<ul>
<li><strong>Type:</strong> <em>CNAME</em></li>
<li><strong>Name:</strong> <em>&lt;custom subdomain host></em></li>
<li><strong>TTL:</strong> <em>Automatic</em></li>
<li><strong>Alias Domain Name:</strong> <em>&lt;COS bucket sub-domain></em></li>
</ul>
</li>
</ul>


<p><em>Name</em> is the sub-domain on the custom domain (e.g. <code>www</code>) through which the COS bucket will be accessible. <em>Alias Domain Name</em> is the COS bucket sub-domain from above, e.g. <code>&lt;BUCKET_NANME&gt;.&lt;REGION&gt;.eu-gb.cloud-object-storage.appdomain.cloud</code></p>

<ul>
<li>Once the record is added, set the <code>Proxy</code> field to true. This is necessary for the page rules to work.</li>
</ul>


<p><strong>Once DNS records have propagated, bucket files should be accessible using the custom domain.</strong></p>

<h1>Configurable Index and Error pages</h1>

<p>COS will now serve static assets from a custom sub-domain, where file names are explicitly included in the URL, e.g. <code>http(s)://&lt;CUSTOM_DOMAIN&gt;/index.html</code>. This works fine for static websites with two exceptions, the default document for the web site and the error page.</p>

<p>When a user visits the COS bucket sub-domain without an explicit file path (<code>http(s)://&lt;CUSTOM_DOMAIN&gt;</code>), the COS service will return the <a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations#compatibility-api-list-objects-v2">bucket file list</a>, rather than the site index page. Additionally, if a user requests a missing file, COS returns an <a href="https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-compatibility-common#compatibility-errors">XML error message</a> rather than a custom error page.</p>

<p>Both issues can be resolved using <a href="https://www.ibm.com/cloud/blog/edge-computing-for-serverless-applications?mhsrc=ibmsearch_a&amp;mhq=edge%20functions">Edge Functions</a>, a new feature in Cloud Internet Services.</p>

<h3>Edge Functions</h3>

<p><a href="https://cloud.ibm.com/docs/infrastructure/cis?topic=cis-edge-functions">Edge functions</a> are JavaScript source files deployed to Cloudflare&#8217;s Edge locations. They can dynamically modify HTTP traffic passing through Cloudflare&#8217;s network (for domains you control). Custom edge functions are triggered on configurable URL routes. Functions are passed the incoming HTTP request and control the HTTP response returned.</p>

<h3>Add Edge Function to provide Index &amp; Error Documents</h3>

<p>Using a custom edge function, HTTP traffic to the custom sub-domain can be modified to support Index and Error documents. Incoming HTTP requests without an explicit file name can be changed to use the index page location. HTTP 404 responses returned from COS can be replaced with a custom error page.</p>

<ul>
<li>Open the &#8221;<em>Edge Functions</em>&#8221; page from the Cloud Internet Services instance homepage.</li>
<li>Click the &#8221;<em>Create</em>&#8221; icon on the &#8221;<em>Actions</em>&#8221; tab.</li>
<li>Enter &#8221;<em>route-index-and-errors</em>&#8221; in the  action name field.</li>
<li>Paste the following <a href="https://gist.github.com/jthomas/3c6c1db53e6f8ae7e70e2238b8c3374b">source code</a> into the action body section.</li>
</ul>


<p><em>The <code>INDEX_DOCUMENT</code> and <code>ERROR_DOCUMENT</code> values control the index and error pages used to redirect requests. Replace these values with the correct page locations for the static site being hosted.</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">INDEX_DOCUMENT</span> <span class="o">=</span> <span class="s1">&#39;index.html&#39;</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">ERROR_DOCUMENT</span> <span class="o">=</span> <span class="s1">&#39;404.html&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="nx">addEventListener</span><span class="p">(</span><span class="s1">&#39;fetch&#39;</span><span class="p">,</span> <span class="nx">event</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">event</span><span class="p">.</span><span class="nx">respondWith</span><span class="p">(</span><span class="nx">handleRequest</span><span class="p">(</span><span class="nx">event</span><span class="p">.</span><span class="nx">request</span><span class="p">))</span>
</span><span class='line'><span class="p">})</span>
</span><span class='line'>
</span><span class='line'><span class="nx">async</span> <span class="kd">function</span> <span class="nx">handleRequest</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">url</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">URL</span><span class="p">(</span><span class="nx">request</span><span class="p">.</span><span class="nx">url</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// if request is a directory path, append the index document.</span>
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="nx">url</span><span class="p">.</span><span class="nx">pathname</span><span class="p">.</span><span class="nx">endsWith</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">))</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">url</span><span class="p">.</span><span class="nx">pathname</span> <span class="o">=</span> <span class="err">`</span><span class="nx">$</span><span class="p">{</span><span class="nx">url</span><span class="p">.</span><span class="nx">pathname</span><span class="p">}</span><span class="nx">$</span><span class="p">{</span><span class="nx">INDEX_DOCUMENT</span><span class="p">}</span><span class="err">`</span>
</span><span class='line'>    <span class="nx">request</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Request</span><span class="p">(</span><span class="nx">url</span><span class="p">,</span> <span class="nx">request</span><span class="p">)</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">response</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">fetch</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// if bucket file is missing, return error page.</span>
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="nx">response</span><span class="p">.</span><span class="nx">status</span> <span class="o">===</span> <span class="mi">404</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">url</span><span class="p">.</span><span class="nx">pathname</span> <span class="o">=</span> <span class="nx">ERROR_DOCUMENT</span>
</span><span class='line'>    <span class="nx">request</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Request</span><span class="p">(</span><span class="nx">url</span><span class="p">,</span> <span class="nx">request</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">response</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">fetch</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">response</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Response</span><span class="p">(</span><span class="nx">response</span><span class="p">.</span><span class="nx">body</span><span class="p">,</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">status</span><span class="o">:</span> <span class="mi">404</span><span class="p">,</span>
</span><span class='line'>      <span class="nx">statusText</span><span class="o">:</span> <span class="s1">&#39;Not Found&#39;</span><span class="p">,</span>
</span><span class='line'>      <span class="nx">headers</span><span class="o">:</span> <span class="nx">response</span><span class="p">.</span><span class="nx">headers</span>
</span><span class='line'>    <span class="p">})</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="nx">response</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Click the &#8221;<em>Save</em>&#8221; button.</li>
</ul>


<h3>Set up Triggers for Edge Function</h3>

<ul>
<li>Select the &#8221;<em>Triggers</em>&#8221; panel from the Edge Functions page.</li>
<li>Click the &#8221;<em>Add trigger</em>&#8221; icon.</li>
<li>Set the Trigger URL to <code>http://&lt;SUB_DOMAIN&gt;.&lt;CUSTOM_DOMAIN&gt;/*</code>.</li>
<li>Select the &#8221;<em>route-index-and-errors</em>&#8221; action from the drop-down menu.</li>
<li>Click the &#8221;<em>Save</em>&#8221; button.</li>
</ul>


<h3>Test Index and Error Pages</h3>

<p>Having set up the trigger and edge function, HTTP requests to the root path on the custom sub-domain will return the index page. Accessing invalid bucket files will also return the error page, rather than the COS error response.</p>

<ul>
<li>Confirm that <code>http://&lt;SUB_DOMAIN&gt;.&lt;CUSTOM_DOMAIN&gt;/</code> returns the same page as <code>http://&lt;SUB_DOMAIN&gt;.&lt;CUSTOM_DOMAIN&gt;/index.html</code></li>
<li>Confirm that <code>http://&lt;SUB_DOMAIN&gt;.&lt;CUSTOM_DOMAIN&gt;/missing-page.html</code> returns the error page. This should be different to the XML error response returned by visiting <code>&lt;BUCKET_NANME&gt;.s3.&lt;REGION&gt;.cloud-object-storage.appdomain.cloud/missing-page.html</code>.</li>
</ul>


<p><strong>If this all works - the site is working! IBM Cloud is now hosting a static website using Cloud Object Storage and Cloud Internet Services with Page Rules and Edge Functions.</strong> üéâüéâüéâ</p>

<h2>Summary</h2>

<p>Static web sites can be hosted on IBM Cloud using Cloud Object Storage and Cloud Internet Services.</p>

<p>Cloud Object stores page files needed to render the static website. Anonymous bucket file access means files are accessible as public HTTP endpoints, without having to run infrastructure to serve the assets.</p>

<p>Cloud Internet Services forwards HTTP traffic from a custom domain to the bucket hostname. DNS CNAME records are used to resolve the sub-domain as the custom bucket hostname. Page Rules override HTTP request headers to make this work. Edge Functions are used to implement configurable Index and Error documents, by dynamically modifying in-flight requests with custom JavaScript.</p>

<p>Hosting static web sites using this method can be much cheaper (and easier) than traditional infrastructure. Developers only get charged for actual site usage, based on bandwidth and HTTP requests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Connecting to IBM Cloud Databases for Redis from Node.js]]></title>
    <link href="http://jamesthom.as/blog/2019/07/22/connecting-to-ibm-cloud-databases-for-redis-from-node-dot-js/"/>
    <updated>2019-07-22T12:31:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/07/22/connecting-to-ibm-cloud-databases-for-redis-from-node-dot-js</id>
    <content type="html"><![CDATA[<p>This blog post explains how to connect to an <a href="https://www.ibm.com/cloud/databases-for-redis">IBM Cloud Databases for Redis</a> instance from a <a href="https://nodejs.org/en/">Node.js</a> application. There is a (small) difference between the connection details needed for an IBM Cloud Databases for Redis instance compared to a local instance of the open-source database. This is due to all IBM Cloud Databases using <a href="https://cloud.ibm.com/docs/services/databases-for-redis?topic=databases-for-redis-external-app#driver-tls-and-self-signed-certificate-support">secured TLS connections</a> with <a href="https://en.wikipedia.org/wiki/Self-signed_certificate">self-signed certificates</a>.</p>

<p><em>I keep running into this issue (and forgetting how to fix it</em> ü§¶‚Äç‚ôÇÔ∏è<em>), so I&#8217;m documenting the solution here to help myself (and others) who might run into it‚Ä¶</em> ü¶∏‚Äç‚ôÇÔ∏è</p>

<h2>Connecting to Redis (without TLS connections)</h2>

<p>Most Node.js application use the <code>redis</code> <a href="https://www.npmjs.com/package/redis">NPM library</a> to interact with an instance of the database. This library has a <code>createClient</code> <a href="">method</a> which returns an instance of the client. The Node.js application passes a connection string into the <code>createClient</code> method. This string contains the hostname, port, username and password for the database instance.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">redis</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s2">&quot;redis&quot;</span><span class="p">),</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">url</span> <span class="o">=</span> <span class="s1">&#39;redis://user:secret@localhost:6379/&#39;</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">client</span> <span class="o">=</span> <span class="nx">redis</span><span class="p">.</span><span class="nx">createClient</span><span class="p">(</span><span class="nx">url</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>The client fires a <code>connect</code> event once the <a href="https://github.com/NodeRedis/node_redis#connection-and-other-events">connection is established</a> or an <code>error</code> event if <a href="https://github.com/NodeRedis/node_redis#connection-and-other-events">issues are encountered</a>.</p>

<h2>IBM Cloud Databases for Redis Service Credentials</h2>

<p>IBM Cloud Databases for Redis provide service credentials through the <a href="https://cloud.ibm.com/docs/services/databases-for-redis?topic=databases-for-redis-connection-strings#the-_service-credentials_-panel">instance management console</a>. Service credentials are JSON objects with connection properties for client libraries, the CLI and other tools. Connection strings for the Node.js client library are available in the <code>connection.rediss.composed</code> field.</p>

<p><strong><em>So, I just copy this field value and use with the <code>redis.createClient</code> method? Not so fast&#8230;</em></strong></p>

<p>IBM Cloud Databases for Redis uses TLS to secure all connections to the Redis instances. This is denoted by the connection string using the <code>rediss://</code> URL prefix, rather than <code>redis://</code>. Using that connection string (without further connection properties), will lead to the following error being thrown by the Node.js application.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nb">Error</span><span class="o">:</span> <span class="nx">Redis</span> <span class="nx">connection</span> <span class="nx">to</span> <span class="o">&lt;</span><span class="nx">id</span><span class="o">&gt;</span><span class="p">.</span><span class="nx">databases</span><span class="p">.</span><span class="nx">appdomain</span><span class="p">.</span><span class="nx">cloud</span><span class="o">:</span><span class="nx">port</span> <span class="nx">failed</span> <span class="o">-</span> <span class="nx">read</span> <span class="nx">ECONNRESET</span>
</span><span class='line'>  <span class="nx">at</span> <span class="nx">TCP</span><span class="p">.</span><span class="nx">onread</span> <span class="p">(</span><span class="nx">net</span><span class="p">.</span><span class="nx">js</span><span class="o">:</span><span class="mi">657</span><span class="o">:</span><span class="mi">25</span><span class="p">)</span> <span class="nx">errno</span><span class="o">:</span> <span class="s1">&#39;ECONNRESET&#39;</span><span class="p">,</span> <span class="nx">code</span><span class="o">:</span> <span class="s1">&#39;ECONNRESET&#39;</span><span class="p">,</span> <span class="nx">syscall</span><span class="o">:</span> <span class="s1">&#39;read&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>If the <code>createClient</code> forces a TLS connection to be used <code>createClient(url, { tls: {} })</code>, this error will be replaced with a different one about self-signed certificates.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nb">Error</span><span class="o">:</span> <span class="nx">Redis</span> <span class="nx">connection</span> <span class="nx">to</span> <span class="o">&lt;</span><span class="nx">id</span><span class="o">&gt;</span><span class="p">.</span><span class="nx">databases</span><span class="p">.</span><span class="nx">appdomain</span><span class="p">.</span><span class="nx">cloud</span><span class="o">:</span><span class="nx">port</span> <span class="nx">failed</span> <span class="nx">failed</span> <span class="o">-</span> <span class="nx">self</span> <span class="nx">signed</span> <span class="nx">certificate</span> <span class="k">in</span> <span class="nx">certificate</span> <span class="nx">chain</span>
</span><span class='line'>    <span class="nx">at</span> <span class="nx">TLSSocket</span><span class="p">.</span><span class="nx">onConnectSecure</span> <span class="p">(</span><span class="nx">_tls_wrap</span><span class="p">.</span><span class="nx">js</span><span class="o">:</span><span class="mi">1055</span><span class="o">:</span><span class="mi">34</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">at</span> <span class="nx">TLSSocket</span><span class="p">.</span><span class="nx">emit</span> <span class="p">(</span><span class="nx">events</span><span class="p">.</span><span class="nx">js</span><span class="o">:</span><span class="mi">182</span><span class="o">:</span><span class="mi">13</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">at</span> <span class="nx">TLSSocket</span><span class="p">.</span><span class="nx">_finishInit</span> <span class="p">(</span><span class="nx">_tls_wrap</span><span class="p">.</span><span class="nx">js</span><span class="o">:</span><span class="mi">635</span><span class="o">:</span><span class="mi">8</span><span class="p">)</span> <span class="nx">code</span><span class="o">:</span> <span class="s1">&#39;SELF_SIGNED_CERT_IN_CHAIN&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>Hmmmm, how to fix this?</em> ü§î</p>

<h2>Connecting to Redis (with TLS connections)</h2>

<p>All connections to IBM Cloud Databases are secured with TLS using self-signed certificates. Public certificates for the signing authorities are provided as Base64 strings in the service credentials. These certificates can be provided in the client constructor to support self-signed TLS connections.</p>

<p><strong><em>Here are the steps needed to use those self-signed certificates with the client library&#8230;</em></strong></p>

<ul>
<li>Extract the <code>connection.rediss.certificate.certificate_base64</code> value from the service credentials.</li>
</ul>


<p><img src="http://jamesthom.as/images/redis-certificates.png" alt="Redis Service Credentials" /></p>

<ul>
<li>Decode the Base64 string in Node.js to extract the PEM certificate string.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">ca</span> <span class="o">=</span> <span class="nx">Buffer</span><span class="p">.</span><span class="nx">from</span><span class="p">(</span><span class="nx">cert_base64</span><span class="p">,</span> <span class="s1">&#39;base64&#39;</span><span class="p">).</span><span class="nx">toString</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Provide the certificate file string as the <code>ca</code> property in the <code>tls</code> object for the client constructor.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">tls</span> <span class="o">=</span> <span class="p">{</span> <span class="nx">ca</span> <span class="p">};</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">client</span> <span class="o">=</span> <span class="nx">redis</span><span class="p">.</span><span class="nx">createClient</span><span class="p">(</span><span class="nx">url</span><span class="p">,</span> <span class="p">{</span> <span class="nx">tls</span> <span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>‚Ä¶Relax! üòé</li>
</ul>


<p><em>The <code>tls</code> property is passed through to the <code>tls.connect</code> <a href="https://nodejs.org/api/tls.html#tls_tls_connect_options_callback">method</a> in Node.js, which is used to setup the TLS connection. This method supports a <code>ca</code> parameter to extend the trusted CA certificates pre-installed in the system. By providing the self-signed certificate using this property, the errors above will not be seen.</em></p>

<h2>Conclusion</h2>

<p>It took me a while to <a href="https://compose.com/articles/ssl-connections-arrive-for-redis-on-compose/">work out</a> how to connect to TLS-secured Redis instances from a Node.js application. <a href="https://stackoverflow.com/questions/10888610/ignore-invalid-self-signed-ssl-certificate-in-node-js-with-https-request/39099130#39099130">Providing the self-signed certificate</a> in the client constructor is a much better solution than having to <a href="https://stackoverflow.com/a/21961005/1427084">disable  all unauthorised TLS connections</a>!</p>

<p>Since I don&#8217;t write new Redis client code very often, I keep forgetting the correct constructor parameters to make this work. Turning this solution into a blog post will (hopefully) embed it in my brain (or at least provide a way to find the answer instead of having to grep through old project code). This might even be useful to others Googling for a solution to those error messages&#8230;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Serverless APIs for MAX models]]></title>
    <link href="http://jamesthom.as/blog/2019/07/02/serverless-max-models/"/>
    <updated>2019-07-02T10:25:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/07/02/serverless-max-models</id>
    <content type="html"><![CDATA[<p>IBM&#8217;s <a href="https://developer.ibm.com/exchanges/models/">Model Asset eXchange</a> provides a <a href="https://developer.ibm.com/exchanges/models/all/">curated list</a> of free Machine Learning models for developers. Models currently published include detecting <a href="https://developer.ibm.com/exchanges/models/all/max-facial-emotion-classifier/">emotions</a> or <a href="https://developer.ibm.com/exchanges/models/all/max-facial-age-estimator/">ages</a> in faces from images, <a href="https://developer.ibm.com/exchanges/models/all/max-weather-forecaster/">forecasting the weather</a>, converting <a href="https://developer.ibm.com/exchanges/models/all/max-speech-to-text-converter/">speech to text</a> and more. Models are pre-trained and ready for use in the cloud.</p>

<p>Models are published as series of <a href="https://hub.docker.com/search?q=codait&amp;type=image">public Docker images</a>. Images automatically expose a HTTP API for model predictions. Documentation in the model repositories explains how to run images locally (using Docker) or deploy to the cloud (using Kubernetes). This got me thinking‚Ä¶</p>

<p><strong>Could MAX models be used from serverless functions?</strong> ü§î</p>

<p>Running machine learning models on serverless platforms can take advantage of the horizontal scalability to process large numbers of computationally intensive classification tasks in parallel. Coupled with the serverless pricing structure (&#8221;<em>no charge for idle</em>&#8221;), this can be an extremely cheap and effective way to perform model classifications in the cloud.</p>

<p><strong>CHALLENGE ACCEPTED!</strong> ü¶∏‚Äç‚ôÇÔ∏èü¶∏‚Äç‚ôÄÔ∏è</p>

<p>After a couple days of experimentation, I had worked out an easy way to <a href="https://github.com/jthomas/serverless-max-models">automatically expose MAX models as Serverless APIs</a> on <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a>.  üéâüéâüéâ</p>

<p><em>I&#8217;ve given instructions below on how to create those APIs from the models using a simple script. If you just want to use the models, follow those instructions. If you are interested in understanding how this works, keep reading as I explain afterwards what I did&#8230;</em></p>

<h2>Running MAX models on IBM Cloud Functions</h2>

<p><a href="https://github.com/jthomas/serverless-max-models">This repository</a> contains a <a href="https://github.com/jthomas/serverless-max-models/blob/master/build.sh">bash script</a> which builds custom Docker runtimes with MAX models for usage on <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a>. Pushing these images to Docker Hub allows IBM Cloud Functions to use them as <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">custom runtimes</a>. <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md">Web Actions</a> created from these custom runtime images expose the same Prediction API described in the model documentation. They can be used with no further changes or custom code needed.</p>

<h3>prerequisites</h3>

<p>Please follow the links below to set up the following tools before proceeding.</p>

<ul>
<li><a href="https://www.docker.com/">Docker</a></li>
<li><a href="https://hub.docker.com/">Docker Hub account</a></li>
<li><a href="https://cloud.ibm.com/registration">IBM Cloud account</a></li>
<li><a href="https://cloud.ibm.com/openwhisk/learn/cli">IBM Cloud Functions CLI installed</a></li>
</ul>


<p><strong>Check out the &#8221;<a href="https://github.com/jthomas/serverless-max-models">Serverless MAX Models</a> repository. Run all the following commands from that folder.</strong></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/jthomas/serverless-max-models 
</span><span class='line'>cd serverless-max-models </span></code></pre></td></tr></table></div></figure>


<h3>build custom runtime images</h3>

<ul>
<li>Set the following environment variables (<code>MODELS</code>) with <a href="https://hub.docker.com/search?q=codait&amp;type=image">MAX model names</a> and run build script.

<ul>
<li><code>MODELS</code>: MAX model names, e.g. <code>max-facial-emotion-classifier</code></li>
<li><code>USERNAME</code>: Docker Hub username.</li>
</ul>
</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MODELS="..." USERNAME="..." ./build.sh</span></code></pre></td></tr></table></div></figure>


<p>This will create Docker images locally with the MAX model names and push to Docker Hub for usage in IBM Cloud Functions. <strong>IBM Cloud Functions only supports public Docker images as custom runtimes.</strong></p>

<h3>create actions using custom runtimes</h3>

<ul>
<li>Create a Web Action using the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">custom Docker runtime</a>.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud wsk action create &lt;MODEL_IMAGE&gt; --docker &lt;DOCKERHUB_NAME&gt;/&lt;MODEL_IMAGE&gt; --web true -m 512</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Retrieve the Web Action URL (<code>https://&lt;REGION&gt;.functions.cloud.ibm.com/api/v1/web/&lt;NS&gt;/default/&lt;ACTION&gt;</code>)</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud wsk action get &lt;MODEL_IMAGE&gt; --url</span></code></pre></td></tr></table></div></figure>


<h3>invoke web action url with prediction api parameters</h3>

<p>Use the same API request parameters as defined in the Prediction API specification with the Web Action URL. This will invoke model predictions and return the result as the HTTP response, e.g.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -F "image=@assets/happy-baby.jpeg" -XPOST &lt;WEB_ACTION_URL&gt;</span></code></pre></td></tr></table></div></figure>


<p><em>NOTE: The first invocation after creating an action may incur long cold-start delays due to the platform pulling the remote image into the local registry. Once the image is available in the platform, both further cold and warm invocations will be much faster.</em></p>

<h2>Example</h2>

<p>Here is an example of creating a serverless API using the <code>max-facial-emotion-classifier</code> <a href="https://developer.ibm.com/exchanges/models/all/max-facial-emotion-classifier/">MAX model</a>. Further examples of models which have been tested are available <a href="https://github.com/jthomas/serverless-max-models/blob/master/README.md#models">here</a>. If you encounter problems, please <a href="https://github.com/jthomas/serverless-max-models/issues">open an issue</a> on Github.</p>

<h3>max-facial-emotion-classifier</h3>

<ul>
<li><a href="https://developer.ibm.com/exchanges/models/all/max-facial-emotion-classifier/">Facial Emotion Classifier (<code>max-facial-emotion-classifier</code>)</a></li>
</ul>


<p>Start by creating the action using the custom runtime and then retrieve the Web Action URL.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ ibmcloud wsk action create max-facial-emotion-classifier --docker &lt;DOCKERHUB_NAME&gt;/max-facial-emotion-classifier --web true -m 512
</span><span class='line'>ok: created action max-facial-emotion-classifier
</span><span class='line'>$ ibmcloud wsk action get max-facial-emotion-classifier --url
</span><span class='line'>ok: got action max-facial-emotion-classifier
</span><span class='line'>https://&lt;REGION&gt;.functions.cloud.ibm.com/api/v1/web/&lt;NS&gt;/default/max-facial-emotion-classifier</span></code></pre></td></tr></table></div></figure>


<p>According to the <a href="http://max-facial-emotion-classifier.max.us-south.containers.appdomain.cloud/">API definition</a> for this model, the prediction API expects a form submission with an image file to classify. Using a <a href="https://github.com/IBM/MAX-Facial-Emotion-Classifier/blob/master/assets/happy-baby.jpeg">sample image</a> from the model repo, the model can be tested using curl.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -F "image=@happy-baby.jpeg" -XPOST https://&lt;REGION&gt;.functions.cloud.ibm.com/api/v1/web/&lt;NS&gt;/default/max-facial-emotion-classifier</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;ok&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;predictions&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;detection_box&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>        <span class="mf">0.15102639296187684</span><span class="p">,</span>
</span><span class='line'>        <span class="mf">0.3828125</span><span class="p">,</span>
</span><span class='line'>        <span class="mf">0.5293255131964809</span><span class="p">,</span>
</span><span class='line'>        <span class="mf">0.5830078125</span>
</span><span class='line'>      <span class="p">],</span>
</span><span class='line'>      <span class="nt">&quot;emotion_predictions&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>        <span class="p">{</span>
</span><span class='line'>          <span class="nt">&quot;label_id&quot;</span><span class="p">:</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;label&quot;</span><span class="p">:</span> <span class="s2">&quot;happiness&quot;</span><span class="p">,</span>
</span><span class='line'>          <span class="nt">&quot;probability&quot;</span><span class="p">:</span> <span class="mf">0.9860254526138306</span>
</span><span class='line'>        <span class="p">},</span>
</span><span class='line'>        <span class="err">...</span>
</span><span class='line'>      <span class="p">]</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>performance</h4>

<p><em>Example Invocation Duration (Cold):</em> ~4.8 seconds</p>

<p><em>Example Invocation Duration (Warm):</em> ~ 800 ms</p>

<h2>How does this work?</h2>

<h3>background</h3>

<p>Running machine learning classifications using pre-trained models from serverless functions has historically been challenging due to the following reason‚Ä¶</p>

<blockquote><p>Developers do not control runtime environments in (most) serverless cloud platforms. Libraries and dependencies needed by the functions must be provided in the deployment package. Most platforms limit deployment package sizes (~50MB compressed &amp; ~250MB uncompressed).</p></blockquote>

<p>Machine Learning libraries and models can be much larger than those deployment size limits. This stops them being included in deployment packages. Loading files dynamically during invocations may be possible but incurs extremely long cold-start delays and additional costs.</p>

<p>Fortunately, <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a> is based on the open-source serverless project, <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>. This platform supports bespoke function runtimes using <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">custom Docker images</a>. Machine learning libraries and models can therefore be provided in custom runtimes. This removes the need to include them in deployment packages or be loaded at runtime.</p>

<p><em>Interested in reading other blog posts about using machine learning libraries and toolkits with IBM Cloud Functions? See <a href="http://jamesthom.as/blog/2017/08/04/large-applications-on-openwhisk/">these posts</a> for <a href="http://jamesthom.as/blog/2018/08/13/serverless-machine-learning-with-tensorflow-dot-js/">more details</a>.</em></p>

<h3>MAX model images</h3>

<p>IBM&#8217;s <a href="https://developer.ibm.com/exchanges/models/all/">Model Asset eXchange</a> publishes Docker images for each model, alongside the pre-trained model files. Images expose a <a href="https://github.com/IBM/MAX-Text-Sentiment-Classifier#3-use-the-model">HTTP API for predictions</a> using the model on port 5000, built using Python and Flask. <a href="http://max-text-sentiment-classifier.max.us-south.containers.appdomain.cloud/">Swagger files</a> for the APIs describe the available operations, input parameters and response bodies.</p>

<p>These images use a custom application framework (<a href="https://pypi.org/project/maxfw/">maxfw</a>), based on Flask, to standardise exposing MAX models as HTTP APIs. This framework handles input parameter validation, response marshalling, CORS support, etc. This allows model runtimes to just implement the prediction API handlers, rather than the entire HTTP application.</p>

<p>Since the framework already handles exposing the model as a HTTP API, I started looking for a way to simulate an external HTTP request coming into the framework. If this was possible, I could trigger this fake request from a Python Web Action to perform the model classification from input parameters. The Web Action would then covert the HTTP response returned into the valid Web Action response parameters.</p>

<h3>flask test client</h3>

<p>Reading through the Flask <a href="http://flask.pocoo.org/docs/1.0/testing/">documentation</a>, I came across the perfect solution! üëèüëèüëè</p>

<blockquote><p>Flask provides a way to test your application by exposing the Werkzeug test Client and handling the context locals for you. You can then use that with your favourite testing solution.</p></blockquote>

<p>This allows application routes to be executed with the <a href="https://werkzeug.palletsprojects.com/en/0.15.x/test/#werkzeug.test.Client">test client</a>, without actually running the HTTP server.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">max_app</span> <span class="o">=</span> <span class="n">MAXApp</span><span class="p">(</span><span class="n">API_TITLE</span><span class="p">,</span> <span class="n">API_DESC</span><span class="p">,</span> <span class="n">API_VERSION</span><span class="p">)</span>
</span><span class='line'><span class="n">max_app</span><span class="o">.</span><span class="n">add_api</span><span class="p">(</span><span class="n">ModelPredictAPI</span><span class="p">,</span> <span class="s">&#39;/predict&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">test_client</span> <span class="o">=</span> <span class="n">max_app</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">test_client</span><span class="p">()</span>
</span><span class='line'><span class="n">r</span> <span class="o">=</span> <span class="n">test_client</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">&#39;/model/predict&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">content</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using this code within a serverless Python function allows function invocations to trigger the prediction API.  The serverless function only has to convert input parameters to the fake HTTP request and then serialise the response back to JSON.</p>

<h3>python docker action</h3>

<p>The custom MAX model runtime image needs to implement the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-new.md#action-interface">HTTP API expected</a> by Apache OpenWhisk. This API is used to instantiate the runtime environment and then pass in invocation parameters on each request. Since the runtime image contains all files and code need to process requests, the <code>/init</code> handler becomes a <a href="https://english.stackexchange.com/questions/25993/what-does-no-op-mean">no-op</a>. The <code>/run</code> handler converts <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md#http-context">Web Action HTTP parameters</a> into the fake HTTP request.</p>

<p>Here is the Python script used to proxy incoming Web Actions requests to the framework model service.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">maxfw.core</span> <span class="kn">import</span> <span class="n">MAXApp</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">api</span> <span class="kn">import</span> <span class="n">ModelPredictAPI</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">config</span> <span class="kn">import</span> <span class="n">API_TITLE</span><span class="p">,</span> <span class="n">API_DESC</span><span class="p">,</span> <span class="n">API_VERSION</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">json</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">base64</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">Response</span>
</span><span class='line'>
</span><span class='line'><span class="n">max_app</span> <span class="o">=</span> <span class="n">MAXApp</span><span class="p">(</span><span class="n">API_TITLE</span><span class="p">,</span> <span class="n">API_DESC</span><span class="p">,</span> <span class="n">API_VERSION</span><span class="p">)</span>
</span><span class='line'><span class="n">max_app</span><span class="o">.</span><span class="n">add_api</span><span class="p">(</span><span class="n">ModelPredictAPI</span><span class="p">,</span> <span class="s">&#39;/predict&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Use flask test client to simulate HTTP requests for the prediction APIs</span>
</span><span class='line'><span class="c"># HTTP request data will come from action invocation parameters, neat huh? :)</span>
</span><span class='line'><span class="n">test_client</span> <span class="o">=</span> <span class="n">max_app</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">test_client</span><span class="p">()</span>
</span><span class='line'><span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># This implements the Docker runtime API used by Apache OpenWhisk</span>
</span><span class='line'><span class="c"># https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md</span>
</span><span class='line'><span class="c"># /init is a no-op as everything is provided in the image.</span>
</span><span class='line'><span class="nd">@app.route</span><span class="p">(</span><span class="s">&quot;/init&quot;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;POST&#39;</span><span class="p">])</span>
</span><span class='line'><span class="k">def</span> <span class="nf">init</span><span class="p">():</span>
</span><span class='line'>    <span class="k">return</span> <span class="s">&#39;&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Action invocation requests will be received as the `value` parameter in request body.</span>
</span><span class='line'><span class="c"># Web Actions provide HTTP request parameters as `__ow_headers` &amp; `__ow_body` parameters.</span>
</span><span class='line'><span class="nd">@app.route</span><span class="p">(</span><span class="s">&quot;/run&quot;</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;POST&#39;</span><span class="p">])</span>
</span><span class='line'><span class="k">def</span> <span class="nf">run</span><span class="p">():</span>
</span><span class='line'>    <span class="n">body</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">json</span>
</span><span class='line'>    <span class="n">form_body</span> <span class="o">=</span> <span class="n">body</span><span class="p">[</span><span class="s">&#39;value&#39;</span><span class="p">][</span><span class="s">&#39;__ow_body&#39;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">headers</span> <span class="o">=</span> <span class="n">body</span><span class="p">[</span><span class="s">&#39;value&#39;</span><span class="p">][</span><span class="s">&#39;__ow_headers&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># binary image content provided as base64 strings</span>
</span><span class='line'>    <span class="n">content</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">form_body</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># send fake HTTP request to prediction API with invocation data</span>
</span><span class='line'>    <span class="n">r</span> <span class="o">=</span> <span class="n">test_client</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s">&#39;/model/predict&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">content</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
</span><span class='line'>    <span class="n">r_headers</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># binary data must be encoded as base64 strings to return in JSON response</span>
</span><span class='line'>    <span class="n">is_image</span> <span class="o">=</span> <span class="n">r_headers</span><span class="p">[</span><span class="s">&#39;Content-Type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&#39;image&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">r_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_image</span> <span class="k">else</span> <span class="n">r</span><span class="o">.</span><span class="n">data</span>
</span><span class='line'>    <span class="n">body</span> <span class="o">=</span> <span class="n">r_data</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">&quot;utf-8&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">response</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;headers&#39;</span><span class="p">:</span> <span class="n">r_headers</span><span class="p">,</span> <span class="s">&#39;status&#39;</span><span class="p">:</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span><span class="p">,</span> <span class="s">&#39;body&#39;</span><span class="p">:</span> <span class="n">body</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">print</span> <span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">status</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">Response</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response</span><span class="p">),</span> <span class="n">status</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">mimetype</span><span class="o">=</span><span class="s">&#39;application/json&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s">&#39;0.0.0.0&#39;</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8080</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>building into an image</h3>

<p>Since the MAX models already exist as public Docker images, those images can be used as base images when building custom runtimes. Those base images handle adding model files and all dependencies needed to execute them into the image.</p>

<p>This is the <code>Dockerfile</code> used by the build script to create the custom model image. The <code>model</code> parameter refers to the build argument containing the model name.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ARG model
</span><span class='line'>FROM codait/<span class="k">${</span><span class="nv">model</span><span class="k">}</span>:latest
</span><span class='line'>
</span><span class='line'>ADD openwhisk.py .
</span><span class='line'>
</span><span class='line'>EXPOSE 8080
</span><span class='line'>
</span><span class='line'>CMD python openwhisk.py
</span></code></pre></td></tr></table></div></figure>


<p>This is then used from the following build script to create a custom runtime image for the model.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'>
</span><span class='line'><span class="nb">set</span> -e -u
</span><span class='line'>
</span><span class='line'><span class="k">for </span>model in <span class="nv">$MODELS</span>; <span class="k">do</span>
</span><span class='line'><span class="k">  </span><span class="nb">echo</span> <span class="s2">&quot;Building $model runtime image&quot;</span>
</span><span class='line'>  docker build -t <span class="nv">$model</span> --build-arg <span class="nv">model</span><span class="o">=</span><span class="nv">$model</span> .
</span><span class='line'>  <span class="nb">echo</span> <span class="s2">&quot;Pushing $model to Docker Hub&quot;</span>
</span><span class='line'>  docker tag <span class="nv">$model</span> <span class="nv">$USERNAME</span>/<span class="nv">$model</span>
</span><span class='line'>  docker push <span class="nv">$USERNAME</span>/<span class="nv">$model</span>
</span><span class='line'><span class="k">done</span>
</span></code></pre></td></tr></table></div></figure>


<p>Once the image is published to Docker Hub, it can be referenced when creating new Web Actions (using the <code>‚Äîdocker</code> parameter). üòé</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ibmcloud wsk action create &lt;MODEL_IMAGE&gt; --docker &lt;DOCKERHUB_NAME&gt;/&lt;MODEL_IMAGE&gt; --web <span class="nb">true</span> -m 512
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>IBM&#8217;s Model Asset eXchange is a curated collection of Machine Learning models, ready to deploy to the cloud for a variety of tasks. All models are available as a series of public Docker images. Models images automatically expose HTTP APIs for classifications.</p>

<p>Documentation in the model repositories explains how to run them locally and deploy using Kubernetes, but what about using on serverless cloud platforms? Serverless platforms are becoming a popular option for deploying Machine Learning models, due to horizontal scalability and cost advantages.</p>

<p>Looking through the source code for the model images, I discovered a mechanism to hook into the custom model framework used to export the model files as HTTP APIs. This allowed me write a simple wrapper script to proxy serverless function invocations to the model prediction APIs. API responses would be serialised back into the Web Action response format.</p>

<p>Building this script into a new Docker image, using the existing model image as the base image, created a new runtime which could be used on the platform. Web Actions created from this runtime image would automatically expose the same HTTP APIs as the existing image!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Accessing Long-Running Apache OpenWhisk Actions Results]]></title>
    <link href="http://jamesthom.as/blog/2019/05/14/accessing-long-running-openwhisk-actions-results/"/>
    <updated>2019-05-14T11:35:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/05/14/accessing-long-running-openwhisk-actions-results</id>
    <content type="html"><![CDATA[<p><a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> actions are invoked by sending HTTP POST requests to the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/rest_api.md">platform API</a>. Invocation requests have two <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/rest_api.md#actions">different modes</a>: <strong>blocking</strong> and <strong>non-blocking</strong>.</p>

<p><strong>Blocking invocations</strong> mean the platform won&#8217;t send the HTTP response until the action finishes. This allows it to include the action result in the response.  Blocking invocations are used when you want to invoke an action and wait for the result.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ wsk action invoke my_action --blocking
</span><span class='line'>ok: invoked /_/my_action with id db70ef682fae4f8fb0ef682fae2f8fd5
</span><span class='line'>{
</span><span class='line'>    "activationId": "db70ef682fae4f8fb0ef682fae2f8fd5",
</span><span class='line'>    ...
</span><span class='line'>    "response": {
</span><span class='line'>        "result": { ... },
</span><span class='line'>        "status": "success",
</span><span class='line'>        "success": true
</span><span class='line'>    },
</span><span class='line'>    ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong>Non-blocking invocations</strong> return as soon as the platform processes the invocation request. This is before the action has finished executing. HTTP responses from non-blocking invocations only include activation identifiers, as the action result is not available.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ wsk action invoke my_action
</span><span class='line'>ok: invoked /_/my_action with id d2728aaa75394411b28aaa7539341195</span></code></pre></td></tr></table></div></figure>


<p><strong>HTTP responses from a blocking invocation will only wait for a limited amount of time before returning.</strong> This defaults to 65 seconds in the <a href="https://github.com/apache/incubator-openwhisk/blob/master/core/controller/src/main/resources/application.conf#L21">platform configuration file</a>. If an action invocation has not finished before this timeout limit, a HTTP 5xx status response is returned.</p>

<p>Hmmm‚Ä¶ ü§î</p>

<p><strong><em>&#8220;So, how can you invoke an action and wait for the result when actions take longer than this limit?&#8221;</em></strong></p>

<p>This question comes up regularly from developers building applications using the platform. I&#8217;ve decided to turn my answer into a blog post to help others struggling with this issue (after answering this question again this week üòé).</p>

<h3>solution</h3>

<ul>
<li><em>Invoke the action using a <a href="https://github.com/apache/incubator-openwhisk-client-js#invoke-action">non-blocking invocation</a>.</em></li>
<li><em>Use the returned activation identifier to poll the <a href="https://github.com/apache/incubator-openwhisk-client-js#retrieve-resource">activation result API</a>.</em></li>
<li><em>The HTTP response for the activation result will return a HTTP 404 response until the action finishes.</em></li>
</ul>


<p>When polling for activation results from non-blocking invocations, you should enforce a limit on the maximum polling time allowed. This is because HTTP 404s can be returned due to other scenarios (e.g. invalid activation identifiers). Enforcing a time limit ensures that, in the event of issues in the application code or the platform, the polling loop with eventually stop!</p>

<p><em>Setting the maximum polling time to the action timeout limit (plus a small offset) is a good approach.</em></p>

<p>An action cannot run for longer than its timeout limit. If the activation record is not available after this duration has elapsed (plus a small offset to handle internal platform delays), something has gone wrong. Continuing to poll after this point runs the risk of turning the polling operation into an infinite loop&#8230;</p>

<h3>example code</h3>

<p>This example provides an implementation of this approach for Node.js using the <a href="https://github.com/apache/incubator-openwhisk-client-js">JavaScript Client SDK</a>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="s2">&quot;use strict&quot;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">openwhisk</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;openwhisk&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">options</span> <span class="o">=</span> <span class="p">{</span> <span class="nx">apihost</span><span class="o">:</span> <span class="o">&lt;</span><span class="nx">API_HOST</span><span class="o">&gt;</span><span class="p">,</span> <span class="nx">api_key</span><span class="o">:</span> <span class="o">&lt;</span><span class="nx">API_KEY</span><span class="o">&gt;</span> <span class="p">}</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">ow</span> <span class="o">=</span> <span class="nx">openwhisk</span><span class="p">(</span><span class="nx">options</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// action duration limit (+ small offset)</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">timeout_ms</span> <span class="o">=</span> <span class="mi">85000</span>
</span><span class='line'><span class="c1">// delay between polling requests</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">polling_delay</span> <span class="o">=</span> <span class="mi">1000</span>
</span><span class='line'><span class="c1">// action to invoke</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">action</span> <span class="o">=</span> <span class="s1">&#39;delay&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">now</span> <span class="o">=</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getTime</span><span class="p">())</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">max_polling_time</span> <span class="o">=</span> <span class="nx">now</span><span class="p">()</span> <span class="o">+</span> <span class="nx">timeout_ms</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">delay</span> <span class="o">=</span> <span class="nx">async</span> <span class="nx">ms</span> <span class="o">=&gt;</span> <span class="k">new</span> <span class="nx">Promise</span><span class="p">(</span><span class="nx">resolve</span> <span class="o">=&gt;</span> <span class="nx">setTimeout</span><span class="p">(</span><span class="nx">resolve</span><span class="p">,</span> <span class="nx">ms</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">activation</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">ow</span><span class="p">.</span><span class="nx">actions</span><span class="p">.</span><span class="nx">invoke</span><span class="p">({</span><span class="nx">name</span><span class="o">:</span> <span class="nx">action</span><span class="p">})</span>
</span><span class='line'><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="k">new</span> <span class="nx">activation</span> <span class="nx">id</span><span class="o">:</span> <span class="nx">$</span><span class="p">{</span><span class="nx">activation</span><span class="p">.</span><span class="nx">activationId</span><span class="p">}</span><span class="err">`</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kd">let</span> <span class="nx">result</span> <span class="o">=</span> <span class="kc">null</span>
</span><span class='line'>
</span><span class='line'><span class="k">do</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">try</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">result</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">ow</span><span class="p">.</span><span class="nx">activations</span><span class="p">.</span><span class="nx">get</span><span class="p">({</span> <span class="nx">name</span><span class="o">:</span> <span class="nx">activation</span><span class="p">.</span><span class="nx">activationId</span> <span class="p">})</span>
</span><span class='line'>    <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">$</span><span class="p">{</span><span class="nx">activation</span><span class="p">.</span><span class="nx">activationId</span><span class="p">})</span> <span class="nx">now</span> <span class="nx">available</span><span class="o">!</span><span class="err">`</span><span class="p">)</span>
</span><span class='line'>  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="nx">err</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="nx">err</span><span class="p">.</span><span class="nx">statusCode</span> <span class="o">!==</span> <span class="mi">404</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="k">throw</span> <span class="nx">err</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">$</span><span class="p">{</span><span class="nx">activation</span><span class="p">.</span><span class="nx">activationId</span><span class="p">})</span> <span class="nx">not</span> <span class="nx">available</span> <span class="nx">yet</span><span class="err">`</span><span class="p">)</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">await</span> <span class="nx">delay</span><span class="p">(</span><span class="nx">polling_delay</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="nx">result</span> <span class="o">&amp;&amp;</span> <span class="nx">now</span><span class="p">()</span> <span class="o">&lt;</span> <span class="nx">max_polling_time</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">$</span><span class="p">{</span><span class="nx">activation</span><span class="p">.</span><span class="nx">activationId</span><span class="p">})</span><span class="err">`</span><span class="p">,</span> <span class="nx">result</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>testing it out</h3>

<p>Here is the source code for an action which will not return until 70 seconds have passed. Blocking invocations firing this action will result in a HTTP timeout before the response is returned.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">delay</span> <span class="o">=</span> <span class="nx">async</span> <span class="nx">ms</span> <span class="o">=&gt;</span> <span class="k">new</span> <span class="nx">Promise</span><span class="p">(</span><span class="nx">resolve</span> <span class="o">=&gt;</span> <span class="nx">setTimeout</span><span class="p">(</span><span class="nx">resolve</span><span class="p">,</span> <span class="nx">ms</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'><span class="kd">function</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="nx">delay</span><span class="p">(</span><span class="mi">70</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using the script above, the action result will be retrieved from a non-blocking invocation.</p>

<ul>
<li><em>Create an action from the source file in the example above.</em></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">action</span> <span class="nx">create</span> <span class="nx">delay</span> <span class="nx">delay</span><span class="p">.</span><span class="nx">js</span> <span class="o">--</span><span class="nx">timeout</span> <span class="mi">80000</span> <span class="o">--</span><span class="nx">kind</span> <span class="nx">nodejs</span><span class="o">:</span><span class="mi">10</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><em>Run the Node.js script to invoke this action and poll for the activation result.</em></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">node</span> <span class="nx">script</span><span class="p">.</span><span class="nx">js</span>
</span></code></pre></td></tr></table></div></figure>


<p>If the script runs correctly, log messages will display the polling status and then the activation result.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">$</span> <span class="nx">node</span> <span class="nx">script</span><span class="p">.</span><span class="nx">js</span>
</span><span class='line'><span class="k">new</span> <span class="nx">activation</span> <span class="nx">id</span><span class="o">:</span> <span class="nx">d4efc4641b544320afc4641b54132066</span>
</span><span class='line'><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">d4efc4641b544320afc4641b54132066</span><span class="p">)</span> <span class="nx">not</span> <span class="nx">available</span> <span class="nx">yet</span>
</span><span class='line'><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">d4efc4641b544320afc4641b54132066</span><span class="p">)</span> <span class="nx">not</span> <span class="nx">available</span> <span class="nx">yet</span>
</span><span class='line'><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">d4efc4641b544320afc4641b54132066</span><span class="p">)</span> <span class="nx">not</span> <span class="nx">available</span> <span class="nx">yet</span>
</span><span class='line'><span class="p">...</span>
</span><span class='line'><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">d4efc4641b544320afc4641b54132066</span><span class="p">)</span> <span class="nx">now</span> <span class="nx">available</span><span class="o">!</span>
</span><span class='line'><span class="nx">activation</span> <span class="nx">result</span> <span class="p">(</span><span class="nx">d4efc4641b544320afc4641b54132066</span><span class="p">)</span> <span class="p">{</span> <span class="p">...</span> <span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Saving Money and Time With Node.js Worker Threads in Serverless Functions]]></title>
    <link href="http://jamesthom.as/blog/2019/05/08/node-dot-js-worker-threads-with-serverless-functions/"/>
    <updated>2019-05-08T12:17:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/05/08/node-dot-js-worker-threads-with-serverless-functions</id>
    <content type="html"><![CDATA[<p>Node.js v12 was <a href="https://foundation.nodejs.org/announcements/2019/04/24/node-js-foundation-and-js-foundation-merge-to-form-openjs-foundation-2">released last month</a>. This new version includes support for <a href="https://nodejs.org/api/worker_threads.html">Worker Threads</a>, that are enabled by default. Node.js <a href="https://nodejs.org/api/worker_threads.html">Worker Threads</a> make it simple to execute JavaScript code in parallel using threads. üëèüëèüëè</p>

<p>This is useful for Node.js applications with CPU-intensive workloads. Using Worker Threads, JavaScript code can be executed code concurrently using multiple CPU cores. This reduces execution time compared to a non-Worker Threads version.</p>

<p>If serverless platforms provide Node.js v12 on multi-core environments, functions can use this feature to reduce execution time and, therefore, lower costs. Depending on the workload, functions can utilise all available CPU cores to parallelise work, rather than executing more functions concurrently. üí∞üí∞üí∞</p>

<p><strong>In this blog post, I&#8217;ll explain how to use Worker Threads from a serverless function. I&#8217;ll be using <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a> (<a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>) as the example platform but this approach is applicable for any serverless platform with Node.js v12 support and a multi-core CPU runtime environment.</strong></p>

<h2>Node.js v12 in IBM Cloud Functions (Apache OpenWhisk)</h2>

<p><em>This section of the blog post is specifically about using the new <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs">Node.js v12 runtime</a> on IBM Cloud Functions (powered by <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>). If you are using a different serverless platform, feel free to skip ahead to the next section‚Ä¶</em></p>

<p>I&#8217;ve recently <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/pull/126">been working</a> on adding the Node.js v12 runtime to Apache OpenWhisk.</p>

<p>Apache OpenWhisk uses <a href="https://hub.docker.com/u/openwhisk">Docker containers</a> as runtime environments for serverless functions. All runtime images are maintained in separate repositories for each supported language, e.g. <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs">Node.js</a>, <a href="https://github.com/apache/incubator-openwhisk-runtime-java">Java</a>, <a href="https://github.com/apache/incubator-openwhisk-runtime-python">Python</a>, etc. Runtime images are automatically built and pushed to <a href="https://hub.docker.com/r/openwhisk/">Docker Hub</a> when the repository is updated.</p>

<h3>node.js v12 runtime image</h3>

<p>Here is <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/pull/126">the PR</a> used to add the new Node.js v12 runtime image to Apache OpenWhisk. This led to the following <a href="https://hub.docker.com/r/openwhisk/action-nodejs-v12">runtime image</a> being exported to Docker Hub: <code>openwhisk/action-nodejs-v12</code>.</p>

<p>Having this image available as a native runtime in Apache OpenWhisk requires <a href="https://github.com/apache/incubator-openwhisk/pull/4472">upstream changes</a> to the project&#8217;s runtime manifest. After this happens, developers will be able to use the <code>--kind</code> CLI flag to select this runtime version.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud wsk action create action_name action.js --kind nodejs:12</span></code></pre></td></tr></table></div></figure>


<p><a href="http://cloud.ibm.com/openwhisk">IBM Cloud Functions</a> is powered by <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>. It will eventually pick up the upstream project changes to include this new runtime version. Until that happens, Docker support allows usage of this new runtime before it is built-in the platform.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud wsk action create action_name action.js --docker openwhisk/action-nodejs-v12</span></code></pre></td></tr></table></div></figure>


<h3>example</h3>

<p>This Apache OpenWhisk action returns the version of Node.js used in the runtime environment.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">function</span> <span class="nx">main</span> <span class="p">()</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">version</span><span class="o">:</span> <span class="nx">process</span><span class="p">.</span><span class="nx">version</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Running this code on IBM Cloud Functions, using the Node.js v12 runtime image, allows us to confirm the new Node.js version is available.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">$</span> <span class="nx">ibmcloud</span> <span class="nx">wsk</span> <span class="nx">action</span> <span class="nx">create</span> <span class="nx">nodejs</span><span class="o">-</span><span class="nx">v12</span> <span class="nx">action</span><span class="p">.</span><span class="nx">js</span> <span class="o">--</span><span class="nx">docker</span> <span class="nx">openwhisk</span><span class="o">/</span><span class="nx">action</span><span class="o">-</span><span class="nx">nodejs</span><span class="o">-</span><span class="nx">v12</span>
</span><span class='line'><span class="nx">ok</span><span class="o">:</span> <span class="nx">created</span> <span class="nx">action</span> <span class="nx">nodejs</span><span class="o">-</span><span class="nx">v12</span>
</span><span class='line'><span class="nx">$</span> <span class="nx">ibmcloud</span> <span class="nx">wsk</span> <span class="nx">action</span> <span class="nx">invoke</span> <span class="nx">nodejs</span><span class="o">-</span><span class="nx">v12</span> <span class="o">--</span><span class="nx">result</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="s2">&quot;version&quot;</span><span class="o">:</span> <span class="s2">&quot;v12.1.0&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Worker Threads in Serverless Functions</h2>

<p><a href="https://medium.com/@Trott/using-worker-threads-in-node-js-80494136dbb6">This is a great introdution blog post</a> to Workers Threads. It uses an example of generating prime numbers as the CPU intensive task to benchmark. Comparing the performance of the single-threaded version to multiple-threads - the performance is improved as a factor of the threads used (up to the number of CPU cores available).</p>

<p>This code can be ported to run in a serverless function. Running with different input values and thread counts will allow benchmarking of the performance improvement.</p>

<h3>non-workers version</h3>

<p>Here is the <a href="https://gist.github.com/jthomas/71c76d62ddfd146c4bf763f5b2f0eec1">sample code</a> for a serverless function to generate prime numbers. It does not use Worker Threads. It will run on the main <a href="https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/">event loop</a> for the Node.js process. This means it will only utilise a single thread (and therefore single CPU core).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="s1">&#39;use strict&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">min</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class='line'>
</span><span class='line'><span class="kd">function</span> <span class="nx">main</span><span class="p">(</span><span class="nx">params</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="p">{</span> <span class="nx">start</span><span class="p">,</span> <span class="nx">end</span> <span class="p">}</span> <span class="o">=</span> <span class="nx">params</span>
</span><span class='line'>  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">params</span><span class="p">)</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">primes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">isPrime</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
</span><span class='line'>  <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="nx">start</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">end</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">j</span> <span class="o">=</span> <span class="nx">min</span><span class="p">;</span> <span class="nx">j</span> <span class="o">&lt;</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">sqrt</span><span class="p">(</span><span class="nx">end</span><span class="p">);</span> <span class="nx">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="k">if</span> <span class="p">(</span><span class="nx">i</span> <span class="o">!==</span> <span class="nx">j</span> <span class="o">&amp;&amp;</span> <span class="nx">i</span><span class="o">%</span><span class="nx">j</span> <span class="o">===</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="nx">isPrime</span> <span class="o">=</span> <span class="kc">false</span><span class="p">;</span>
</span><span class='line'>        <span class="k">break</span><span class="p">;</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="nx">isPrime</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">primes</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">i</span><span class="p">);</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="nx">isPrime</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span> <span class="nx">primes</span> <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>porting the code to use worker threads</h3>

<p>Here is the prime number calculation code which uses Worker Threads. Dividing the total input range by the number of Worker Threads generates individual thread input values. Worker Threads are spawned and passed chunked input ranges. Threads calculate primes and then send the result back to the parent thread.</p>

<script src="https://gist.github.com/Trott/7bb7ee55c247047d030b4c427434ef51.js"></script>


<p>Reviewing the code to start converting it to a serverless function, I realised there were two issues running this code in serverless environment: <strong>worker thread initialisation</strong> and <strong>optimal worker thread counts</strong>.</p>

<h4>How to initialise Worker Threads?</h4>

<p>This is how the existing source code <a href="https://nodejs.org/dist/latest-v12.x/docs/api/worker_threads.html#worker_threads_new_worker_filename_options">initialises the Worker Threads</a>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'> <span class="nx">threads</span><span class="p">.</span><span class="nx">add</span><span class="p">(</span><span class="k">new</span> <span class="nx">Worker</span><span class="p">(</span><span class="nx">__filename</span><span class="p">,</span> <span class="p">{</span> <span class="nx">workerData</span><span class="o">:</span> <span class="p">{</span> <span class="nx">start</span><span class="o">:</span> <span class="nx">myStart</span><span class="p">,</span> <span class="nx">range</span> <span class="p">}}));</span>
</span></code></pre></td></tr></table></div></figure>


<p> <em><code>__filename</code> is a special global variable in Node.js which contains the currently executing script file path.</em></p>

<p>This means the Worker Thread will be initialised with a copy of the currently executing script. Node.js provides a special variable to indicate whether the script is executing in the parent or child thread. This can be used to branch script logic.</p>

<p><strong>So, what&#8217;s the issue with this?</strong></p>

<p>In the Apache OpenWhisk Node.js runtime, action source files are <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L61-L79">dynamically imported</a> into the runtime environment. The script used to start the Node.js runtime process is for the <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js">platform handler</a>, not the action source files. This means the <code>__filename</code> variable does not point to the action source file.</p>

<p>This issue is fixed by separating the serverless function handler and worker thread code into separate files. Worker Threads can be started with a reference to the worker thread script source file, rather than the currently executing script name.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'> <span class="nx">threads</span><span class="p">.</span><span class="nx">add</span><span class="p">(</span><span class="k">new</span> <span class="nx">Worker</span><span class="p">(</span><span class="s2">&quot;./worker.js&quot;</span><span class="p">,</span> <span class="p">{</span> <span class="nx">workerData</span><span class="o">:</span> <span class="p">{</span> <span class="nx">start</span><span class="o">:</span> <span class="nx">myStart</span><span class="p">,</span> <span class="nx">range</span> <span class="p">}}));</span>
</span></code></pre></td></tr></table></div></figure>


<h4>How Many Worker Threads?</h4>

<p>The next issue to resolve is how many Worker Threads to use. In order to maximise parallel processing capacity, there should be a Worker Thread for each CPU core. This is the maximum number of threads that can run concurrently.</p>

<p>Node.js provides CPU information for the runtime environment using the <code>os.cpus()</code> <a href="https://nodejs.org/api/os.html#os_os_cpus">function</a>. The result is an array of objects (one per logical CPU core), with model information, processing speed and elapsed processing times. The length of this array will determine number of Worker Threads used. This ensures the number of Worker Threads will always match the CPU cores available.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">threadCount</span> <span class="o">=</span> <span class="nx">os</span><span class="p">.</span><span class="nx">cpus</span><span class="p">().</span><span class="nx">length</span>
</span></code></pre></td></tr></table></div></figure>


<h3>workers threads version</h3>

<p>Here is the serverless version of the prime number generation algorithm which uses Worker Threads.</p>

<p>The code is split over two files - <code>primes-with-workers.js</code> and <code>worker.js</code>.</p>

<h4>primes-with-workers.js</h4>

<p><a href="https://gist.github.com/jthomas/154a039d52b97d5ed19d4ddac3ff9f43">This file</a> contains the serverless function handler used by the platform. Input ranges (based on the <code>min</code> and <code>max</code> action parameters) are divided into chunks, based upon the number of Worker Threads. The handler function creates a Worker Thread for each chunk and waits for the message with the result. Once all the results have been retrieved, it returns all those primes numbers as the invocation result.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="s1">&#39;use strict&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="p">{</span> <span class="nx">Worker</span> <span class="p">}</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;worker_threads&#39;</span><span class="p">);</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">os</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;os&#39;</span><span class="p">)</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">threadCount</span> <span class="o">=</span> <span class="nx">os</span><span class="p">.</span><span class="nx">cpus</span><span class="p">().</span><span class="nx">length</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">compute_primes</span> <span class="o">=</span> <span class="nx">async</span> <span class="p">(</span><span class="nx">start</span><span class="p">,</span> <span class="nx">range</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="k">new</span> <span class="nx">Promise</span><span class="p">((</span><span class="nx">resolve</span><span class="p">,</span> <span class="nx">reject</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>    <span class="kd">let</span> <span class="nx">primes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>    <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">adding</span> <span class="nx">worker</span> <span class="p">(</span><span class="nx">$</span><span class="p">{</span><span class="nx">start</span><span class="p">}</span> <span class="o">=&gt;</span> <span class="nx">$</span><span class="p">{</span><span class="nx">start</span> <span class="o">+</span> <span class="nx">range</span><span class="p">})</span><span class="err">`</span><span class="p">)</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">worker</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Worker</span><span class="p">(</span><span class="s1">&#39;./worker.js&#39;</span><span class="p">,</span> <span class="p">{</span> <span class="nx">workerData</span><span class="o">:</span> <span class="p">{</span> <span class="nx">start</span><span class="p">,</span> <span class="nx">range</span> <span class="p">}})</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">worker</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;error&#39;</span><span class="p">,</span> <span class="nx">reject</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">worker</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;exit&#39;</span><span class="p">,</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="nx">resolve</span><span class="p">(</span><span class="nx">primes</span><span class="p">))</span>
</span><span class='line'>    <span class="nx">worker</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;message&#39;</span><span class="p">,</span> <span class="nx">msg</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">primes</span> <span class="o">=</span> <span class="nx">primes</span><span class="p">.</span><span class="nx">concat</span><span class="p">(</span><span class="nx">msg</span><span class="p">)</span>
</span><span class='line'>    <span class="p">})</span>
</span><span class='line'>  <span class="p">})</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">async</span> <span class="kd">function</span> <span class="nx">main</span><span class="p">(</span><span class="nx">params</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="p">{</span> <span class="nx">min</span><span class="p">,</span> <span class="nx">max</span> <span class="p">}</span> <span class="o">=</span> <span class="nx">params</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">range</span> <span class="o">=</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">ceil</span><span class="p">((</span><span class="nx">max</span> <span class="o">-</span> <span class="nx">min</span><span class="p">)</span> <span class="o">/</span> <span class="nx">threadCount</span><span class="p">)</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">start</span> <span class="o">=</span> <span class="nx">min</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="o">?</span> <span class="mi">2</span> <span class="o">:</span> <span class="nx">min</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">workers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">Calculating</span> <span class="nx">primes</span> <span class="kd">with</span> <span class="nx">$</span><span class="p">{</span><span class="nx">threadCount</span><span class="p">}</span> <span class="nx">threads</span><span class="p">...</span><span class="err">`</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">threadCount</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">myStart</span> <span class="o">=</span> <span class="nx">start</span>
</span><span class='line'>    <span class="nx">workers</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">compute_primes</span><span class="p">(</span><span class="nx">myStart</span><span class="p">,</span> <span class="nx">range</span><span class="p">))</span>
</span><span class='line'>    <span class="nx">start</span> <span class="o">+=</span> <span class="nx">range</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">workers</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">compute_primes</span><span class="p">(</span><span class="nx">start</span><span class="p">,</span> <span class="nx">max</span> <span class="o">-</span> <span class="nx">start</span><span class="p">))</span>
</span><span class='line'>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">primes</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">Promise</span><span class="p">.</span><span class="nx">all</span><span class="p">(</span><span class="nx">workers</span><span class="p">)</span>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span> <span class="nx">primes</span><span class="o">:</span> <span class="nx">primes</span><span class="p">.</span><span class="nx">flat</span><span class="p">()</span> <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">exports</span><span class="p">.</span><span class="nx">main</span> <span class="o">=</span> <span class="nx">main</span>
</span></code></pre></td></tr></table></div></figure>


<h4>workers.js</h4>

<p><a href="https://gist.github.com/jthomas/154a039d52b97d5ed19d4ddac3ff9f43#file-workers-js">This is the script</a> used in the Worker Thread. The <code>workerData</code> value is used to receive number ranges to search for prime numbers. Primes numbers are sent back to the parent thread using the <code>postMessage</code> function. Since this script is only used in the Worker Thread, it does need to use the <code>isMainThread</code> value to check if it is a child or parent process.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="s1">&#39;use strict&#39;</span><span class="p">;</span>
</span><span class='line'><span class="kr">const</span> <span class="p">{</span> <span class="nx">Worker</span><span class="p">,</span> <span class="nx">isMainThread</span><span class="p">,</span> <span class="nx">parentPort</span><span class="p">,</span> <span class="nx">workerData</span> <span class="p">}</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;worker_threads&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">min</span> <span class="o">=</span> <span class="mi">2</span>
</span><span class='line'>
</span><span class='line'><span class="kd">function</span> <span class="nx">generatePrimes</span><span class="p">(</span><span class="nx">start</span><span class="p">,</span> <span class="nx">range</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">primes</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">isPrime</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">end</span> <span class="o">=</span> <span class="nx">start</span> <span class="o">+</span> <span class="nx">range</span><span class="p">;</span>
</span><span class='line'>  <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="nx">start</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">end</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">j</span> <span class="o">=</span> <span class="nx">min</span><span class="p">;</span> <span class="nx">j</span> <span class="o">&lt;</span> <span class="nb">Math</span><span class="p">.</span><span class="nx">sqrt</span><span class="p">(</span><span class="nx">end</span><span class="p">);</span> <span class="nx">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="k">if</span> <span class="p">(</span><span class="nx">i</span> <span class="o">!==</span> <span class="nx">j</span> <span class="o">&amp;&amp;</span> <span class="nx">i</span><span class="o">%</span><span class="nx">j</span> <span class="o">===</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>        <span class="nx">isPrime</span> <span class="o">=</span> <span class="kc">false</span><span class="p">;</span>
</span><span class='line'>        <span class="k">break</span><span class="p">;</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="nx">isPrime</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">primes</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">i</span><span class="p">);</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>    <span class="nx">isPrime</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="nx">primes</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">primes</span> <span class="o">=</span> <span class="nx">generatePrimes</span><span class="p">(</span><span class="nx">workerData</span><span class="p">.</span><span class="nx">start</span><span class="p">,</span> <span class="nx">workerData</span><span class="p">.</span><span class="nx">range</span><span class="p">);</span>
</span><span class='line'><span class="nx">parentPort</span><span class="p">.</span><span class="nx">postMessage</span><span class="p">(</span><span class="nx">primes</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h4>package.json</h4>

<p>Source files deployed from a zip file also need to include a <code>package.json</code> file in the archive. The <code>main</code> property is used to determine the script to import as the exported package module.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;name&quot;</span><span class="p">:</span> <span class="s2">&quot;worker_threads&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;version&quot;</span><span class="p">:</span> <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;main&quot;</span><span class="p">:</span> <span class="s2">&quot;primes-with-workers.js&quot;</span><span class="p">,</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Performance Comparison</h2>

<p>Running both functions with the same input parameters allows execution time comparison. The Worker Threads version should improve performance by a factor proportional to available CPU cores. Reducing execution time also means reduced costs in a serverless platform.</p>

<h3>non-workers performance</h3>

<p>Creating a new serverless function (<code>primes</code>) from the non-worker threads source code, using the Node.js v12 runtime, I can test with small values to check correctness.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ibmcloud wsk action create primes primes.js --docker openwhisk/action-nodejs-v12
</span><span class='line'>ok: created action primes
</span><span class='line'><span class="nv">$ </span>ibmcloud wsk action invoke primes --result -p start 2 -p end 10
</span><span class='line'><span class="o">{</span>
</span><span class='line'>    <span class="s2">&quot;primes&quot;</span>: <span class="o">[</span> 2, 3, 5, 7 <span class="o">]</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Playing with sample input values, 10,000,000 seems like a useful benchmark value. This takes long enough with the single-threaded version to benefit from parallelism.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span><span class="nb">time </span>ibmcloud wsk action invoke primes --result -p start 2 -p end 10000000 &gt; /dev/null
</span><span class='line'>
</span><span class='line'>real  0m35.151s
</span><span class='line'>user  0m0.840s
</span><span class='line'>sys   0m0.315s
</span></code></pre></td></tr></table></div></figure>


<p><strong>Using the simple single-threaded algorithm it takes the serverless function around ~35 seconds to calculate primes up to ten million.</strong></p>

<h3>workers threads performance</h3>

<p>Creating a new serverless function, from the worker threads-based source code using the Node.js v12 runtime, allows me to verify it works as expected for small input values.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ibmcloud wsk action create primes-workers action.zip --docker openwhisk/action-nodejs-v12
</span><span class='line'>ok: created action primes-workers
</span><span class='line'><span class="nv">$ </span>ibmcloud wsk action invoke primes-workers --result -p min 2 -p max 10
</span><span class='line'><span class="o">{</span>
</span><span class='line'>    <span class="s2">&quot;primes&quot;</span>: <span class="o">[</span> 2, 3, 5, 7 <span class="o">]</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Hurrah, it works.</p>

<p>Invoking the function with an <code>max</code> parameter of 10,000,000 allows us to benchmark against the non-workers version of the code.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span><span class="nb">time </span>ibmcloud wsk action invoke primes-workers --result -p min 2 -p max 10000000 --result &gt; /dev/null
</span><span class='line'>
</span><span class='line'>real  0m8.863s
</span><span class='line'>user  0m0.804s
</span><span class='line'>sys   0m0.302s
</span></code></pre></td></tr></table></div></figure>


<p><strong>The workers versions only takes ~25% of the time of the single-threaded version!</strong></p>

<p>This is because IBM Cloud Functions&#8217; runtime environments provide access to four CPU cores. Unlike other platforms, CPU cores are not tied to memory allocations. Utilising all available CPU cores concurrently allows the algorithm to run 4x times as fast. Since serverless platforms charge based on execution time, reducing execution time also means reducing costs.</p>

<p><strong>The worker threads version also costs 75% less than the single-threaded version!</strong></p>

<h2>Conclusion</h2>

<p><a href="https://foundation.nodejs.org/announcements/2019/04/24/node-js-foundation-and-js-foundation-merge-to-form-openjs-foundation-2">Node.js v12</a> was released in April 2019. This version included support for <a href="https://nodejs.org/api/worker_threads.html">Worker Threads</a>, that were enabled by default (rather than needing an optional runtime flag). Using multiple CPU cores in Node.js applications has never been easier!</p>

<p>Node.js applications with CPU-intensive workloads can utilise this feature to reduce execution time. Since serverless platforms charge based upon execution time, this is especially useful for Node.js serverless functions. Utilising multiple CPU cores leads, not only to improved performance, but also lower bills.</p>

<p>PRs have been <a href="https://github.com/apache/incubator-openwhisk/pull/4472">opened</a> to enable Node.js v12 as a built-in runtime to the Apache OpenWhisk project. This Docker <a href="https://hub.docker.com/r/openwhisk/action-nodejs-v12">image</a> for the new runtime version is already available on Docker Hub. This means it can be used with any Apache OpenWhisk instance straight away!</p>

<p>Playing with Worker Threads on IBM Cloud Functions allowed me to demonstrate how to speed up performance for CPU-intensive workloads by utilising multiple cores concurrently. Using <a href="https://gist.github.com/jthomas/154a039d52b97d5ed19d4ddac3ff9f43">an example of prime number generation</a>, calculating all primes up to ten million took ~35 seconds with a single thread and ~8 seconds with four threads. This represents a reduction in execution time and cost of 75%!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apache OpenWhisk Web Action HTTP Proxy]]></title>
    <link href="http://jamesthom.as/blog/2019/04/29/apache-openwhisk-web-action-http-proxy/"/>
    <updated>2019-04-29T10:29:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/04/29/apache-openwhisk-web-action-http-proxy</id>
    <content type="html"><![CDATA[<p><em>What if you could take an existing web application and run it on a serverless platform with no changes?</em> ü§î</p>

<p>Lots of existing (simple) stateless web applications are perfect candidates for serverless, but use web  frameworks that don&#8217;t know how to integrate with those platforms. People have started to develop a <a href="https://github.com/IBM/expressjs-openwhisk">number</a> <a href="https://github.com/claudiajs/claudia">of</a> <a href="https://github.com/logandk/serverless-wsgi">custom</a> <a href="https://github.com/Miserlou/Zappa">plugins</a> for those frameworks to try and bridge this gap.</p>

<p>These plugins can provide an easier learning curve for developers new to serverless. They can still use familiar web application frameworks whilst learning about the platforms. It also provides a path to &#8220;lift and shift&#8221; existing (simple) web applications to serverless platforms.</p>

<p>This approach relies on custom framework plugins being available, for every web app framework and serverless platform, which is not currently the case. <strong>Is there a better solution?</strong></p>

<p>Recently, I&#8217;ve been experimenting with <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk&#8217;s</a> <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">Docker support</a> to prototype a <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy">different approach</a>. This solution allows any web application to run on the platform, without needing bespoke framework plugins, with minimal changes. <em>Sounds interesting? Read about how I did this below‚Ä¶</em> üëç</p>

<h2>Apache OpenWhisk Web Action HTTP Proxy</h2>

<p><a href="https://github.com/jthomas/openwhisk-web-action-http-proxy">This project</a> provides a static binary which proxies HTTP traffic from <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md">Web Actions</a> to existing web applications. <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md#http-context">HTTP events</a> received by the Web Action Proxy are forwarded as HTTP requests to the web application. HTTP responses from the web application are returned as Web Action <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md#handling-http-requests-with-actions">responses</a>.</p>

<p><img src="https://raw.githubusercontent.com/jthomas/openwhisk-web-action-http-proxy/master/web-action-proxy.png" alt="Apache OpenWhisk Web Action HTTP Proxy" /></p>

<p>Both the proxy and web application needed to be started inside the serverless runtime environment. The proxy uses port 8080 and the web application can use any other port. An environment variable or action parameter can be used to configure the local port to proxy.</p>

<p>Running both HTTP processes on the platform is possible due to custom runtime support in Apache OpenWhisk. This allows using <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">custom Docker images</a> as the runtime environment. Custom runtimes images can be built which include the proxy binary and (optionally) the web application source files.</p>

<p>Two different options are available for getting web application source files into the runtime environment.</p>

<ul>
<li><strong>Build source files directly into the container image alongside proxy binary.</strong></li>
<li><strong>Dynamically inject source files into container runtime during initialisation.</strong></li>
</ul>


<p>Building source files into the container is simpler and incurs lower cold-starts delays, but means source code will be publicly available on Docker Hub. Injecting source files through action zips means the public container image can exclude all private source files and secrets. The extra initialisation time for dynamic injection does increase cold-start delays.</p>

<p><em><strong>Please note: This is an alpha-stage experiment!</strong> Don&#8217;t expect everything to work. This project is designed to run small simple stateless web applications on Apache OpenWhisk. Please don&#8217;t attempt to &#8220;lift &#8216;n&#8217; shift&#8221; a huge stateful enterprise app server onto the platform!</em></p>

<h3>Node.js + Express Example</h3>

<p>This is an <a href="https://github.com/jthomas/express_example">example Node.js web application</a>, built using the <a href="https://expressjs.com/">Express web application framework</a>:</p>

<p><img src="https://camo.githubusercontent.com/2aa43809d8d8a9f9ccb906c1028d81f1ba1913d9/687474703a2f2f7368617065736865642e636f6d2f696d616765732f61727469636c65732f657870726573735f6578616d706c652e6a7067" alt="https://camo.githubusercontent.com/2aa43809d8d8a9f9ccb906c1028d81f1ba1913d9/687474703a2f2f7368617065736865642e636f6d2f696d616765732f61727469636c65732f657870726573735f6578616d706c652e6a7067" /></p>

<p>The web application renders static HTML content for three routes (<code>/</code>,  <code>/about</code> and <code>/contact</code>). CSS files and fonts are also served by the backend.</p>

<p><strong>Use these steps to run this web application on Apache OpenWhisk using the Web Action Proxy&#8230;</strong></p>

<ul>
<li>Clone project repo.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/jthomas/express_example</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Install project dependencies in the <code>express_example</code> directory.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>npm install</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Bundle web application and libraries into zip file.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>zip -r action.zip *</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Create the Web Action (using a custom runtime image) with the following command.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wsk action create --docker jamesthomas/generic_node_proxy --web true --main "npm start" -p "__ow_proxy_port" 3000 web_app action.zip</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Retrieve the Web Action URL for the new action.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wsk action get web_app --url</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Open the Web Action URL in a HTTP web browser. <em>(Note: Web Action URLs must end with a forward-slash to work correctly, e.g. <code>https://&lt;OW_HOST&gt;/api/v1/web/&lt;NAMESPACE&gt;/default/web_app/</code>).</em></li>
</ul>


<p><img src="http://jamesthom.as/images/express-js-web-action-proxy.gif" alt="Web Action Proxy Express JS" /></p>

<p>If this works, the web application should load as above. Clicking links in the menu will navigate to different pages in the application.</p>

<h4>custom runtime image</h4>

<p>This example Web Action uses my own pre-built custom runtime image for Node.js web applications (<code>jamesthomas/generic_node_proxy</code>). This was created from the following Dockerfile to support dynamic runtime injection of web application source files.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM node:10
</span><span class='line'>
</span><span class='line'>ADD proxy /app/
</span><span class='line'>WORKDIR /app
</span><span class='line'>EXPOSE 8080
</span><span class='line'>
</span><span class='line'>CMD ./proxy</span></code></pre></td></tr></table></div></figure>


<h3>More Examples</h3>

<p>See the <code>examples</code> directory in the project repository for sample applications with build instructions for the following runtimes.</p>

<ul>
<li><a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/examples/nodejs+express">Node.js with Express.js</a></li>
<li><a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/examples/python+flask">Python with Flask</a></li>
<li><a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/examples/java+openliberty">Java with OpenLiberty</a></li>
</ul>


<h3>Usage &amp; Configuration</h3>

<p>Web application source files can be either be <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy#usage-dynamic-runtime-injection">dynamically injected</a> (as in the example above) or <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy#usage-sources-files-in-image">built into</a> the custom runtime image.</p>

<p><a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/README.md#usage-dynamic-runtime-injection">Dynamic injection</a> uses a custom runtime image with just the proxy binary and runtime dependencies. Web application source files are provided in the action zip file and extracted into the runtime upon initialisation. The proxy will start the app server during cold-starts.</p>

<p>Alternatively, source files for the web application <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/README.md#usage-sources-files-in-image">can be included directly</a> in the runtime image. The container start command will start both processes concurrently. No additional files are provided when creating the web action.</p>

<p><a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/README.md#configuration">Configuration</a> for values such as the proxy port, can be provided using <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/README.md#environment-variables">environment variables</a> or <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/README.md#action-parameters">default action parameters</a>.</p>

<p><em>Please see the <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/README.md">project documentation</a> for more details on both these approaches, how to use them and configuration parameters.</em></p>

<h2>Challenges</h2>

<p>This experiment is still in the alpha-stage and comes with many restrictions at the moment&#8230;</p>

<ul>
<li>HTTP request and responses sizes are limited to the maximum sizes allowed by Apache OpenWhisk for input parameters and activation results. This defaults to 1MB in the open-source project and 5MB on IBM Cloud Functions.</li>
<li>Page links must use URLs with relative paths to the Web Action URL rather than the host root, e.g. <code>href="home"</code> rather than <code>href="/home"</code>. This is due to the Web Actions being served from a sub-path of the platform (<code>/api/v1/web/&lt;NAMESPACE&gt;/default/&lt;ACTION&gt;</code>) rather than the host root.</li>
<li>Docker images will be pulled from the public registry on the first invocation. This will lead to long cold-start times for the first request after the action has been created. Large image sizes = longer delays. This only occurs on the first invocation.</li>
<li>Web app startup times affect cold start times. The proxy blocks waiting for the web application to start before responding. This delay is included in each cold start. Concurrent HTTP requests from a web  browser for static page assets will (initially) result in multiple cold starts.</li>
<li>Web Sockets and other complex HTTP features, e.g. server-side events, cannot be supported.</li>
<li>Web applications will run in ephemeral container environments that  are paused between requests and destroyed without warning. This is not a traditional web application environment, e.g. running background tasks will not work.</li>
</ul>


<p>Lots of things haven&#8217;t been tested. Don&#8217;t expect complex stateful web applications to work.</p>

<h2>Conclusion</h2>

<p>Being able to run existing web applications on serverless platforms opens up a huge opportunity for moving simple (and stateless) web application over to those platforms. These applications can then benefit from the scaling, cost and operational benefits serverless platforms provide.</p>

<p>Previous attempts to support traditional web applications on serverless platforms relied on custom framework plugins. This approach was limited by the availability of custom plugins for each web application framework and serverless platform.</p>

<p>Playing around with Apache OpenWhisk&#8217;s custom runtime support, I had an idea‚Ä¶ <strong>could a generic HTTP proxy be used to support any framework without needing any plugins?</strong> This led to the <a href="https://github.com/jthomas/openwhisk-web-action-http-proxy/blob/master/README.md#usage-sources-files-in-image">Apache OpenWhisk Web Action HTTP Proxy</a> project.</p>

<p>By building a custom runtime, the HTTP proxy and web application can both be started within the same serverless environment. HTTP events received by the Web Action Proxy are forwarded as HTTP requests to the web application. HTTP responses from the web application are returned as Web Action responses.</p>

<p>Web application sources files can be injected into the runtime environment during initialisation or built straight into the custom runtime image. No significant changes are required in the web application and it does not need custom framework plugins.</p>

<p>Apache OpenWhisk&#8217;s support for custom Docker runtimes opens up a huge range of opportunities for running more varied workloads on serverless platforms - and this is a great example of that!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Serverless CI/CD with Travis CI, Serverless Framework and IBM Cloud Functions]]></title>
    <link href="http://jamesthom.as/blog/2019/04/23/serverless-ci-slash-cd-with-travis-ci-serverless-framework-and-ibm-cloud-functions/"/>
    <updated>2019-04-23T15:08:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/04/23/serverless-ci-slash-cd-with-travis-ci-serverless-framework-and-ibm-cloud-functions</id>
    <content type="html"><![CDATA[<p>How do you set up a <a href="https://dzone.com/articles/what-is-cicd">CI/CD pipeline</a> for serverless applications?</p>

<p>This blog post will explain how to use <a href="https://travis-ci.org/">Travis CI</a>, <a href="https://github.com/serverless/serverless">The Serverless Framework</a> and the <a href="https://github.com/avajs/ava">AVA testing framework</a> to set up a fully-automated build, deploy and test pipeline for a serverless application. It will use a real example of a production <a href="https://github.com/jthomas/openwhisk-release-verification">serverless application</a>, built using <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> and running on <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a>. The CI/CD pipeline will execute the following tasks&#8230;</p>

<ul>
<li><strong>Run project unit tests.</strong></li>
<li><strong>Deploy application to test environment.</strong></li>
<li><strong>Run acceptance tests against test environment.</strong></li>
<li><strong>Deploy application to production environment.</strong></li>
<li><strong>Run smoke tests against production environment.</strong></li>
</ul>


<p>Before diving into the details of the CI/CD pipeline setup, let&#8217;s start by showing the example serverless application being used for this project&#8230;</p>

<h2>Serverless Project - <a href="http://apache.jamesthom.as/">http://apache.jamesthom.as/</a></h2>

<p>The &#8221;<a href="https://github.com/jthomas/openwhisk-release-verification">Apache OpenWhisk Release Verification</a>&#8221; project is a serverless web application to help committers verify release candidates for the open-source project. It automates running the verification steps from the <a href="https://cwiki.apache.org/confluence/display/OPENWHISK/How+to+verify+the+release+checklist+and+vote+on+OpenWhisk+modules+under+Apache">ASF release checklist</a> using serverless functions. Automating release candidate validation makes it easier for  committers to participate in release voting.</p>

<p><img src="https://raw.githubusercontent.com/jthomas/openwhisk-release-verification/master/release-verification-tool.gif" alt="Apache OpenWhisk Release Verification Tool" /></p>

<p>The project consists of a static web assets (HTML, JS, CSS files) and HTTP APIs. Static web assets are hosted by Github Pages from the <a href="https://github.com/jthomas/openwhisk-release-verification">project repository</a>. HTTP APIs are implemented as Apache OpenWhisk <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md">actions</a> and exposed using the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/apigateway.md">API Gateway</a> service. <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a> is used to host the Apache OpenWhisk application.</p>

<p>No other cloud services, like databases, are needed by the backend. Release candidate information is retrieved in real-time by parsing the <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/">HTML page</a> from the ASF website.</p>

<p><img src="http://jamesthom.as/images/ow_release_verifier/architecture.png" alt="Serverless Architecture" /></p>

<h3>Configuration</h3>

<p><a href="https://github.com/serverless/serverless">The Serverless Framework</a> (with the <a href="https://github.com/serverless/serverless-openwhisk">Apache OpenWhisk provider plugin</a>) is used to define the serverless functions used in the application. HTTP endpoints are also defined in the YAML configuration file.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">service</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">release-verfication</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">provider</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">openwhisk</span>
</span><span class='line'>  <span class="l-Scalar-Plain">runtime</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">nodejs:10</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">functions</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">versions</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">handler</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">index.versions</span>
</span><span class='line'>    <span class="l-Scalar-Plain">events</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">http</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">GET /api/versions</span>
</span><span class='line'>  <span class="l-Scalar-Plain">version_files</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">handler</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">index.version_files</span>
</span><span class='line'>    <span class="l-Scalar-Plain">events</span><span class="p-Indicator">:</span>
</span><span class='line'>      <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">http</span><span class="p-Indicator">:</span>
</span><span class='line'>          <span class="l-Scalar-Plain">method</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">GET</span>
</span><span class='line'>          <span class="l-Scalar-Plain">path</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">/api/versions/{version}</span>
</span><span class='line'>          <span class="l-Scalar-Plain">resp</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">http</span>
</span><span class='line'><span class="nn">...</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">plugins</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">serverless-openwhisk</span>
</span></code></pre></td></tr></table></div></figure>


<p>The framework handles all deployment and configuration tasks for the application. Setting up the application in a new environment is as simple as running the <code>serverless deploy</code> <a href="https://github.com/serverless/serverless">command</a>.</p>

<h3>Environments</h3>

<p>Apache OpenWhisk uses <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/reference.md#fully-qualified-names">namespaces</a> to group individual packages, actions, triggers and rules. Different namespaces can be used to provide isolated environments for applications.</p>

<p>IBM Cloud Functions automatically creates <a href="https://cloud.ibm.com/docs/openwhisk?topic=cloud-functions-cloudfunctions_cli#region_info">user-based namespaces</a> in platform instances. These auto-generated namespaces mirror the IBM Cloud organisation and space used to access the instance. Creating <a href="https://cloud.ibm.com/docs/account?topic=account-orgsspacesusers#cf-org-concepts">new spaces within an organisation</a> will provision extra namespaces.</p>

<p>I&#8217;m using a custom organisation for the application with three different spaces: <strong>dev</strong>, <strong>test</strong> and <strong>prod</strong>.</p>

<p><strong>dev</strong> is used as a test environment to deploy functions during development. <strong>test</strong> is used by the CI/CD pipeline to deploy a temporary instance of the application during acceptance tests. <strong>prod</strong> is the production environment hosting the external application actions.</p>

<h3>Credentials</h3>

<p>The <a href="https://cloud.ibm.com/docs/cli?topic=cloud-cli-install-ibmcloud-cli">IBM Cloud CLI</a> is used to handle IBM Cloud Functions credentials. <a href="https://cloud.ibm.com/docs/iam?topic=iam-manapikey">Platform API keys</a> will be used to log in the CLI from the CI/CD system.</p>

<p>When Cloud Functions CLI commands are issued (after targeting a new region, organisation or space), API keys for that Cloud Functions instance are automatically retrieved and stored locally. The Serverless Framework knows how to use these local credentials when interacting with the platform.</p>

<h3>High Availability?</h3>

<p>The Apache OpenWhisk Release Verifier is not a critical cloud application which needs &#8221;<a href="https://en.wikipedia.org/wiki/Five_nines">five nines</a>&#8221; of availability. The application is idle most of the time. It does not need a <a href="https://en.wikipedia.org/wiki/High_availability">highly available</a> serverless architecture. This means the build pipeline does not have to&#8230;</p>

<ul>
<li><a href="https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-multi-region-serverless#multi-region-serverless">Deploy application instances in multiple cloud regions.</a></li>
<li><a href="https://www.ibm.com/blogs/bluemix/2019/04/load-balancing-api-calls-across-regions-with-ibm-cloud-internet-services-and-cloud-api-gateway/">Set up a global load balancer between regional instances.</a></li>
<li>Support &#8221;<a href="https://www.martinfowler.com/bliki/BlueGreenDeployment.html">zero downtime deploys</a>&#8221; to minimise downtime during deployments.</li>
<li>Automatic roll-back to previous versions on production issues.</li>
</ul>


<p>New deployments will simply overwrite resources in the production namespace in a single region. If the production site is broken after a deployment, the smoke tests should catch this and email me to fix it!</p>

<h2>Testing</h2>

<p>Given this tool will be used to check release candidates for the open-source project, I wanted to ensure it worked properly! Incorrect validation results could lead to invalid source archives being published.</p>

<p>I&#8217;ve chosen to rely heavily on unit tests to check the core business logic. These tests ensure all validation tasks work correctly, including PGP signature verification, cryptographic hash matching, LICENSE file contents and other ASF requirements for project releases.</p>

<p>Additionally, I&#8217;ve used end-to-end acceptance tests to validate the HTTP APIs work as expected. HTTP requests are sent to the API GW endpoints, with responses compared against expected values. All available release candidates are run through the validation process to check no errors are returned.</p>

<h3>Unit Tests</h3>

<p><a href="https://en.wikipedia.org/wiki/Unit_testing">Unit tests</a> are implemented with the <a href="https://github.com/avajs/ava">AVA testing framework</a>. Unit tests live in the <code>unit/test/</code> <a href="https://github.com/jthomas/openwhisk-release-verification/tree/master/test/unit">folder</a>.</p>

<p>The <code>npm test</code> command alias runs the <code>ava test/unit/</code> command to execute all unit tests. This command can be executed locally, during development, or from the CI/CD pipeline.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>npm <span class="nb">test</span>
</span><span class='line'>
</span><span class='line'>&gt; release-verification@1.0.0 <span class="nb">test</span> ~/code/release-verification
</span><span class='line'>&gt; ava <span class="nb">test</span>/unit/
</span><span class='line'>
</span><span class='line'> 27 tests passed
</span></code></pre></td></tr></table></div></figure>


<h3>Acceptance Tests</h3>

<p><a href="https://en.wikipedia.org/wiki/Acceptance_testing">Acceptance tests</a> check API endpoints return the expected responses for valid (and invalid) requests. Acceptance tests are executed against the API Gateway endpoints for an application instance.</p>

<p>The hostname used for HTTP requests is controlled using an environment variable (<code>HOST</code>). Since the same test suite test is used for acceptance and smoke tests, setting this environment variable is the only configuration needed to run tests against different environments.</p>

<p>API endpoints in the test and production environments are exposed using different custom sub-domains (<code>apache-api.jamesthom.as</code> and <code>apache-api-test.jamesthom.as</code>). NPM <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/package.json#L8-L9">scripts are used</a> to provide commands (<code>acceptance-test</code> &amp; <code>acceptance-prod</code>) which set the environment hostname before running the test suite.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="s2">&quot;scripts&quot;</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="s2">&quot;acceptance-test&quot;</span><span class="o">:</span> <span class="s2">&quot;HOST=apache-api-test.jamesthom.as ava -v --fail-fast test/acceptance/&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="s2">&quot;acceptance-prod&quot;</span><span class="o">:</span> <span class="s2">&quot;HOST=apache-api.jamesthom.as ava -v --fail-fast test/acceptance/&quot;</span>
</span><span class='line'>  <span class="p">},</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">$</span> <span class="nx">npm</span> <span class="nx">run</span> <span class="nx">acceptance</span><span class="o">-</span><span class="nx">prod</span>
</span><span class='line'>
</span><span class='line'><span class="o">&gt;</span> <span class="nx">release</span><span class="o">-</span><span class="nx">verification</span><span class="err">@</span><span class="mf">1.0</span><span class="p">.</span><span class="mi">0</span> <span class="nx">acceptance</span><span class="o">-</span><span class="nx">prod</span> <span class="o">~</span><span class="err">/code/release-verification</span>
</span><span class='line'><span class="o">&gt;</span> <span class="nx">HOST</span><span class="o">=</span><span class="nx">apache</span><span class="o">-</span><span class="nx">api</span><span class="p">.</span><span class="nx">jamesthom</span><span class="p">.</span><span class="nx">as</span> <span class="nx">ava</span> <span class="o">-</span><span class="nx">v</span> <span class="o">--</span><span class="nx">fail</span><span class="o">-</span><span class="nx">fast</span>  <span class="nx">test</span><span class="o">/</span><span class="nx">acceptance</span><span class="o">/</span>
</span><span class='line'>
</span><span class='line'>  <span class="err">‚úî</span> <span class="nx">should</span> <span class="k">return</span> <span class="nx">list</span> <span class="nx">of</span> <span class="nx">release</span> <span class="nx">candidates</span> <span class="p">(</span><span class="mf">3.7</span><span class="nx">s</span><span class="p">)</span>
</span><span class='line'>    <span class="err">‚Ñπ</span> <span class="nx">running</span> <span class="nx">api</span> <span class="nx">testing</span> <span class="nx">against</span> <span class="nx">https</span><span class="o">:</span><span class="c1">//apache-api.jamesthom.as/api/versions</span>
</span><span class='line'>  <span class="err">‚úî</span> <span class="nx">should</span> <span class="k">return</span> <span class="mi">404</span> <span class="k">for</span> <span class="nx">file</span> <span class="nx">list</span> <span class="nx">when</span> <span class="nx">release</span> <span class="nx">candidate</span> <span class="nx">is</span> <span class="nx">invalid</span> <span class="p">(</span><span class="mf">2.1</span><span class="nx">s</span><span class="p">)</span>
</span><span class='line'>    <span class="err">‚Ñπ</span> <span class="nx">running</span> <span class="nx">api</span> <span class="nx">testing</span> <span class="nx">against</span> <span class="nx">https</span><span class="o">:</span><span class="c1">//apache-api.jamesthom.as/api/versions/unknown</span>
</span><span class='line'>  <span class="p">...</span>
</span><span class='line'>
</span><span class='line'>  <span class="mi">6</span> <span class="nx">tests</span> <span class="nx">passed</span>
</span></code></pre></td></tr></table></div></figure>


<p>Acceptance tests are also implemented with the AVA testing framework. All acceptance tests live in a single <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/test/acceptance/api.js">test file</a> (<code>unit/acceptance/api.js</code>).</p>

<h2>CI/CD Pipeline</h2>

<p>When new commits are pushed to the <code>master</code> branch on the project repository, the following steps needed to be kicked off by the build pipeline‚Ä¶</p>

<ul>
<li><em>Run project unit tests.</em></li>
<li><em>Deploy application to test environment.</em></li>
<li><em>Run acceptance tests against test environment.</em></li>
<li><em>Deploy application to production environment.</em></li>
<li><em>Run smoke tests against production environment.</em></li>
</ul>


<p>If any of the steps fail, the build pipeline should stop and send me a notification email.</p>

<h3>Travis</h3>

<p><a href="https://travis-ci.org/">Travis CI</a> is used to implement the CI/CD build pipeline. Travis CI uses a <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/.travis.yml">custom file</a> (<code>.travis.yml</code>) in the project repository to configure the build pipeline. This YAML file defines commands to execute during each phase of build pipeline. If any of the commands fail, the build will stop at that phase without proceeding.</p>

<p><em>Here is the completed <code>.travis.yml</code> file for this project: https://github.com/jthomas/openwhisk-release-verification/blob/master/.travis.yml</em></p>

<p>I&#8217;m using the following Travis CI <a href="https://docs.travis-ci.com/user/job-lifecycle#the-job-lifecycle">build phases</a> to implement the pipeline: <strong>install</strong>, <strong>before_script</strong>, <strong>script</strong>, <strong>before_deploy</strong> and <strong>deploy</strong>. Commands will run in the Node.js 10 build environment, which pre-installs the language runtime and package manager.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">language</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">node_js</span>
</span><span class='line'><span class="l-Scalar-Plain">node_js</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="s">&quot;10&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<h4>install</h4>

<p>In the <code>install</code> <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/.travis.yml#L5-L9">phase</a>, I need to set up the build environment to deploy the application and run tests.</p>

<p>This means installing the IBM Cloud CLI, <a href="https://cloud.ibm.com/openwhisk/learn/cli">Cloud Functions CLI plugin</a>, The Serverless Framework (with Apache OpenWhisk plugin), application test framework (AvaJS) and other project dependencies.</p>

<p>The IBM Cloud CLI is installed using a shell script. Running a CLI sub-command installs the <a href="https://cloud.ibm.com/openwhisk/learn/cli">Cloud Functions plugin</a>.</p>

<p>The Serverless Framework is installed as global NPM package (using <code>npm -g install</code>). The Apache OpenWhisk provider plugin is handled as <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/package.json#L13-L23">normal project dependency</a>, along with the test framework. Both those dependencies are installed using NPM.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">install</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">curl -fsSL https://clis.cloud.ibm.com/install/linux | sh</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud plugin install cloud-functions</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">npm install serverless -g</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">npm install</span>
</span></code></pre></td></tr></table></div></figure>


<h4>before_script</h4>

<p>This <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/.travis.yml#L11-L16">phase</a> is used to run unit tests, catching errors in core business logic, before setting up credentials (used in the <code>script</code> phase) for the acceptance test environment. Unit test failures will halt the build immediately, skipping test and production deployments.</p>

<p>Custom variables provide the API key, platform endpoint, organisation and space identifiers which are used for the test environment. The CLI is authenticated using these values, before running the <code>ibmcloud fn api list</code> command. This ensures Cloud Functions credentials are available locally, as used by The Serverless Framework.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">before_script</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">npm test</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud login --apikey $IBMCLOUD_API_KEY -a $IBMCLOUD_API_ENDPOINT</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud target -o $IBMCLOUD_ORG -s $IBMCLOUD_TEST_SPACE</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud fn api list &gt; /dev/null</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud target</span>
</span></code></pre></td></tr></table></div></figure>


<h4>script</h4>

<p>With the build system configured, the application can be deployed to test environment, followed by running acceptance tests. If either deployment or acceptance tests fail, the build will stop, skipping the production deployment.</p>

<p>Acceptance tests use an environment variable to configure the hostname test cases are executed against. The <code>npm run acceptance-test</code> alias command sets this value to the test environment hostname (<code>apache-api-test.jamesthom.as</code>) before running the test suite.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">script</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">sls deploy</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">npm run acceptance-test</span>
</span></code></pre></td></tr></table></div></figure>


<h4>before_deploy</h4>

<p>Before deploying to production, Cloud Functions credentials need to be updated. The IBM Cloud CLI is used to target the production environment, before running a Cloud Functions CLI command. This updates local credentials with the production environment credentials.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">before_deploy</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud target -s $IBMCLOUD_PROD_SPACE</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud fn api list &gt; /dev/null</span>
</span><span class='line'>  <span class="p-Indicator">-</span> <span class="l-Scalar-Plain">ibmcloud target</span>
</span></code></pre></td></tr></table></div></figure>


<h4>deploy</h4>

<p>If all the proceeding stages have successfully finished, the application can be deployed to the production. Following this final deployment, smoke tests are used to check production APIs still work as expected.</p>

<p>Smoke tests are just the same acceptance tests executed against the production environment. The <code>npm run acceptance-prod</code> alias command sets the hostname configuration value to the production environment  (<code>apache-api.jamesthom.as</code>) before running the test suite.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">deploy</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">provider</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">script</span>
</span><span class='line'>  <span class="l-Scalar-Plain">script</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">sls deploy &amp;&amp; npm run acceptance-prod</span>
</span><span class='line'>  <span class="l-Scalar-Plain">skip_cleanup</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">true</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>Using the <code>skip_cleanup</code> parameter leaves installed artifacts from previous phases in the build environment. This means we don&#8217;t have to re-install the IBM Cloud CLI, The Serverless Framework or NPM dependencies needed to run the production deployment and smoke tests.</em></p>

<h3>success?</h3>

<p>If all of the <a href="https://travis-ci.org/jthomas/openwhisk-release-verification">build phases</a> are successful, the latest project code should have been deployed to the production environment. üíØüíØüíØ</p>

<p><img src="http://jamesthom.as/images/build-screenshot.png" alt="Build Screenshoot" /></p>

<p>If the build failed due to unit test failures, the test suite can be ran locally to fix any errors. Deployment failures can be investigated using the console output logs from Travis CI. Acceptance test issues, against test or production environments, can be debugged by logging into those environments locally and running the test suite from my development machine.</p>

<h2>Conclusion</h2>

<p>Using Travis CI with The Serverless Framework and a JavaScript testing framework, I was able to set up a fully-automated CI/CD deployment pipeline for the Apache OpenWhisk release candidate verification tool.</p>

<p>Using a CI/CD pipeline, rather than a manual approach, for deployments has the following advantages&#8230;</p>

<ul>
<li>No more manual and error-prone deploys relying on a human üë®‚Äçüíª :)</li>
<li>Automatic unit &amp; acceptance test execution catch errors before deployments.</li>
<li>Production environment only accessed by CI/CD system, reducing accidental breakages.</li>
<li>All cloud resources must be configured in code. No &#8221;<a href="https://martinfowler.com/bliki/SnowflakeServer.html">snowflake</a>&#8221; environments allowed.</li>
</ul>


<p>Having finished code for new project features or bug fixes, all I have to do is push changes to the GitHub repository. This fires the Travis CI build pipeline which will automatically deploy the updated application to the production environment. If there are any issues, due to failed tests or deployments, I&#8217;ll be notified by email.</p>

<p>This allows me to get back to adding new features to the tool (and fixing bugs) rather than wrestling with deployments, managing credentials for multiple environments and then trying to remember to run tests against the correct instances!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automating Apache OpenWhisk Releases With Serverless]]></title>
    <link href="http://jamesthom.as/blog/2019/04/10/automating-apache-openwhisk-releases-with-serverless/"/>
    <updated>2019-04-10T15:00:00+01:00</updated>
    <id>http://jamesthom.as/blog/2019/04/10/automating-apache-openwhisk-releases-with-serverless</id>
    <content type="html"><![CDATA[<p>This blog post explains how I used <a href="https://github.com/jthomas/openwhisk-release-verification">serverless functions</a> to automate <a href="https://cwiki.apache.org/confluence/display/OPENWHISK/How+to+verify+the+release+checklist+and+vote+on+OpenWhisk+modules+under+Apache">release candidate verification</a> for the <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> project.</p>

<p><img src="https://raw.githubusercontent.com/jthomas/openwhisk-release-verification/master/release-verification-tool.gif" alt="Apache OpenWhisk Release Verification Tool" /></p>

<p><em>Automating this process has the following benefits&#8230;</em></p>

<ul>
<li><strong>Removes the chance of human errors compared to the previously manual validation process.</strong></li>
<li><strong>Allows me to validate new releases without access to my dev machine.</strong></li>
<li><strong>Usable by all committers by hosting as an <a href="http://apache.jamesthom.as/">external serverless web app</a>.</strong></li>
</ul>


<p>Automating release candidate validation makes it easier for project committers to participate in release voting. This should make it faster to get necessary release votes, allowing us to ship new versions sooner!</p>

<h2>background</h2>

<h3>apache software foundation</h3>

<p>The <a href="http://www.apache.org/">Apache Software Foundation</a> has a well-established <a href="https://www.apache.org/dev/release-publishing.html">release process</a> for delivering new product releases from projects belonging to the foundation. According to their <a href="https://www.apache.org/dev/release-publishing.html#goal">documentation</a>&#8230;</p>

<blockquote><p>An Apache release is a set of valid &amp; signed artifacts, voted on by the appropriate PMC and distributed on the ASF&#8217;s official release infrastructure.</p>

<p>https://www.apache.org/dev/release-publishing.html</p></blockquote>

<p>Releasing a new software version requires the release manager to create a release candidate from the  project source files. Source archives must be cryptographically <a href="http://www.apache.org/legal/release-policy.html#release-signing">signed</a> by the release manager. All source archives for the release must be comply with <a href="http://www.apache.org/legal/release-policy.html">strict criteria</a> to be considered valid release candidates. This includes (but is not limited to) the following requirements:</p>

<ul>
<li><em>Checksums and PGP signatures for source archives are valid.</em></li>
<li><em>LICENSE, NOTICE and DISCLAIMER files included and correct.</em></li>
<li><em>All source files have license headers.</em></li>
<li><em>No compiled archives bundled in source archives.</em></li>
</ul>


<p>Release candidates can then be proposed on the project mailing list for review by members of the <a href="https://apache.org/dev/pmc.html">Project Management Committee</a> (PMC). PMC members are <a href="http://www.apache.org/legal/release-policy.html#release-approval">eligible to vote</a> on all release candidates. Before casting their votes, PMC members are required to check release candidate meets the requirements above.</p>

<p><strong>If a minimum of three positive votes is cast (with more positive than negative votes), the release passes!</strong> The release manager can then move the release candidate archives to the release <a href="https://dist.apache.org/repos/dist/release/incubator/openwhisk/">directory</a>.</p>

<h3>apache openwhisk releases</h3>

<p>As a committer and PMC member on the Apache OpenWhisk project, I&#8217;m eligible to vote on new releases.</p>

<p>Apache OpenWhisk (currently) has 52 separate <a href="https://github.com/apache?q=openwhisk">source repositories</a> under the project on GitHub. With a fast-moving open-source project, new releases candidate are constantly <a href="https://lists.apache.org/list.html?dev@openwhisk.apache.org:lte=3y:%5BVOTE%5D">being proposed</a>, which all require the necessary number of binding PMC votes to pass.</p>

<p>Manually validating release candidates can be a time-consuming process. This can make it challenging to get a quorum of binding votes from PMC members for the release to pass. I started thinking how I could improve my productivity around the validation process, enabling me to participate in more votes.</p>

<p><strong>Would it be possible to automate some (or all) of the steps in release candidate verification? Could we even use a serverless application to do this?</strong></p>

<h1>apache openwhisk release verifier</h1>

<p><strong>Spoiler Alert: YES! I ended up building a serverless application to do this for me.</strong></p>

<p>It is available at <a href="https://apache.jamesthom.as/">https://apache.jamesthom.as/</a></p>

<p><img src="http://jamesthom.as/images/ow_release_verifier/overview.png" alt="Apache OpenWhisk Release Verifier" /></p>

<p>Source code for this project is available <a href="https://github.com/jthomas/openwhisk-release-verification">here</a>.</p>

<p><a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a> is used to run the serverless backend for the web application. This means Apache OpenWhisk is being used to validate future releases of itself‚Ä¶ which is awesome.</p>

<h2>architecture</h2>

<p><img src="http://jamesthom.as/images/ow_release_verifier/architecture.png" alt="Project Architecture" /></p>

<p>HTML, JS and CSS files are served by Github Pages from the <a href="https://github.com/jthomas/openwhisk-release-verification">project repository</a>.</p>

<p>Backend APIs are Apache OpenWhisk actions running on <a href="http://cloud.ibm.com/openwhisk">IBM Cloud Functions</a>.</p>

<p>Both the front-page and API are served from a custom sub-domains of my <a href="http://jamesthom.as/">personal domain</a>.</p>

<h3>available release candidates</h3>

<p>When the user loads the page, the drop-down list needs to contain the current list of release candidates from the ASF development <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/">distribution site</a>.</p>

<p>This information is available to the web page via the <a href="https://apache-api.jamesthom.as/api/versions">https://apache-api.jamesthom.as/api/versions</a> endpoint. The <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/">serverless function</a> powering this API parses that <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/">live HTML page</a> (extracting the current list of release candidates) each time it is invoked.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>http get https://apache-api.jamesthom.as/api/versions
</span><span class='line'>HTTP/1.1 200 OK
</span><span class='line'>...
</span><span class='line'><span class="o">{</span>
</span><span class='line'>    <span class="s2">&quot;versions&quot;</span>: <span class="o">[</span>
</span><span class='line'>        <span class="s2">&quot;apache-openwhisk-0.11.0-incubating-rc1&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;apache-openwhisk-0.11.0-incubating-rc2&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;apache-openwhisk-1.13.0-incubating-rc1&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;apache-openwhisk-1.13.0-incubating-rc2&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;apache-openwhisk-2.0.0-incubating-rc2&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;apache-openwhisk-3.19.0-incubating-rc1&quot;</span>
</span><span class='line'>    <span class="o">]</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>release candidate version info</h3>

<p>Release candidates may have <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/apache-openwhisk-2.0.0-incubating-rc2/">multiple source archives</a> being distributed in that release. Validation steps need to be executed for each of those archives within the release candidate.</p>

<p>Once a user has selected a release candidate version, source archives to validate are shown in the table. This data is available from the <a href="https://apache-api.jamesthom.as/api/versions/VERSION">https://apache-api.jamesthom.as/api/versions/VERSION</a> endpoint. This information is parsed from the <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/apache-openwhisk-2.0.0-incubating-rc2/">HTML page</a> on the ASF site.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>http get https://apache-api.jamesthom.as/api/versions/apache-openwhisk-2.0.0-incubating-rc2
</span><span class='line'>HTTP/1.1 200 OK
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'><span class="o">{</span>
</span><span class='line'>    <span class="s2">&quot;files&quot;</span>: <span class="o">[</span>
</span><span class='line'>        <span class="s2">&quot;openwhisk-package-alarms-2.0.0-incubating-sources.tar.gz&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;openwhisk-package-cloudant-2.0.0-incubating-sources.tar.gz&quot;</span>,
</span><span class='line'>        <span class="s2">&quot;openwhisk-package-kafka-2.0.0-incubating-sources.tar.gz&quot;</span>
</span><span class='line'>    <span class="o">]</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>release verification</h3>

<p>Having selected a release candidate version, clicking the &#8221;<em>Validate</em>&#8221; button will start validation process. Triggering the <a href="https://apache-api.jamesthom.as/api/versions/VERSION/validate">https://apache-api.jamesthom.as/api/versions/VERSION/validate</a> endpoint will run the <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/index.js#L47-L64">serverless function</a> used to execute the validation steps.</p>

<p><em>This serverless function will carry out the following verification steps&#8230;</em></p>

<h4>checking download links</h4>

<p>All the source archives for a release candidate are downloaded to temporary storage in the runtime environment. The function also downloads the associated SHA512 and PGP signature files for comparison. Multiple readable streams can be created from the same file path to allow the verification steps to happen in parallel, rather than having to re-download the archive for each task.</p>

<h4>checking SHA512 hash values</h4>

<p>SHA512 sums are distributed in a text file containing hex strings with the hash value.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>openwhisk-package-alarms-2.0.0-incubating-sources.tar.gz:
</span><span class='line'>3BF87306 D424955B B1B2813C 204CC086 6D27FA11 075F0B30 75F67782 5A0198F8 091E7D07
</span><span class='line'> B7357A54 A72B2552 E9F8D097 50090E9F A0C7DBD1 D4424B05 B59EE44E
</span></code></pre></td></tr></table></div></figure>


<p>The serverless function needs to dynamically compute the hash for the source archive and compare the hex bytes against the text file contents. Node.js comes with a <a href="https://nodejs.org/docs/latest-v10.x/api/crypto.html">built-in crypto library</a> making it easy to create hash values from input streams.</p>

<p><em>This is the <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/lib/verify.js#L18-L35">function</a> used to compute and compare the hash values.</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">hash</span> <span class="o">=</span> <span class="nx">async</span> <span class="p">(</span><span class="nx">file_stream</span><span class="p">,</span> <span class="nx">hash_file</span><span class="p">,</span> <span class="nx">name</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="k">new</span> <span class="nx">Promise</span><span class="p">((</span><span class="nx">resolve</span><span class="p">,</span> <span class="nx">reject</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">sha512</span> <span class="o">=</span> <span class="nx">parse_hash_from_file</span><span class="p">(</span><span class="nx">hash_file</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">hmac</span> <span class="o">=</span> <span class="nx">crypto</span><span class="p">.</span><span class="nx">createHash</span><span class="p">(</span><span class="s1">&#39;sha512&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">file_stream</span><span class="p">.</span><span class="nx">pipe</span><span class="p">(</span><span class="nx">hmac</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">hmac</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;readable&#39;</span><span class="p">,</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>      <span class="kr">const</span> <span class="nx">stream_hash</span> <span class="o">=</span> <span class="nx">hmac</span><span class="p">.</span><span class="nx">read</span><span class="p">().</span><span class="nx">toString</span><span class="p">(</span><span class="s1">&#39;hex&#39;</span><span class="p">)</span>
</span><span class='line'>      <span class="kr">const</span> <span class="nx">valid</span> <span class="o">=</span> <span class="nx">stream_hash</span> <span class="o">===</span> <span class="nx">sha512</span><span class="p">.</span><span class="nx">signature</span>
</span><span class='line'>      <span class="nx">logger</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">file</span> <span class="p">(</span><span class="nx">$</span><span class="p">{</span><span class="nx">name</span><span class="p">})</span> <span class="nx">calculated</span> <span class="nx">hash</span><span class="o">:</span> <span class="nx">$</span><span class="p">{</span><span class="nx">stream_hash</span><span class="p">}</span><span class="err">`</span><span class="p">)</span>
</span><span class='line'>      <span class="nx">logger</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">file</span> <span class="p">(</span><span class="nx">$</span><span class="p">{</span><span class="nx">name</span><span class="p">})</span> <span class="nx">hash</span> <span class="nx">from</span> <span class="nx">file</span><span class="o">:</span>  <span class="nx">$</span><span class="p">{</span><span class="nx">sha512</span><span class="p">.</span><span class="nx">signature</span><span class="p">}</span><span class="err">`</span><span class="p">)</span>
</span><span class='line'>      <span class="nx">resolve</span><span class="p">({</span><span class="nx">valid</span><span class="p">})</span>
</span><span class='line'>    <span class="p">})</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">hmac</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s1">&#39;error&#39;</span><span class="p">,</span> <span class="nx">err</span> <span class="o">=&gt;</span> <span class="nx">reject</span><span class="p">(</span><span class="nx">err</span><span class="p">))</span>
</span><span class='line'>  <span class="p">})</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>validating PGP signatures</h4>

<p><strong>Node.js&#8217; crypto library does not support validating PGP signatures.</strong></p>

<p>I&#8217;ve used the <a href="https://www.npmjs.com/package/openpgp">OpenPGP.js library</a> to handle this task. This is a Javascript implementation of the OpenPGP protocol (and the most popular PGP library for Node.js). Three input values are needed to <a href="https://github.com/openpgpjs/openpgpjs#create-and-verify-detached-signatures">validate PGP messages</a>.</p>

<ul>
<li><em>Message contents to check.</em></li>
<li><em>PGP signature for the message.</em></li>
<li><em>Public key for the private key used to sign the release.</em></li>
</ul>


<p>The &#8220;message&#8221; to check is the source archive. PGP signatures come from the <code>.asc</code> files located in the release candidate directory.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="o">-----</span><span class="nx">BEGIN</span> <span class="nx">PGP</span> <span class="nx">SIGNATURE</span><span class="o">-----</span>
</span><span class='line'><span class="nx">Version</span><span class="o">:</span> <span class="nx">GnuPG</span> <span class="nx">v1</span>
</span><span class='line'>
</span><span class='line'><span class="nx">iQIcBAABAgAGBQJcpO0FAAoJEHKvDMIsTPMgf0kP</span><span class="o">+</span><span class="nx">wbtJ1ONZJQKjyDVx8uASMDQ</span>
</span><span class='line'><span class="p">...</span>
</span><span class='line'><span class="o">-----</span><span class="nx">END</span> <span class="nx">PGP</span> <span class="nx">SIGNATURE</span><span class="o">-----</span>
</span></code></pre></td></tr></table></div></figure>


<p>Public keys used to sign releases are <a href="https://dist.apache.org/repos/dist/dev/incubator/openwhisk/KEYS">stored in the root folder</a> of the release directory for that project.</p>

<p><em>This <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/lib/verify.js#L37-L58">function</a> is used to implement the signature checking process.</em></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">signature</span> <span class="o">=</span> <span class="nx">async</span> <span class="p">(</span><span class="nx">file_stream</span><span class="p">,</span> <span class="nx">signature</span><span class="p">,</span> <span class="nx">public_keys</span><span class="p">,</span> <span class="nx">name</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">options</span> <span class="o">=</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">message</span><span class="o">:</span> <span class="nx">openpgp</span><span class="p">.</span><span class="nx">message</span><span class="p">.</span><span class="nx">fromBinary</span><span class="p">(</span><span class="nx">file_stream</span><span class="p">),</span>
</span><span class='line'>    <span class="nx">signature</span><span class="o">:</span> <span class="nx">await</span> <span class="nx">openpgp</span><span class="p">.</span><span class="nx">signature</span><span class="p">.</span><span class="nx">readArmored</span><span class="p">(</span><span class="nx">signature</span><span class="p">),</span>
</span><span class='line'>    <span class="nx">publicKeys</span><span class="o">:</span> <span class="p">(</span><span class="nx">await</span> <span class="nx">openpgp</span><span class="p">.</span><span class="nx">key</span><span class="p">.</span><span class="nx">readArmored</span><span class="p">(</span><span class="nx">public_keys</span><span class="p">)).</span><span class="nx">keys</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">verified</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">openpgp</span><span class="p">.</span><span class="nx">verify</span><span class="p">(</span><span class="nx">options</span><span class="p">)</span>
</span><span class='line'>  <span class="nx">await</span> <span class="nx">openpgp</span><span class="p">.</span><span class="nx">stream</span><span class="p">.</span><span class="nx">readToEnd</span><span class="p">(</span><span class="nx">verified</span><span class="p">.</span><span class="nx">data</span><span class="p">)</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">valid</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">verified</span><span class="p">.</span><span class="nx">signatures</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nx">verified</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span> <span class="nx">valid</span> <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>scanning archive files</h4>

<p>Using the <a href="https://github.com/npm/node-tar">node-tar library</a>, downloaded source archives are extracted into the local runtime to allow scanning of individual files.</p>

<p>LICENSE.txt, DISCLAIMER.txt and NOTICE.txt files are checked to ensure correctness. An <a href="https://www.npmjs.com/package/isbinaryfile">external NPM library</a> is used to check all files in the archive for binary contents. The code also scans for directory names that might contain third party libraries (<code>node_modules</code> or <code>.gradle</code>).</p>

<h3>capturing validation logs</h3>

<p>It is important to provide PMC members with verifiable logs on the validation steps performed. This allows them to sanity check the steps performed (including manual validation). This verification text can also be provided in the voting emails as evidence of release candidate validity.</p>

<p>Using a <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/lib/logger.js">custom logging library</a>, all debug logs sent to the console <a href="https://github.com/jthomas/openwhisk-release-verification/blob/master/index.js#L63">are recorded in the action result</a> (and therefore returned in the API response).</p>

<h3>showing results</h3>

<p>Once all the validation tasks have been executed - the results are returned to the front-end as a JSON response. The client-side JS parses these results and updates the validation table. Validation logs are shown in a collapsible window.</p>

<p><img src="http://jamesthom.as/images/ow_release_verifier/emojis.png" alt="Verification Results" /></p>

<p>Using visual emojis for pass and failure indicators for each step - the user can easily verify whether a release passes the validation checks. If any of the steps have failed, the validation logs provide an opportunity to understand why.</p>

<p><img src="http://jamesthom.as/images/ow_release_verifier/logs.png" alt="Verification Logs" /></p>

<h2>other tools</h2>

<p>This is not the only tool that can automate checks needed to validate Apache Software Foundation releases.</p>

<p>Another <a href="https://twitter.com/rabbah">community member</a> has also built a bash script (<a href="https://gitbox.apache.org/repos/asf?p=incubator-openwhisk-release.git;a=blob_plain;f=tools/rcverify.sh;hb=HEAD">rcverify.sh</a>) that can verify releases on your local machine. This script will automatically download the release candidate files and run many of the same validation tasks as the remote tool locally.</p>

<p>There is also an existing tool (<a href="https://creadur.apache.org/rat/">Apache Rat</a>) from another project that provides a Java-based application for auditing license headers in source files.</p>

<h2>conclusion</h2>

<p>Getting new product releases published for an open-source project under the ASF is not a simple task for developers used to pushing a button on Github! The ASF has a series of strict guidelines on what constitutes a release and the ratification process from PMC members. PMC members need to run a series of manual verification tasks before casting binding votes on proposed release candidates.</p>

<p>This can be a time-consuming task for PMC members on a project like Apache OpenWhisk, with 52 different project repositories all being released at different intervals. In an effort to improve my own productivity around this process, I started looking for ways to automate the verification tasks. This would enable me to participate in more votes and be a &#8220;better&#8221; PMC member.</p>

<p>This led to building a serverless web application to run all the verification tasks remotely, which is now hosted at <a href="https://apache.jamesthom.as">https://apache.jamesthom.as</a>. This tool uses Apache OpenWhisk (provided by IBM Cloud Functions), which means the project is being used to verify future releases of itself! I&#8217;ve also <a href="https://github.com/jthomas/openwhisk-release-verification">open-sourced</a> the code to provide an example of how to use the platform for automating tasks like this.</p>

<p>With this tool and others listed above, verifying new <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> releases has never been easier!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenWhisk Web Action Errors With Sequences]]></title>
    <link href="http://jamesthom.as/blog/2019/02/27/openwhisk-web-action-errors-with-sequences/"/>
    <updated>2019-02-27T10:00:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/27/openwhisk-web-action-errors-with-sequences</id>
    <content type="html"><![CDATA[<p>This week, I came across an interesting problem when building HTTP APIs on <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a>.</p>

<blockquote><p>How can Apache OpenWhisk Web Actions, implemented using action sequences, handle application errors that need the sequence to stop processing and a custom HTTP response to be returned?</p></blockquote>


<p>This came from wanting to add custom <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication">HTTP authentication</a> to existing Web Actions. I had decided to enhance existing Web Actions with authentication using action sequences. This would combine a new action for authentication validation with the existing API route handlers.</p>

<p><img src="http://jamesthom.as/images/sequences-and-web-actions/outline.png" title="" ></p>

<p>When the HTTP authentication is valid, the authentication action becomes a &#8221;<a href="https://en.wikipedia.org/wiki/NOP_(code)">no-op</a>&#8221;, which passes along the HTTP request to the route handler action to process as normal.</p>

<p><strong>But what happens when authentication fails?</strong></p>

<p>The authentication action needs to stop request processing and return a <a href="https://httpstatuses.com/401">HTTP 401</a> response immediately.</p>

<p><img src="http://jamesthom.as/images/sequences-and-web-actions/options.png" title="" ></p>

<p><em>Does Apache OpenWhisk even support this?</em></p>

<p>Fortunately, it does (phew) and I eventually worked out how to do this (based on a combination of re-reading <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/">documentation</a>, the platform <a href="https://github.com/apache/incubator-openwhisk/blob/master/core/controller/src/main/scala/org/apache/openwhisk/core/controller/WebActions.scala">source code</a> and just trying stuff out!).</p>

<p><em>Before explaining how to return custom HTTP responses using web action errors in sequences, let&#8217;s review web actions, actions sequences and why developers often use them together&#8230;</em></p>

<h2>Web Actions</h2>

<p><a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md">Web Actions</a> are OpenWhisk <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md">actions</a> that can be invoked using external HTTP requests.</p>

<p>Incoming HTTP requests are provided as event parameters. HTTP responses are controlled using attributes (<code>statusCode</code>, <code>body</code>, <code>headers</code>) in the action result.</p>

<p>Web Actions can be invoked directly, using the platform API, or connected to <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/apigateway.md">API Gateway endpoints</a>.</p>

<h3>example</h3>

<p>Here is an example Web Action that returns a static HTML page.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">function</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">headers</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="s1">&#39;Content-Type&#39;</span><span class="o">:</span> <span class="s1">&#39;text/html&#39;</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="nx">statusCode</span><span class="o">:</span> <span class="mi">200</span><span class="p">,</span>
</span><span class='line'>    <span class="nx">body</span><span class="o">:</span> <span class="s1">&#39;&lt;html&gt;&lt;body&gt;&lt;h3&gt;hello&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;&#39;</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>exposing web actions</h3>

<p>Web actions can be exported from any existing action by setting an <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/annotations.md#annotations-specific-to-web-actions">annotation</a>.</p>

<p>This is handled automatically by CLI using the <code>‚Äîweb</code> configuration flag when creating or updating actions.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">action</span> <span class="nx">create</span> <span class="nx">ACTION_NAME</span> <span class="nx">ACTION_CODE</span> <span class="o">--</span><span class="nx">web</span> <span class="kc">true</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Action Sequences</h2>

<p>Multiple actions can be composed together into a &#8220;meta-action&#8221; using <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md#creating-action-sequences">sequences</a>.</p>

<p>Sequence configuration defines a series of existing actions to be called sequentially upon invocation.  Actions connected in sequences can use different runtimes and even be sequences themselves.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">action</span> <span class="nx">create</span> <span class="nx">mySequence</span> <span class="o">--</span><span class="nx">sequence</span> <span class="nx">action_a</span><span class="p">,</span><span class="nx">action_b</span><span class="p">,</span><span class="nx">action_c</span>
</span></code></pre></td></tr></table></div></figure>


<p>Input events are passed to the first action in the sequence. Action results from each action in the sequence are passed to the next action in the sequence. The response from the last action in the sequence is returned as the action result.</p>

<h3>example</h3>

<p>Here is a sequence (<code>mySequence</code>) composed of three actions (<code>action_a</code>, <code>action_b</code>, <code>action_c</code>).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">action</span> <span class="nx">create</span> <span class="nx">mySequence</span> <span class="o">--</span><span class="nx">sequence</span> <span class="nx">action_a</span><span class="p">,</span><span class="nx">action_b</span><span class="p">,</span><span class="nx">action_c</span>
</span></code></pre></td></tr></table></div></figure>


<p>Invoking <code>mySequence</code> will invoke <code>action_a</code> with the input parameters. <code>action_b</code> will be invoked with the result from <code>action_a</code>.  <code>action_c</code> will be invoked with the result from <code>action_b</code>. The result returned by <code>action_c</code> will be returned as the sequence result.</p>

<h2>Web Actions from Action Sequences</h2>

<p>Using Action Sequences as Web Actions is a useful pattern for externalising common HTTP request and response processing tasks into separate serverless functions.</p>

<p>These common actions can be included in multiple Web Actions, rather than manually duplicating the same boilerplate code in each HTTP route action. This is similar to the &#8221;<a href="https://dzone.com/articles/understanding-middleware-pattern-in-expressjs">middleware</a>&#8221; pattern used by lots of common web application frameworks.</p>

<p>Web Actions using this approach are easier to test, maintain and allows API handlers to implement core business logic rather than lots of duplicate boilerplate code.</p>

<h3>authentication example</h3>

<p>In my application, new authenticated web actions were composed of two actions (<code>check_auth</code> and the API route handler, e.g. <code>route_handler</code>).</p>

<p>Here is an outline of the <code>check_auth</code> function in Node.js.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">check_auth</span> <span class="o">=</span> <span class="p">(</span><span class="nx">params</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">headers</span> <span class="o">=</span> <span class="nx">params</span><span class="p">.</span><span class="nx">__ow_headers</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">auth</span> <span class="o">=</span> <span class="nx">headers</span><span class="p">[</span><span class="s1">&#39;authorization&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">is_auth_valid</span><span class="p">(</span><span class="nx">auth</span><span class="p">))</span> <span class="p">{</span>
</span><span class='line'>    <span class="c1">// stop sequence processing and return HTTP 401?</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// ...else pass along request to next sequence action</span>
</span><span class='line'>  <span class="k">return</span> <span class="nx">params</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>check_auth</code> function will inspect the HTTP request and validate the authorisation token. If the token is valid, the function returns the input parameters untouched, which leads the platform the invoke the <code>route_handler</code> to generate the HTTP response from the API route.</p>

<p><strong>But what happens if the authentication is invalid?</strong></p>

<p>The  <code>check_auth</code> action needs to return a HTTP 401 response immediately, rather than proceeding to the  <code>route_handler</code> action.</p>

<p><img src="http://jamesthom.as/images/sequences-and-web-actions/options.png" title="" ></p>

<h3>handling errors - synchronous results</h3>

<p>Sequence actions can stop sequence processing by returning an error. Action errors are indicated by action results which include an &#8220;error&#8221; property or return rejected promises (for asynchronous results). Upon detecting an error, the platform will return the error result as the sequence action response.</p>

<p><em>If <code>check_auth</code> returns an error upon authentication failures, sequence processing can be halted, but how to control the HTTP response?</em></p>

<p><a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md#error-handling">Error responses</a> can also control the HTTP response, using the same properties (<code>statusCode</code>, <code>headers</code> and <code>body</code>) as a successful invocation result, with one difference: <strong>those properties must be the children of the <code>error</code> property rather than top-level properties.</strong></p>

<p>This example shows the error result needed to generate an immediate HTTP 401 response.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>   <span class="nt">&quot;error&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;statusCode&quot;</span><span class="p">:</span> <span class="mi">401</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;body&quot;</span><span class="p">:</span> <span class="s2">&quot;Authentication credentials are invalid.&quot;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In Node.js, this can be returned using a synchronous result as shown here.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">check_auth</span> <span class="o">=</span> <span class="p">(</span><span class="nx">params</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">headers</span> <span class="o">=</span> <span class="nx">params</span><span class="p">.</span><span class="nx">__ow_headers</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">auth</span> <span class="o">=</span> <span class="nx">headers</span><span class="p">[</span><span class="s1">&#39;authorization&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">is_auth_valid</span><span class="p">(</span><span class="nx">auth</span><span class="p">))</span> <span class="p">{</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">response</span> <span class="o">=</span> <span class="p">{</span> <span class="nx">statusCode</span><span class="o">:</span> <span class="mi">401</span><span class="p">,</span> <span class="nx">body</span><span class="o">:</span> <span class="s2">&quot;Authentication credentials are invalid.&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">return</span> <span class="p">{</span> <span class="nx">error</span><span class="o">:</span> <span class="nx">response</span> <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="nx">params</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>handling errors - using promises</h3>

<p>If a rejected Promise is used to return an error from an asynchronous operation, the promise result needs to contain the HTTP response properties as <strong>top-level properties</strong>, rather than under an <code>error</code> parent. This is because the Node.js runtime automatically <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs/blob/master/core/nodejsActionBase/runner.js#L118">serialises the promise value</a> to an <code>error</code> property on the activation result.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">check_auth</span> <span class="o">=</span> <span class="p">(</span><span class="nx">params</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">headers</span> <span class="o">=</span> <span class="nx">params</span><span class="p">.</span><span class="nx">__ow_headers</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">auth</span> <span class="o">=</span> <span class="nx">headers</span><span class="p">[</span><span class="s1">&#39;authorization&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">is_auth_valid</span><span class="p">(</span><span class="nx">auth</span><span class="p">))</span> <span class="p">{</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">response</span> <span class="o">=</span> <span class="p">{</span> <span class="nx">statusCode</span><span class="o">:</span> <span class="mi">401</span><span class="p">,</span> <span class="nx">body</span><span class="o">:</span> <span class="s2">&quot;Authentication credentials are invalid.&quot;</span> <span class="p">}</span>
</span><span class='line'>    <span class="k">return</span> <span class="nx">Promise</span><span class="p">.</span><span class="nx">reject</span><span class="p">(</span><span class="nx">response</span><span class="p">)</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="nx">params</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>conclusion</h2>

<p>Creating web actions from sequences is a novel way to implement the &#8220;HTTP middleware&#8221; pattern on serverless platforms. Surrounding route handlers with pre-HTTP request modifier actions for common tasks, allows route handlers to remove boilerplate code and focus on the core business logic.</p>

<p>In my application, I wanted to use this pattern was being used for custom HTTP authentication validation.</p>

<p>When the HTTP request contains the correct credentials, the request is passed along unmodified. When the credentials are invalid, the action needs to stop sequence processing and return a HTTP 401 response.</p>

<p>Working out how to do this wasn&#8217;t immediately obvious from the documentation. HTTP response parameters need to included under the <code>error</code> property for synchronous results. I have now opened a PR to improve the project documentation about this.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pluggable Event Providers for Apache OpenWhisk]]></title>
    <link href="http://jamesthom.as/blog/2019/02/20/pluggable-event-providers-for-apache-openwhisk/"/>
    <updated>2019-02-20T11:53:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/20/pluggable-event-providers-for-apache-openwhisk</id>
    <content type="html"><![CDATA[<p>Recently I presented my work building &#8221;<em><a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">pluggable event providers</a></em>&#8221; for <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a> to the open-source community on the <a href="https://www.youtube.com/openwhisk">bi-weekly video meeting</a>.</p>

<p>This was based on my experience building a <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/feeds.md">new event provider</a> for Apache OpenWhisk, which led me to prototype an <strong>easier way to add event sources to platform</strong> whilst <strong>cutting down on the boilerplate code</strong> required.</p>

<p>Slides from the talk are <a href="https://speakerdeck.com/jthomas/apache-openwhisk-pluggable-event-providers">here</a> and there&#8217;s also a video recording <a href="https://www.youtube.com/watch?v=krm7X5YpGy0">available</a>.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/krm7X5YpGy0?start=89" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<p>This blog post is overview of what I talked about on the call, explaining the background for the project and what was built. Based on positive feedback from the community, I have now open-sourced <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed">both</a> <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">components</a> of the experiment and will be merging it back upstream into Apache OpenWhisk in future.</p>

<h2>pluggable event providers - why?</h2>

<p>At the end of last year, I was asked to prototype an <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html">S3-compatible</a> Object Store event source for Apache OpenWhisk. Reviewing the <a href="https://github.com/search?q=incubator-openwhisk-package">existing event providers</a> helped me understand how they work and what was needed to build a new event source.</p>

<p>This led me to an interesting question&#8230;</p>

<blockquote><p>Why do we have relatively few community contributions for event sources?</p></blockquote>

<p>Most of the existing event sources in the project were contributed by IBM. There hasn&#8217;t been a new event source from an external community member. This is in stark contrast to <a href="https://github.com/search?q=incubator-openwhisk-runtime">additional platform runtimes</a>. Support for PHP, Ruby, DotNet, Go and many more languages all came from community contributions.</p>

<p><em>Digging into the source code for the existing feed providers, I came to the following conclusions&#8230;.</em></p>

<ul>
<li><strong>Trigger feed providers are not simple to implement.</strong></li>
<li><strong>Documentation how existing providers work is lacking.</strong></li>
</ul>


<p>Feed providers can feel a bit like magic to users. You call the <code>wsk</code> CLI with a <code>feed</code> parameter and that&#8217;s it, the platform handles everything else. But what actually happens to bind triggers to external event sources?</p>

<p><em>Let&#8217;s start by explaining how trigger feeds are implemented in Apache OpenWhisk, before moving onto my idea to make contributing new feed providers easier.</em></p>

<h2>how trigger feeds work</h2>

<p>Users normally interact with trigger feeds using the <code>wsk</code> CLI. Whilst creating a trigger, the <code>feed</code> parameter can be included to connect that trigger to an external event source. Feed provider options as provided as further CLI parameters.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>wsk trigger create periodic \
</span><span class='line'>  --feed /whisk.system/alarms/alarm \
</span><span class='line'>  --param cron "*/2 * * * *" \
</span><span class='line'>  --param trigger_payload ‚Äú{‚Ä¶}‚Äù \
</span><span class='line'>  --param startDate "2019-01-01T00:00:00.000Z" \
</span><span class='line'>  --param stopDate "2019-01-31T23:59:00.000Z"</span></code></pre></td></tr></table></div></figure>


<p><em>But what are those trigger feed identifiers used with the <code>feed</code> parameter?</em></p>

<p><strong>It turns out they are just normal actions which have been shared in a public package!</strong></p>

<p>The CLI creates the trigger (using the platform API) and then invokes the referenced feed action. Invocation parameters include the following values used to manage the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/feeds.md#implementing-feed-actions">trigger feed lifecycle</a>.</p>

<ul>
<li><code>lifecycleEvent</code> - Feed operation (<code>CREATE</code>, <code>READ</code>, <code>UPDATE</code>, <code>DELETE</code>, <code>PAUSE</code>, or <code>UNPAUSE</code>).</li>
<li><code>triggerName</code> - Trigger identifier.</li>
<li><code>authKey</code> - API key provided to invoke trigger.</li>
</ul>


<p>Custom feed parameters from the user are also included in the event parameters.</p>

<p><strong>This is the entire interaction of the platform with the feed provider.</strong></p>

<p>Providers are responsible for the full management lifecycle of trigger feed event sources. They have to maintain the list of registered triggers and auth keys, manage connections to user-provided event sources, fire triggers upon external events, handle retries and back-offs in cases of rate-limiting and much more.</p>

<p>Feed providers used with a trigger are stored as custom annotations. This allows the CLI to call the same feed action to stop the event binding when the trigger is deleted.</p>

<h3>trigger management</h3>

<p>Reading the source code for the <a href="https://github.com/search?q=incubator-openwhisk-package">existing feed providers</a>, nearly all of the code is responsible for handling the lifecycle of trigger management events, rather than integrating with the external event source.</p>

<p>Despite this, all of the existing providers are in separate repositories and don&#8217;t share code explicitly, although the same source files have been replicated in different repos.</p>

<p>The <a href="https://github.com/apache/incubator-openwhisk-package-cloudant">CouchDB feed provider</a> is a good example of how feed providers can be implemented.</p>

<h3>couchdb feed provider</h3>

<p>The <a href="https://github.com/apache/incubator-openwhisk-package-cloudant">CouchDB trigger feed provider</a> uses a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/actions/event-actions/changes.js">public action</a> to handle the lifecycle events from the <code>wsk</code> CLI.</p>

<p><img src="http://jamesthom.as/images/pluggable-providers/feeds-overview.png" title="" ></p>

<p>This <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/actions/event-actions/changes.js">action</a> just proxies the incoming requests to a separate <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/actions/event-actions/changesWebAction.js">web actio</a>n. The <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/webactions.md">web action</a> implements the logic to handle the trigger lifecycle event. The web action uses a CouchDB database used to store registered triggers. Based upon the lifecycle event details, the web action updates the database document for that trigger.</p>

<p><img src="http://jamesthom.as/images/pluggable-providers/feeds-provider.png" title="" ></p>

<p>The feed provider also runs a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/tree/master/provider">seperate Docker container</a>, which handles listening to CouchDB change feeds from user-provided credentials. It uses the changes feed from the trigger management database, modified from the web action, to listen for triggers being added, removed, disabled or re-enabled.</p>

<p><img src="http://jamesthom.as/images/pluggable-providers/feeds-fire-trigger.png" title="" ></p>

<p>When database change events <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/provider/lib/utils.js#L78">occur</a>, the container <a href="https://github.com/apache/incubator-openwhisk-package-cloudant/blob/master/provider/lib/utils.js#L66-L76">fires triggers</a> on the platform with the event details.</p>

<h2>building a new event provider?</h2>

<p>Having understood how feed providers work (and how the existing providers were designed), I started to think about the new event source for an S3-compatible object store.</p>

<p>Realising ~90% of the code between providers was the same, I wondered if there was a different approach to creating new event providers, rather than cloning an existing provider and changing the small amount of code used to interact with the event sources.</p>

<p><strong>What about building a generic event provider which a pluggable event source?</strong></p>

<p>This generic event provider would handle all the trigger management logic, which isn&#8217;t specific to individual event sources. The event source plugin would manage connecting to external event sources and then firing triggers as event occurred. Event source plugins would implement a standard interface and be registered dynamically during startup.</p>

<p><img src="http://jamesthom.as/images/pluggable-providers/generic-provider.png" title="" ></p>

<h3>advantages</h3>

<p>Using this approach would make it much easier to contribute and maintain new event sources.</p>

<ul>
<li><p>Users would be able to create new event sources with a few lines of custom integration code, rather than replicating all the generic trigger lifecycle management code.</p></li>
<li><p>Maintaining a single repo for the generic event provider is easier than having the same code copied and pasted in multiple independent repositories.</p></li>
</ul>


<p>I started hacking away at the existing CouchDB event provider to replace the event source integration with a generic plugin interface. Having completed this, I then wrote a new S3-compatible event source using the plugin model. After a couple of weeks I had something working&#8230;.</p>

<h2>generic event provider</h2>

<p>The <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">generic event provider</a> is based on the exiting CouchDB feed provider source code. The project contains the stateful container code and feed package actions (public &amp; web). It uses the same platform services (CouchDB and Redis) as the existing provider to maintain trigger details.</p>

<p>The event provider plugin is integrated through the <code>EVENT_PROVIDER</code> environment variable. The name should refer to a Node.js module from NPM with the following <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider#plugin-interface">interface</a>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// initialise plugin instance (must be a JS constructor)</span>
</span><span class='line'><span class="nx">module</span><span class="p">.</span><span class="nx">exports</span> <span class="o">=</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">trigger_manager</span><span class="p">,</span> <span class="nx">logger</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="c1">// register new trigger feed</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">add</span> <span class="o">=</span> <span class="nx">async</span> <span class="p">(</span><span class="nx">trigger_id</span><span class="p">,</span> <span class="nx">trigger_params</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{}</span>
</span><span class='line'>    <span class="c1">// remove existing trigger feed</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">remove</span> <span class="o">=</span> <span class="nx">async</span> <span class="nx">trigger_id</span> <span class="o">=&gt;</span> <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>   <span class="k">return</span> <span class="p">{</span> <span class="nx">add</span><span class="p">,</span> <span class="nx">remove</span> <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// valiate feed parameters</span>
</span><span class='line'><span class="nx">module</span><span class="p">.</span><span class="nx">exports</span><span class="p">.</span><span class="nx">validate</span> <span class="o">=</span> <span class="nx">async</span> <span class="nx">trigger_params</span> <span class="o">=&gt;</span> <span class="p">{}</span>
</span></code></pre></td></tr></table></div></figure>


<p>When a new trigger is added to the trigger feeds&#8217; database, the details will be passed to the <code>add</code> method. Trigger parameters will be used to set up listening to the external event source. When external events occur, the <code>trigger_manager</code> can be use to automatically fire triggers.</p>

<p>When users delete triggers with feeds, the trigger will be removed from the database. This will lead to the <code>remove</code> method being called. Plugins should stop listening to messages for this event source.</p>

<h3>firing trigger events</h3>

<p>As event arrive from the external source, the plugin can use the <code>trigger_manager</code> instance, passed in through the constructor, to fire triggers with the identifier.</p>

<p>The <code>trigger_manager</code> parameter exposes two async functions:</p>

<ul>
<li><code>fireTrigger(id, params)</code> - fire trigger given by id passed into <code>add</code> method with event parameters.</li>
<li><code>disableTrigger(id, status_code, message)</code> - disable trigger feed due to external event source issues.</li>
</ul>


<p>Both functions handle the retry logic and error handling for those operations. These should be used by the event provider plugin to fire  triggers when events arrive from external sources and then disable triggers due to external event source issues.</p>

<h3>validating event source parameters</h3>

<p>This static function on the plugin constructor is used to validate incoming trigger feed parameters for correctness, e.g. checking  authentication credentials for an event source. It is passed the trigger  parameters from the user.</p>

<h2>S3 event feed provider</h2>

<p>Using this new generic event provider, I was able to create an event source for an <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed">S3-compatible object store</a>. Most importantly, this new event source was implemented using just <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed/tree/master/lib">~300 lines</a> of JavaScript! This is much smaller than the 7500 lines of code in the generic event provider.</p>

<p>The feed provider polls buckets on an interval using the <code>ListObjects</code> <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/v2-RESTBucketGET.html">API call</a>. Results are cached in Redis to allow comparison between intervals. Comparing the differences in bucket file name and etags, allows file change events to be detected.</p>

<p>Users can call the feed provider with a bucket name, endpoint, API key and polling interval.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">trigger</span> <span class="nx">create</span> <span class="nx">test</span><span class="o">-</span><span class="nx">s3</span><span class="o">-</span><span class="nx">trigger</span> <span class="o">--</span><span class="nx">feed</span> <span class="o">/&lt;</span><span class="nx">PROVIDER_NS</span><span class="o">&gt;</span><span class="err">/s3-trigger-feed/changes --param bucket &lt;BUCKET_NAME&gt; --param interval &lt;MINS&gt; --param s3_endpoint &lt;S3_ENDPOINT&gt; --param s3_apikey &lt;COS_KEY&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>File events are fired as the bucket files change with the following trigger events.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;file&quot;</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="s2">&quot;ETag&quot;</span><span class="o">:</span> <span class="s2">&quot;\&quot;fb47672a6f7c34339ca9f3ed55c6e3a9\&quot;&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="s2">&quot;Key&quot;</span><span class="o">:</span> <span class="s2">&quot;file-86.txt&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="s2">&quot;LastModified&quot;</span><span class="o">:</span> <span class="s2">&quot;2018-12-19T08:33:27.388Z&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="s2">&quot;Owner&quot;</span><span class="o">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="s2">&quot;DisplayName&quot;</span><span class="o">:</span> <span class="s2">&quot;80a2054e-8d16-4a47-a46d-4edf5b516ef6&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="s2">&quot;ID&quot;</span><span class="o">:</span> <span class="s2">&quot;80a2054e-8d16-4a47-a46d-4edf5b516ef6&quot;</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="s2">&quot;Size&quot;</span><span class="o">:</span> <span class="mi">25</span><span class="p">,</span>
</span><span class='line'>    <span class="s2">&quot;StorageClass&quot;</span><span class="o">:</span> <span class="s2">&quot;STANDARD&quot;</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;status&quot;</span><span class="o">:</span> <span class="s2">&quot;deleted&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>Pssst - if you are using <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a> - I actually have this deployed and running so you can try it out. Use the <code>/james.thomas@uk.ibm.com_dev/s3-trigger-feed/changes</code> feed action name. This package is only available in the London region.</em></p>

<h2>next steps</h2>

<p>Feedback on the call was overwhelming positive on my experiment. Based upon this, I&#8217;ve now open-sourced both the <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider">generic event provider</a> and <a href="https://github.com/jthomas/openwhisk-s3-trigger-feed">s3 event source plugin</a> to allow the community to evaluate the project further.</p>

<p>I&#8217;d like to build a few more example event providers to validate the approach further before moving towards contributing this code back upstream.</p>

<p>If you want to try this generic event provider out with your own install of OpenWhisk, please see the <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider/blob/master/README.md#running-the-provider--plugin">documentation</a> in the README for how to get started.</p>

<p>If you want to build new event sources, please see the <a href="https://github.com/jthomas/openwhisk-pluggable-event-provider/blob/master/README.md#plugin-interface">instructions</a> in the generic feed provider repository and take a look at the S3 plugin for an example to follow.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CouchDB Filters with OpenWhisk Triggers]]></title>
    <link href="http://jamesthom.as/blog/2019/02/12/couchdb-filters-with-openwhisk-triggers/"/>
    <updated>2019-02-12T14:22:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/12/couchdb-filters-with-openwhisk-triggers</id>
    <content type="html"><![CDATA[<p>Imagine you have an <a href="http://openwhisk.incubator.apache.org/">OpenWhisk</a> <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions.md">action</a> to send emails to users to verify their email addresses. User profiles, containing email addresses and verification statuses, are maintained in a <a href="https://couchdb.apache.org/">CouchDB</a> database.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="err">...</span>
</span><span class='line'>    <span class="nt">&quot;email&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;address&quot;</span><span class="p">:</span> <span class="s2">&quot;user@host.com&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;unverified&quot;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Setting up a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant">CouchDB trigger feed</a> allows the email action <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/triggers_rules.md">to be invoked</a> when the user profile changes. When user profiles have unverified email addresses, the action can send verification emails.</p>

<p>Whilst this works fine - it will result in a lot of unnecessary invocations. All modifications to user profiles, not just the email field, will result in the action being invoked. This will incur a cost despite the action having nothing to do.</p>

<blockquote><p>How can we restrict document change events to just those we care about?</p></blockquote>

<p>CouchDB <a href="https://docs.couchdb.org/en/stable/ddocs/ddocs.html#filter-functions">filter functions</a> to the rescue ü¶∏‚Äç‚ôÇÔ∏èü¶∏‚Äç.</p>

<h2>CouchDB Filter Functions</h2>

<p><a href="https://docs.couchdb.org/en/stable/ddocs/ddocs.html#filter-functions">Filter functions</a> are Javascript functions executed against (potential) <a href="http://guide.couchdb.org/draft/notifications.html">change feed events</a>. The function is invoked with each document update. The return value is evaluated as a boolean variable. If true, the document is published on the changes feed. Otherwise, the event is filtered from the changes feed.</p>

<h3>example</h3>

<p>Filter functions are created through <a href="https://docs.couchdb.org/en/stable/ddocs/ddocs.html">design documents</a>. Function source strings are stored as properties under the <code>filters</code> document attribute. Key names are used as filter identifiers.</p>

<p>Filter functions should have the following interface.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">function</span><span class="p">(</span><span class="nx">doc</span><span class="p">,</span> <span class="nx">req</span><span class="p">){</span>
</span><span class='line'>    <span class="c1">// document passes test</span>
</span><span class='line'>    <span class="k">if</span> <span class="p">(</span><span class="nx">doc</span><span class="p">.</span><span class="nx">property</span> <span class="o">==</span> <span class="s1">&#39;value&#39;</span><span class="p">){</span>
</span><span class='line'>        <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// ... else ignore document upate</span>
</span><span class='line'>    <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p> <code>doc</code> is the modified document object and <code>req</code> contains (optional) request parameters.</p>

<p><em>Let&#8217;s now explain how to create a filter function to restrict profile update events to just those with unverified email addresses&#8230;</em></p>

<h2>Filtering Profile Updates</h2>

<h3>user profile documents</h3>

<p>In this example, email addresses are stored in user profile documents under the <code>email</code> property. <code>address</code> contains the user&#8217;s email address and <code>status</code> records the verification status (<code>unverified</code> or <code>verified</code>).</p>

<p>When a new user is added, or an existing user changes their email address, the <code>status</code> attribute is set to <code>unverified</code>. This indicates a verification message needs to be sent to the email address.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="err">...</span>
</span><span class='line'>    <span class="nt">&quot;email&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;address&quot;</span><span class="p">:</span> <span class="s2">&quot;user@host.com&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;status&quot;</span><span class="p">:</span> <span class="s2">&quot;unverified&quot;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>unverified email filter</h3>

<p>Here is the CouchDB filter function that will ignore document updates with verified email addresses.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">function(doc)</span><span class="p">{</span>
</span><span class='line'>    <span class="err">if</span> <span class="err">(doc.email.status</span> <span class="err">==</span> <span class="err">&#39;unverified&#39;){</span>
</span><span class='line'>        <span class="err">return</span> <span class="err">true;</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="err">return</span> <span class="kc">false</span>
</span><span class='line'><span class="err">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>design document with filters</h3>

<p>Save the following JSON document in CouchDB. This creates a new design document (<code>profile</code>) containing a filter function (<code>unverified-emails</code>).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;_id&quot;</span><span class="p">:</span> <span class="s2">&quot;_design/profile&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;filters&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;unverified-emails&quot;</span><span class="p">:</span> <span class="s2">&quot;function (doc) {\n  if (doc.email.status == &#39;unverified&#39;) {\n    return true\n  }\n  return false\n}&quot;</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="nt">&quot;language&quot;</span><span class="p">:</span> <span class="s2">&quot;javascript&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>trigger feed with filter</h3>

<p>Once the design document is created, the filter name can be used as a <a href="https://github.com/apache/incubator-openwhisk-package-cloudant#create-the-trigger-using-the-filter-function">trigger feed parameter</a>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">wsk</span> <span class="err">trigger</span> <span class="err">create</span> <span class="err">verify_emails</span> <span class="err">--feed</span> <span class="err">/_/myCloudant/changes</span> <span class="err">\</span>
</span><span class='line'><span class="err">--param</span> <span class="err">dbname</span> <span class="err">user_profiles</span> <span class="err">\</span>
</span><span class='line'><span class="err">--param</span> <span class="err">filter</span> <span class="s2">&quot;profile/unverified-emails&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The trigger only fires when a profile change contains an unverified email address. No more unnecessary invocations, which saves us money! üòé</p>

<h3>caveats</h3>

<p><em>&#8220;Why are users getting multiple verification emails?&#8221;</em> üò°</p>

<p>If a user changes their profile information, whilst leaving their email address the same but before clicking the verification email, an additional email will be sent.</p>

<p>This is because the <code>status</code> field is still in the <code>unverified</code> state when the next document update occurs. Filter functions are stateless and can&#8217;t decide if this email address has already been seen.</p>

<p>Instead of leaving the <code>status</code> field as <code>unverified</code>, the email action should change the state to another value, e.g. <code>pending</code>, to indicate the verification email has been sent.</p>

<p>Any further document updates, whilst waiting for the verification response, won&#8217;t pass the filter and users won&#8217;t receive multiple emails. üëç</p>

<h2>Conclusion</h2>

<p>CouchDB filters are an easy way to subscribe to a subset of events from the changes feed. Combining CouchDB trigger feeds with filters allows actions to ignore irrelevant document updates. Multiple trigger feeds can be set up from a single database using filter functions.</p>

<p>As well as saving unnecessary invocations (and therefore money), this can simplify data models. A single database can be used to store all documents, rather than having to split different types into multiple databases, whilst still supporting changes feeds per document type.</p>

<p>This is an awesome feature of CouchDB!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Large (Java) Applications on Apache OpenWhisk]]></title>
    <link href="http://jamesthom.as/blog/2019/02/05/large-java-applications-on-openwhisk/"/>
    <updated>2019-02-05T10:49:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/02/05/large-java-applications-on-openwhisk</id>
    <content type="html"><![CDATA[<p>This blog post will explain how to run large <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-java.md">Java applications</a> on <a href="http://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>.</p>

<p>Java actions are <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-java.md">deployed from JAR files</a> containing application class files. External libraries can be used by bundling those dependencies into a <a href="https://stackoverflow.com/questions/19150811/what-is-a-fat-jar">fat JAR file</a>. The JAR file must be less than the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/reference.md#per-action-artifact-mb-default-48mb">maximum action size</a> of 48MB.</p>

<blockquote><p>So, what if the application uses lots of external libraries and the JAR file is larger than 48MB? ü§î</p></blockquote>

<p>Apache OpenWhisk&#8217;s support for <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">custom Docker runtimes</a> provides a workaround. In a <a href="http://jamesthom.as/blog/2017/08/04/large-applications-on-openwhisk/">previous blog post</a>, we showed how this feature could be used with Python applications which rely on lots of external libraries.</p>

<p>Using the same approach with Java, a <a href="https://github.com/apache/incubator-openwhisk-runtime-java/">custom Java runtime</a> can be created with additional libraries pre-installed. Those libraries do not need to be included in the application jar, which will just contain private class files. This should hopefully reduce the JAR file to under the action size limit.</p>

<p><em>Let&#8217;s walk through an example to show how this works&#8230;.</em></p>

<h2>Example Java Class using External Libraries</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'><span class="kn">import</span> <span class="nn">com.google.gson.JsonObject</span><span class="o">;</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">org.apache.commons.text.WordUtils</span><span class="o">;</span>
</span><span class='line'>
</span><span class='line'><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Capitialize</span> <span class="o">{</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kd">static</span> <span class="n">JsonObject</span> <span class="nf">main</span><span class="o">(</span><span class="n">JsonObject</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">String</span> <span class="n">name</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="na">getAsJsonPrimitive</span><span class="o">(</span><span class="s">&quot;message&quot;</span><span class="o">).</span><span class="na">getAsString</span><span class="o">();</span>
</span><span class='line'>        <span class="n">JsonObject</span> <span class="n">response</span> <span class="o">=</span> <span class="k">new</span> <span class="n">JsonObject</span><span class="o">();</span>
</span><span class='line'>        <span class="n">response</span><span class="o">.</span><span class="na">addProperty</span><span class="o">(</span><span class="s">&quot;capitalized&quot;</span><span class="o">,</span> <span class="n">WordUtils</span><span class="o">.</span><span class="na">capitalize</span><span class="o">(</span><span class="n">name</span><span class="o">));</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">response</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This example Java action capitalises sentences from the input event. It uses the <a href="https://commons.apache.org/proper/commons-text/">Apache Commons Text library</a> to handle <a href="https://commons.apache.org/proper/commons-text/javadocs/api-release/org/apache/commons/text/WordUtils.html#capitalize(java.lang.String)">capitialisation</a> of input strings. This external library will be installed in the runtime, rather than bundled in the application JAR file.</p>

<h2>Build Custom Java Runtime</h2>

<ul>
<li>Clone the existing <a href="https://github.com/apache/incubator-openwhisk-runtime-java/">Apache OpenWhisk Java runtime repository</a>.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>git clone https://github.com/apache/incubator-openwhisk-runtime-java
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Edit the <code>core/java8/proxy/build.gradle</code> file and update the <code>dependencies</code> <a href="https://github.com/apache/incubator-openwhisk-runtime-java/blob/master/core/java8/proxy/build.gradle#L24-L26">configuration</a> with extra dependencies needed in the runtime.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>dependencies <span class="o">{</span>
</span><span class='line'>    compile <span class="s1">&#39;com.google.code.gson:gson:2.6.2&#39;</span>
</span><span class='line'>    compile <span class="s1">&#39;org.apache.commons:commons-text:1.6&#39;</span> // &lt;-- the additional library
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>Note: <code>com.google.code.gson:gson:2.6.2</code> is used by the runtime to handle JSON encoding/decoding. Do not remove this dependency.</em></p>

<ul>
<li>Execute the following command to build the custom <a href="https://en.wikipedia.org/wiki/Docker_%28software%29">Docker</a> image.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>./gradlew core:java8:distDocker
</span></code></pre></td></tr></table></div></figure>


<h2>Push Image To Docker Hub</h2>

<p>If the build process succeeds, a local Docker image named <code>java8action</code> should be available. This needs to be pushed to <a href="https://hub.docker.com/">Docker Hub</a> to allow Apache OpenWhisk to use it.</p>

<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/tag/">Tag</a> the custom image with a <a href="https://hub.docker.com/signup">Docker Hub username</a>.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>docker tag java8action &lt;DOCKERHUB_USERNAME&gt;/java8action
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/push/">Push</a> the tagged custom image to Docker Hub.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>docker push &lt;DOCKERHUB_USERNAME&gt;/java8action
</span></code></pre></td></tr></table></div></figure>


<h2>Create OpenWhisk Action With Custom Runtime</h2>

<ul>
<li>Compile the Java source file.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>javac Capitialize.java
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Create the application JAR from the class file.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>jar cvf capitialize.jar Capitialize.class
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Create the Java action with the custom runtime.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>wsk action create capitialize capitialize.jar --main Capitialize --docker &lt;DOCKERHUB_USERNAME&gt;/java8action
</span></code></pre></td></tr></table></div></figure>


<p><em><code>--main</code> is the class file name containing the action handler in the JAR file. <code>--docker</code> is the Docker image name for the custom runtime.</em></p>

<h2>Test it out!</h2>

<ul>
<li>Execute the <code>capitialize</code> action with input text to returned capitalised sentences.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>wsk action invoke capitialize -b -r -p message <span class="s2">&quot;this is a sentence&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>If this works, the following JSON should be printed to the console.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;capitalized&quot;</span><span class="p">:</span> <span class="s2">&quot;This Is A Sentence&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The external library has been used in the application without including it in the application JAR file! üíØüíØüíØ</p>

<h2>Conclusion</h2>

<p>Apache OpenWhisk supports running Java applications using fat JARs, which bundle application source code and external dependencies. JAR files cannot be more than 48MB, which can be challenging when applications uses lots of external libraries.</p>

<p>If application source files and external libraries result in JAR files larger than this limit, Apache OpenWhisk&#8217;s support for custom Docker runtimes provide a solution for running large Java applications on the platform.</p>

<p>By building a custom Java runtime, extra libraries can be pre-installed in the runtime. These dependencies do not need to be included in the application JAR file, which reduces the file size to under the action size limit. üëç</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Provisioning IBM Cloud Services With Terraform]]></title>
    <link href="http://jamesthom.as/blog/2019/01/25/provisioning-ibm-cloud-services-with-terraform/"/>
    <updated>2019-01-25T10:09:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/01/25/provisioning-ibm-cloud-services-with-terraform</id>
    <content type="html"><![CDATA[<p><strong>This blog post will teach you how to provision <a href="https://cloud.ibm.com/catalog">applications services</a> on <a href="https://cloud.ibm.com/">IBM Cloud</a> with <a href="https://www.terraform.io/">Terraform</a>.</strong></p>

<p>Terraform is an open-source &#8221;<a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">infrastructure-as-code</a>&#8221; tool. It allows cloud resources to be defined using a <a href="https://www.terraform.io/docs/configuration/syntax.html">declarative configuration file</a>. The <a href="https://www.terraform.io/docs/commands/index.html">Terraform CLI</a> then uses this file to automatically provision and maintain cloud infrastructure needed by your application. This allows the creation of reproducible environments in the cloud across your application life cycle.</p>

<p>IBM Cloud created an <a href="https://github.com/IBM-Cloud/terraform-provider-ibm">official provider plugin</a> for Terraform. This allows IBM Cloud services to be <a href="https://ibm-cloud.github.io/tf-ibm-docs/">declared</a> in Terraform configuration files. This is a much better approach than using the CLI or IBM Cloud UI to create application services manually.</p>

<p><strong>The following steps needed to set up Terraform with IBM Cloud will be explained.</strong></p>

<ul>
<li><em>Install Terraform CLI tools and IBM Cloud Provider Plugin.</em></li>
<li><em>Create API keys for platform access.</em></li>
<li><em>Terraform configuration for IBM Cloud services.</em></li>
<li><em>Terraform CLI commands to provision IBM Cloud services.</em></li>
</ul>


<p>Ready? Let&#8217;s go! üòéüòéüòé</p>

<h2>Install Terraform</h2>

<ul>
<li><a href="https://www.terraform.io/intro/getting-started/install.html">Download and install</a> Terraform for your system.</li>
</ul>


<p>Once installed, the <code>terraform</code> command will be available.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ terraform
</span><span class='line'>Usage: terraform [-version] [-help] &lt;command&gt; [args]
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h2>Install IBM Cloud Terraform Plugin</h2>

<ul>
<li>Download the IBM Cloud Terraform plugin binary from the <a href="https://github.com/IBM-Cloud/terraform-provider-ibm/releases">Github releases page</a>.</li>
<li>Unzip the release archive to extract the plugin binary (<code>terraform-provider-ibm_vX.Y.Z</code>).</li>
<li>Move the binary into the <a href="https://www.terraform.io/docs/configuration/providers.html#third-party-plugins">Terraform plugins directory</a> for the platform.

<ul>
<li><em>Linux/Unix/OS X:</em> <code>~/.terraform.d/plugins</code></li>
<li><em>Windows:</em> <code>%APPDATA%\terraform.d\plugins</code></li>
</ul>
</li>
</ul>


<h2>IBM Cloud Authentication Credentials</h2>

<p>IBM Cloud&#8217;s Terraform provider plugin needs authentication credentials to interact with the platform. This is best handled by creating an API key and exporting as an environment variable. API keys can be created from the <a href="https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use">IBM Cloud CLI</a> or the <a href="https://cloud.ibm.com/iam#/users">web site</a>.</p>

<h3>using the cli</h3>

<ul>
<li>Run the <a href="https://console.bluemix.net/docs/cli/reference/ibmcloud/cli_api_policy.html#ibmcloud_iam_api_key_create">following command</a> to generate an API key.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud iam api-key-create terraform-api-key</span></code></pre></td></tr></table></div></figure>


<p>The <code>apikey</code> property in the JSON output is the API key value.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "name": "terraform-api-key",
</span><span class='line'>  "description": "...",
</span><span class='line'>  "apikey": "xxx-yyy-zzz",
</span><span class='line'>  "createdAt": "...",
</span><span class='line'>  "locked": false,
</span><span class='line'>  "uuid": "..."
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><em>Store this value securely. API keys cannot be retrieved after creation!</em></p>

<h3>using the web site.</h3>

<ul>
<li>From the <a href="https://cloud.ibm.com/iam#/users">IAM Users page</a>, select a user account.</li>
<li>Under the &#8221;<em>API keys</em>&#8221; table, click the &#8221;<em>Create an IBM Cloud API Key</em>&#8221; button.</li>
<li>Give the key a name and (optional) description.</li>
<li>Make a note of the API key value returned. API keys cannot be retrieved after creation.</li>
</ul>


<h3>exporting as an environment variable</h3>

<ul>
<li>Expose the API key as an environment variable to provide credentials to Terraform.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>export BM_API_KEY=API_KEY_VALUE</span></code></pre></td></tr></table></div></figure>


<h2>Terraform configuration</h2>

<p>We can now start to write configuration files to describe IBM Cloud services we want to provision. Terraform configuration files are human-readable text files, ending with the <code>.tf</code> extension, which contain <a href="https://github.com/hashicorp/hcl">HashiCorp Configuration Language</a> (HCL) syntax.</p>

<p>IBM Cloud platform services come in two flavours: IAM managed resource instances and older Cloud Foundry-based service instances. This is due to the history of IBM Cloud starting as Bluemix, a Cloud Foundry-based cloud platform. Both platform services types can be provisioned using Terraform.</p>

<p>Most IBM Cloud platform services are available today as &#8221;<strong>resource instances</strong>&#8221;.</p>

<h3>create new configuration file</h3>

<ul>
<li>Create a new <code>infra.tf</code> file which contains the following syntax.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>provider "ibm" {}</span></code></pre></td></tr></table></div></figure>


<h3>add resource instances</h3>

<p><a href="https://ibm-cloud.github.io/tf-ibm-docs/v0.14.1/r/resource_instance.html">Resource instances</a> can be added to the configuration file as follows.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource "ibm_resource_instance" "resource_instance_name" {
</span><span class='line'>  name              = "test"
</span><span class='line'>  service           = "service-id"
</span><span class='line'>  plan              = "service-plan"
</span><span class='line'>  location          = "region-info"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li><code>resource_instance_name</code> - identifier for this service in the configuration, referenced by service keys.</li>
<li><code>name</code> - user-provided service name used by the platform to identify service.</li>
<li><code>service</code> - service identifier on the platform (can be found in the service documentation page).</li>
<li><code>plan</code> - service plan used for billing.</li>
<li><code>location</code> - cloud region used during service provisioning.</li>
</ul>


<p>Here is an example of provisioning a <a href="https://cloud.ibm.com/catalog/services/cloudant">Cloudant</a> database using the <code>ibm_resource_instance</code> configuration.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource "ibm_resource_instance" "cloudant" {
</span><span class='line'>  name              = "my-cloudant-db"
</span><span class='line'>  service           = "cloudantnosqldb"
</span><span class='line'>  plan              = "lite"
</span><span class='line'>  location          = "us-south"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><em>Other parameters are supported for resource configuration, see the <a href="https://ibm-cloud.github.io/tf-ibm-docs/v0.14.1/r/resource_instance.html">docs</a> for more details&#8230;</em></p>

<h3>add resource keys</h3>

<p>Applications accessing resource instances need service credentials. Access keys can also be provisioned using <a href="https://ibm-cloud.github.io/tf-ibm-docs/v0.14.1/r/resource_key.html">Terraform configuration</a>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource "ibm_resource_key" "resource_key_name" {
</span><span class='line'>  name                 = "my-key-name"
</span><span class='line'>  role                 = "&lt;IAM_ROLE&gt;"
</span><span class='line'>  resource_instance_id = "${ibm_resource_instance.resource_instance_name.id}"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li><code>name</code> - user-provided key name used by the platform to identify the credentials.</li>
<li><code>role</code> - IBM Cloud <a href="https://cloud.ibm.com/docs/iam/users_roles.html#iamusermanrol">IAM roles</a> (as supported by the service, e.g. Writer or Reader).</li>
</ul>


<p>Here is an example of provisioning a resource key for the <a href="https://cloud.ibm.com/catalog/services/cloudant">Cloudant</a> example from above.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource "ibm_resource_key" "cloudant_key" {
</span><span class='line'>  name                  = "my-db-key"
</span><span class='line'>  role                  = "Manager"
</span><span class='line'>  resource_instance_id  = "${ibm_resource_instance.cloudant.id}"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h3>(optional) add services instances to configuration</h3>

<p>Use the <a href="https://ibm-cloud.github.io/tf-ibm-docs/v0.14.1/r/service_instance.html">following configuration</a> to provision older Cloud Foundry services.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource "ibm_service_instance" "service_instance_name" {
</span><span class='line'>  name       = "test"
</span><span class='line'>  space_guid = "cf-space-guid"
</span><span class='line'>  service    = "service-id"
</span><span class='line'>  plan       = "service-plan"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li><code>service_instance_name</code> - identifier for this service in the configuration, referenced by service keys.</li>
<li><code>name</code> - user-provided service name used by the platform to identify the service.</li>
<li><code>service</code> - service identifier on the platform (can be found in the service documentation page).</li>
<li><code>plan</code> - service plan used for billing.</li>
</ul>


<h3>(optional) add service instance keys</h3>

<p>Applications accessing service instances need service credentials. Service keys can also be provisioned using <a href="https://ibm-cloud.github.io/tf-ibm-docs/v0.14.1/r/service_key.html">Terraform configuration</a>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>resource "ibm_service_key" "service_key_name" {
</span><span class='line'>  name                 = "my-key-name"
</span><span class='line'>  service_instance_guid = "${ibm_service_instance.service_instance_name.id}"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li><code>name</code> - user-provided key name used by the platform to identify the credentials.</li>
<li><code>service_instance_guid</code> - Service instance GUID.</li>
</ul>


<h3>add output configuration</h3>

<p>Accessing service keys and other service details is handled with <code>output</code> <a href="https://www.terraform.io/docs/configuration/outputs.html">configuration</a> in Terraform files.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>output "app_credentials" {
</span><span class='line'>  value = "${ibm_resource_key.resource_key_name.credentials}"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Output values can be logged to the console using the <a href="https://www.terraform.io/docs/commands/output.html">Terraform CLI</a>.</p>

<p>Here is an example of accessing Cloudant credentials provisioned in the example above.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>output "cloudant_credentials" {
</span><span class='line'>  value = "${ibm_resource_key.cloudant_key.credentials}"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>Run Terraform commands</h2>

<p>Having finished the configuration file to describe our applications services, the Terraform CLI can now provision those services!</p>

<ul>
<li><a href="https://www.terraform.io/docs/commands/init.html">Initialise</a> the terraform project.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>terraform init</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://www.terraform.io/docs/commands/validate.html">Validate</a> the configuration file for syntax errors.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>terraform validate</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://www.terraform.io/docs/commands/plan.html">Display</a> the platform changes to be executed on the configuration file.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>terraform plan</span></code></pre></td></tr></table></div></figure>


<p><em>Here is the example output from running that command with the Cloudant database example.</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Refreshing Terraform state in-memory prior to plan...
</span><span class='line'>The refreshed state will be used to calculate this plan, but will not be
</span><span class='line'>persisted to local or remote state storage.
</span><span class='line'>
</span><span class='line'>------------------------------------------------------------------------
</span><span class='line'>
</span><span class='line'>An execution plan has been generated and is shown below.
</span><span class='line'>Resource actions are indicated with the following symbols:
</span><span class='line'>  + create
</span><span class='line'>
</span><span class='line'>Terraform will perform the following actions:
</span><span class='line'>
</span><span class='line'>  + ibm_resource_instance.cloudant
</span><span class='line'>      id:                   &lt;computed&gt;
</span><span class='line'>      location:             "us-south"
</span><span class='line'>      name:                 "my-cloudant-db"
</span><span class='line'>      plan:                 "lite"
</span><span class='line'>      service:              "cloudantnosqldb"
</span><span class='line'>      status:               &lt;computed&gt;
</span><span class='line'>
</span><span class='line'>  + ibm_resource_key.cloudant_key
</span><span class='line'>      id:                   &lt;computed&gt;
</span><span class='line'>      credentials.%:        &lt;computed&gt;
</span><span class='line'>      name:                 "my-db-key"
</span><span class='line'>      parameters.%:         &lt;computed&gt;
</span><span class='line'>      resource_instance_id: "${ibm_resource_instance.cloudant.id}"
</span><span class='line'>      role:                 "Manager"
</span><span class='line'>      status:               &lt;computed&gt;
</span><span class='line'>
</span><span class='line'>Plan: 2 to add, 0 to change, 0 to destroy.
</span><span class='line'>
</span><span class='line'>------------------------------------------------------------------------
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://www.terraform.io/docs/commands/apply.html">Execute</a> the planned changes using <code>apply</code>.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>terraform apply -auto-approve</span></code></pre></td></tr></table></div></figure>


<p>Terraform will now provision the platform services, resources keys and output credentials to the console.</p>

<p><em>Here is the example output from running that command with the Cloudant database example.</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibm_resource_instance.cloudant: Creating...
</span><span class='line'>  location: "" =&gt; "us-south"
</span><span class='line'>  name:     "" =&gt; "my-cloudant-db"
</span><span class='line'>  plan:     "" =&gt; "lite"
</span><span class='line'>  service:  "" =&gt; "cloudantnosqldb"
</span><span class='line'>  status:   "" =&gt; "&lt;computed&gt;"
</span><span class='line'>ibm_resource_instance.cloudant: Still creating... (10s elapsed)
</span><span class='line'>ibm_resource_instance.cloudant: Still creating... (20s elapsed)
</span><span class='line'>ibm_resource_instance.cloudant: Creation complete after 21s (ID: ...)
</span><span class='line'>ibm_resource_key.cloudant_key: Creating...
</span><span class='line'>  credentials.%:        "" =&gt; "&lt;computed&gt;"
</span><span class='line'>  name:                 "" =&gt; "my-db-key"
</span><span class='line'>  parameters.%:         "" =&gt; "&lt;computed&gt;"
</span><span class='line'>  resource_instance_id: "" =&gt; "crn:v1:bluemix:public:cloudantnosqldb:us-south:a/...::"
</span><span class='line'>  role:                 "" =&gt; "Manager"
</span><span class='line'>  status:               "" =&gt; "&lt;computed&gt;"
</span><span class='line'>ibm_resource_key.cloudant_key: Creation complete after 8s (ID: ...)
</span><span class='line'>
</span><span class='line'>Apply complete! Resources: 2 added, 0 changed, 0 destroyed.
</span><span class='line'>
</span><span class='line'>Outputs:
</span><span class='line'>
</span><span class='line'>cloudant_credentials = {
</span><span class='line'>  apikey = &lt;API_KEY_VALUE&gt;
</span><span class='line'>  host = &lt;DB_HOST&gt;
</span><span class='line'>  ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><strong>API keys from the <code>cloudant_credentials</code> output section can be used applications to interact with the provisioned database! üëèüëèüëè</strong></p>

<h2>Conclusion</h2>

<p>Provisioning cloud services using Terraform is a great way to manage application resources on IBM Cloud.</p>

<p>Applications resources are defined in a declarative configuration file, following the &#8220;infrastructure-as-code&#8221; approach to managing cloud environments. This configuration is maintained in the application&#8217;s source code repository to enable reproducible environments.</p>

<p>IBM Cloud provides an official provider plugin for Terraform. This allows IBM Cloud services to be defined through custom configuration primitives. Developers can then use the Terraform CLI to provision new resources and extract service keys needed to access those services. üíØüíØüíØ</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Loosely-coupled Serverless Functions With Apache Openwhisk]]></title>
    <link href="http://jamesthom.as/blog/2019/01/18/loosely-coupled-serverless-functions-with-openwhisk/"/>
    <updated>2019-01-18T15:10:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/01/18/loosely-coupled-serverless-functions-with-openwhisk</id>
    <content type="html"><![CDATA[<p>Just like software engineering, <a href="https://medium.com/@PaulDJohnston/serverless-best-practices-b3c97d551535">best practices for serverless applications</a> advise keeping functions small and focused on a single task, aka &#8221;<a href="https://en.wikipedia.org/wiki/Unix_philosophy#Do_One_Thing_and_Do_It_Well">do one thing and do it well</a>&#8221;. Small single-purpose functions are easier to develop, test and debug. üëç</p>

<p><strong>But what happens when you need execute multiple asynchronous tasks (implemented as separate functions) from an incoming event, like an API request?</strong> ü§î</p>

<h2>Functions Calling Functions?</h2>

<p>Functions can invoke other functions directly, using asynchronous calls through the client SDK. This works at the cost of introducing <a href="https://en.wikipedia.org/wiki/Coupling_%28computer_programming%29">tighter coupling</a> between functions, which is generally avoided in software engineering! Disadvantages of this approach include&#8230;</p>

<ul>
<li><em>Functions which call other functions can be more difficult to test. Test cases needs to mock out the client SDK to remove side-effects during unit or integration tests.</em></li>
<li><em>It can lead to repetitive code if you want to fire multiple tasks with the same event. Each invocation needs to manually handle error conditions and re-tries on network or other issues, which complicates the business logic.</em></li>
<li><em>Modifying the functions being invoked cannot be changed dynamically. The function doing the invoking has to be re-deployed with updated code.</em></li>
</ul>


<p><a href="https://twitter.com/PaulDJohnston">Some people</a> have even labelled &#8221;<em>functions calling functions</em>&#8221; an <a href="https://medium.com/@PaulDJohnston/serverless-best-practices-b3c97d551535">anti-pattern</a> in serverless development! üò±</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Most common Serverless mistake?<br><br>Functions calling other functions<br><br>Why do people make this mistake?<br><br>Because people assume they should build functions like microservices and then use them in a similar way.<br><br>Causes no end of problems</p>&mdash; Serverless / Green Data Advocate (@PaulDJohnston) <a href="https://twitter.com/PaulDJohnston/status/1085106548270088193?ref_src=twsrc%5Etfw">January 15, 2019</a></blockquote>


<p><strong>Hmmm&#8230; so what should we do?</strong></p>

<p>Apache OpenWhisk has an awesome feature to help with this problem, triggers and rules! üëè</p>

<h2>OpenWhisk Triggers &amp; Rules</h2>

<p>Triggers and Rules in OpenWhisk are similar to the <a href="https://en.wikipedia.org/wiki/Observer_pattern">Observer pattern</a> from software engineering.</p>

<p>Users can fire &#8220;events&#8221; in OpenWhisk by invoking a named <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/triggers_rules.md#creating-triggers">trigger</a> with parameters. <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/triggers_rules.md#using-rules">Rules</a> are used to &#8220;subscribe&#8221; actions to all events for a given trigger name. Actions are invoked with event parameters when a trigger is fired. Multiple rules can be configured to support multiple &#8220;listeners&#8221; to the same trigger events. Event senders are decoupled from event receivers.</p>

<p><img src="http://jamesthom.as/images/loose-coupling-openwhisk/t-r-a.png"></p>

<p>Developers using OpenWhisk are most familiar with triggers when used with <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/catalog.md">feed providers</a>. This is used to subscribe actions to external event sources. The feed provider is responsible for listening to the event source and automatically firing trigger events with event details.</p>

<p><strong>But triggers can be fired manually from actions to provide custom event streams!</strong> üôå</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">openwhisk</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;openwhisk&#39;</span><span class="p">)</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">params</span> <span class="o">=</span> <span class="p">{</span><span class="nx">msg</span><span class="o">:</span> <span class="s1">&#39;event parameters&#39;</span><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// replace code like this...</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">ow</span><span class="p">.</span><span class="nx">actions</span><span class="p">.</span><span class="nx">invoke</span><span class="p">({</span><span class="nx">name</span><span class="o">:</span> <span class="s2">&quot;some-action&quot;</span><span class="p">,</span> <span class="nx">params</span><span class="p">})</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// ...with this</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">ow</span><span class="p">.</span><span class="nx">triggers</span><span class="p">.</span><span class="nx">invoke</span><span class="p">({</span><span class="nx">name</span><span class="o">:</span> <span class="s2">&quot;some-trigger&quot;</span><span class="p">,</span> <span class="nx">params</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>This allows applications to move towards an <a href="https://en.wikipedia.org/wiki/Event-driven_architecture">event-driven architecture</a> and promotes loose-coupling between functions with all the associated benefits for testing, deployment and scalability. üëå</p>

<h3>creating triggers</h3>

<p>Triggers are managed through the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/rest_api.md">platform API</a>. They can be created, deleted, retrieved and fired using  HTTP requests. Users normally interact with triggers through the <a href="https://github.com/apache/incubator-openwhisk-cli">CLI</a> or <a href="https://github.com/apache/incubator-openwhisk-client-js/">platform SDKs</a>.</p>

<p>Triggers can be created using the following CLI command.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">trigger</span> <span class="nx">create</span> <span class="o">&lt;</span><span class="nx">TRIGGER_NAME</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>default parameters</h3>

<p>Triggers support <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/parameters.md#setting-default-parameters-on-an-action">default parameters</a> like actions. Default parameters are stored in the platform and included in all trigger events. If the event object includes parameters with the same key, default parameter values are ignored.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">trigger</span> <span class="nx">create</span> <span class="o">&lt;</span><span class="nx">TRIGGER_NAME</span><span class="o">&gt;</span> <span class="o">-</span><span class="nx">p</span> <span class="o">&lt;</span><span class="nx">PARAM</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="nx">PARAM_VALUE</span><span class="o">&gt;</span> <span class="o">-</span><span class="nx">p</span> <span class="o">&lt;</span><span class="nx">PARAM_2</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="nx">PARAM_VALUE</span><span class="o">&gt;</span> <span class="p">...</span>
</span></code></pre></td></tr></table></div></figure>


<h3>binding triggers to actions with rules</h3>

<p>Rules bind triggers to actions. When triggers are fired, all actions connected via rules are invoked with the trigger event. Multiple rules can refer to the same trigger supporting multiple listeners to the same event.</p>

<p>Rules can also be created using the following CLI command.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">rule</span> <span class="nx">create</span> <span class="nx">RULE_NAME</span> <span class="nx">TRIGGER_NAME</span> <span class="nx">ACTION_NAME</span>
</span></code></pre></td></tr></table></div></figure>


<p>Tools like <a href="https://github.com/serverless/serverless-openwhisk">The Serverless Framework</a> and <a href="https://github.com/apache/incubator-openwhisk-wskdeploy">wskdeploy</a> allow users to configure triggers and rules declaratively through YAML configuration files.</p>

<h3>firing triggers</h3>

<p>The JS SDK can be used to <a href="https://github.com/apache/incubator-openwhisk-client-js#fire-trigger">fire triggers programatically</a> from applications.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">openwhisk</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;openwhisk&#39;</span><span class="p">)</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">name</span> <span class="o">=</span> <span class="s1">&#39;sample-trigger&#39;</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">params</span> <span class="o">=</span> <span class="p">{</span><span class="nx">msg</span><span class="o">:</span> <span class="s1">&#39;event parameters&#39;</span><span class="p">}</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">result</span> <span class="o">=</span> <span class="nx">ow</span><span class="p">.</span><span class="nx">triggers</span><span class="p">.</span><span class="nx">invoke</span><span class="p">({</span><span class="nx">name</span><span class="p">,</span> <span class="nx">params</span><span class="p">})</span>
</span></code></pre></td></tr></table></div></figure>


<p>CLI commands (<code>wsk trigger fire</code>) can fire triggers manually with event parameters for testing.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">trigger</span> <span class="nx">fire</span> <span class="nx">sample</span><span class="o">-</span><span class="nx">trigger</span> <span class="o">-</span><span class="nx">p</span> <span class="nx">msg</span> <span class="s2">&quot;event parameters&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>activation records for triggers</h3>

<p>Activation records are created for trigger events. These activation records contain event parameters, rules fired, activations ids and invocation status for each action invoked. This is useful for debugging trigger events when issues are occurring.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">$</span> <span class="nx">wsk</span> <span class="nx">trigger</span> <span class="nx">fire</span> <span class="nx">sample</span><span class="o">-</span><span class="nx">trigger</span> <span class="o">-</span><span class="nx">p</span> <span class="nx">hello</span> <span class="nx">world</span>
</span><span class='line'><span class="nx">ok</span><span class="o">:</span> <span class="nx">triggered</span> <span class="o">/</span><span class="nx">_</span><span class="o">/</span><span class="nx">sample</span><span class="o">-</span><span class="nx">trigger</span> <span class="kd">with</span> <span class="nx">id</span> <span class="o">&lt;</span><span class="nx">ACTIVATION_ID</span><span class="o">&gt;</span>
</span><span class='line'><span class="nx">$</span> <span class="nx">wsk</span> <span class="nx">activation</span> <span class="nx">get</span> <span class="o">&lt;</span><span class="nx">ACTIVATION_ID</span><span class="o">&gt;</span>
</span><span class='line'><span class="nx">ok</span><span class="o">:</span> <span class="nx">got</span> <span class="nx">activation</span> <span class="o">&lt;</span><span class="nx">ACTIVATION_ID</span><span class="o">&gt;</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'> <span class="p">...</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>response.result</code> property in the activation record contains the fired trigger event (combining default and event parameter values).</p>

<p>Rules fired by the trigger are recorded in activation records as the JSON values under the <code>logs</code> parameter.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;statusCode&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;success&quot;</span><span class="p">:</span> <span class="kc">true</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;activationId&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;ACTION_ACTIVATION_ID&gt;&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;rule&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;RULE_NAME&gt;&quot;</span><span class="p">,</span>
</span><span class='line'>  <span class="nt">&quot;action&quot;</span><span class="p">:</span> <span class="s2">&quot;&lt;ACTION_NAME&gt;&quot;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>Activation records are only generated when triggers have enabled rules with valid actions attached</em></p>

<h2>Example - WC Goal Bot</h2>

<p>This is great in theory but what about in practice?</p>

<p><a href="https://github.com/jthomas/goalbot">Goal Bot</a> was a small serverless application I built in 2018 for the World Cup. It was a <a href="https://twitter.com/WC2018_Goals">Twitter bot</a> which tweeted out all goals scored in real-time. The application used the  &#8220;actions connected via triggers events&#8221; architecture pattern. This made development and testing easier and faster.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">‚öΩÔ∏è GOAL ‚öΩÔ∏è<br>üë® Harry MAGUIRE (Û†Åøüè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø ) @ 30&#39;. üë®<br>üèü Sweden üá∏üá™ (0) v England Û†Åøüè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø (1) üèü<a href="https://twitter.com/hashtag/WorldCup?src=hash&amp;ref_src=twsrc%5Etfw">#WorldCup</a></p>&mdash; WC 2018 Goal Bot (@WC2018_Goals) <a href="https://twitter.com/WC2018_Goals/status/1015604110006120448?ref_src=twsrc%5Etfw">July 7, 2018</a></blockquote>


<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>This function has two functions <code>goals</code> and <code>twitter</code>.</p>

<p><code>goals</code> was <a href="https://github.com/jthomas/goalbot/blob/master/serverless.yml#L11-L16">responsible</a> for detecting new goals scored using an external API. When invoked, it would retrieve all goals currently scored in the World Cup. Comparing the API response to a previous cached version calculated new goals scored. This function was connected to the alarm event source to run once a minute.</p>

<p><code>twitter</code> was <a href="https://github.com/jthomas/goalbot/blob/master/serverless.yml#L17-L22">responsible</a> for sending tweets from the @WC_Goals account. Twitter&#8217;s API was used to create  goal tweets constructed from the event parameters.</p>

<p><strong>Goal events detected in the <code>goals</code> function need to be used to invoke the <code>twitter</code> function.</strong></p>

<p>Rather than the <code>goals</code> function invoke the <code>twitter</code> function directly, a trigger event (<code>goal</code>) was <a href="https://github.com/jthomas/goalbot/blob/master/lib/goal_tracker.js#L39-L41">fired</a>. The <code>twitter</code> function was bound to the <code>goal</code> trigger using a <a href="https://github.com/jthomas/goalbot/blob/master/serverless.yml#L21-L22">custom rule</a>.</p>

<p><img src="http://jamesthom.as/images/loose-coupling-openwhisk/goalbot.png"></p>

<p>De-coupling the two tasks in my application (checking for new goals and creating tweets) using triggers and rules had the following benefits&#8230;</p>

<ul>
<li><p>The <code>goals</code> function could be invoked in testing without tweets being sent. By disabling the rule binding the <code>twitter</code> function to the trigger, the goals function can fire events without causing side-effects.</p></li>
<li><p>Compared to having a &#8220;mono-function&#8221; combining both tasks, splitting tasks into functions means the <code>twitter</code> function can be tested with manual events, rather than having to manipulate the database and stub API responses to generate the correct test data.</p></li>
<li><p>It would also be easy to extend this architecture with additional notification services, like slack bots. New notification services could be attached to the same trigger source with an additional rule. This would not require any changes to the <code>goals</code> or <code>twitter</code> functions.</p></li>
</ul>


<h2>Triggers versus Queues</h2>

<p>Another common solution to de-coupling functions in serverless architectures is using <a href="https://theburningmonk.com/2018/04/what-is-the-best-event-source-for-doing-pub-sub-with-aws-lambda/">message queues</a>.</p>

<p>Functions push events in external queues, rather than invoking triggers directly. Event sources are responsible for firing the registered functions with new messages. Apache OpenWhisk <a href="https://github.com/apache/incubator-openwhisk-package-kafka">supports Kafka</a> as an event source which could be used with this approach.</p>

<p><em>How does firing triggers directly compare to pushing events into an external queue (or other event source)?</em></p>

<p>Both queues and triggers can be used to achieve the same goal (&#8221;<em>connect functions via events</em>&#8221;) but have different semantics. It is important to understand the benefits of both to choose the most appropriate architecture for your application.</p>

<h3>benefits of using triggers against queues</h3>

<p>Triggers are built into the Apache OpenWhisk platform. There is no configuration needed to use them. External event sources like queues need to be provisioned and managed as additional cloud services.</p>

<p>Trigger invocations are free in IBM Cloud Functions. IBM Cloud Functions <a href="https://console.bluemix.net/openwhisk/learn/pricing">charges only</a> for execution time and memory used in functions. Queues will incur additional usage costs based on the service&#8217;s pricing plan.</p>

<h3>disadvantages of using triggers against queues</h3>

<p>Triggers are not queues. Triggers are not queues. Triggers are not queues. üíØ</p>

<p>If a trigger is fired and no actions are connected, the event is lost. Trigger events are not persisted until listeners are attached. <strong>If you need event persistence, message priorities, disaster recovery and other advanced features provided by message queues, use a message queue!</strong></p>

<p>Triggers are subject to <a href="https://console.bluemix.net/docs/openwhisk/openwhisk_reference.html#openwhisk_syslimits">rate limiting</a> in Apache OpenWhisk. In IBM Cloud Functions, this defaults to 1000 concurrent invocations and 5000 total invocations per namespace per minute. These limits can be raised through a support ticket but there are practical limits to the maximum rates allowed. Queues have support for much higher throughput rates.</p>

<p>External event providers are also responsible for handling the retries when triggers have been rate-limited due to excess events. Invoking triggers manually relies on the invoking function to handle this. Emulating retry behaviour from an event provider is impractical due to costs and limits on function duration.</p>

<h2>Other hints and tips</h2>

<p><strong><em>Want to invoke an action which fires triggers without setting off listeners?</em></strong></p>

<p>Rules can be dynamically disabled without having to remove them. This can be used during integration testing or debugging issues in production.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">wsk</span> <span class="err">rule</span> <span class="err">disable</span> <span class="err">RULE_NAME</span>
</span><span class='line'><span class="err">wsk</span> <span class="err">rule</span> <span class="err">enable</span> <span class="err">RULE_NAME</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong><em>Want to verify triggers are fired with correct events without mocking client libraries?</em></strong></p>

<p>Trigger events are not logged unless there is at least one enabled rule. Create a new rule which binds the <code>/whisk.system/utils/echo</code> action to the trigger. This built-in function just returns input parameters as the function response. This means the activation records with trigger events will now be available.</p>

<h2>conclusion</h2>

<p>Building event-driven serverless applications from loosely-coupled functions has numerous benefits including development speed, improved testability, deployment velocity, lower costs and more.</p>

<p>Decomposing &#8220;monolithic&#8221; apps into independent serverless functions often needs event handling functions to trigger off multiple backend operations, implemented in separate serverless functions. Developers unfamiliar with serverless often resort to direct function invocations.</p>

<p>Whilst this works, it introduces tight coupling between those functions, which is normally avoided in software engineering. This approach has even been highlighted as a &#8220;serverless&#8221; anti-pattern.</p>

<p>Apache OpenWhisk has an awesome feature to help with this problems, triggers and rules!</p>

<p>Triggers provide a lightweight event firing mechanism in the platform. Rules bind actions to triggers to automate invoking actions when events are fired. Applications can fire trigger events to invoke other operations, rather than using direct invocations. This keeps the event sender and receivers de-coupled from each other. üëè</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Highly Available Serverless Apps With Cloudant's Cross-Region Replication]]></title>
    <link href="http://jamesthom.as/blog/2019/01/10/highly-available-serverless-apps-with-cloudant-cross-region-replication/"/>
    <updated>2019-01-10T11:23:00+00:00</updated>
    <id>http://jamesthom.as/blog/2019/01/10/highly-available-serverless-apps-with-cloudant-cross-region-replication</id>
    <content type="html"><![CDATA[<p>Building <a href="https://www.techrepublic.com/blog/the-enterprise-cloud/what-high-availability-for-cloud-services-means-in-the-real-world/">highly available</a> serverless applications relies on eliminating &#8221;<a href="https://en.wikipedia.org/wiki/Single_point_of_failure"><em>single points of failure</em></a>&#8221; from application architectures.</p>

<p><a href="https://cloud.ibm.com/docs/tutorials/multi-region-serverless.html#deploy-serverless-apps-across-multiple-regions">Existing tutorials</a> showed how to deploy the same serverless application on IBM Cloud in different regions. Using the <a href="https://cloud.ibm.com/docs/infrastructure/cis/glb.html#global-load-balancer-glb-concepts">Global Load Balancer</a> from <a href="https://cloud.ibm.com/catalog/services/internet-svcs">IBM Cloud Internet Services</a>, traffic is distributed across multiple applications from the same hostname. The <a href="https://cloud.ibm.com/docs/infrastructure/cis/glb.html#global-load-balancer-glb-concepts">Global Load Balancer</a> automatically detects outages in the regional applications and redirects traffics as necessary.</p>

<p><strong>But what if all instances rely on the same database service and that has issues?</strong> üò±üî•</p>

<p>In addition to running multiple instances of the application, independent databases in different regions are also necessary for a highly available serverless application. Maintaining consistent application state across regions needs all database changes to be automatically synchronised between instances. ü§î</p>

<p><strong>In this blog post, we&#8217;re going to look at using <a href="https://cloud.ibm.com/catalog/services/cloudant">IBM Cloudant&#8217;s</a> <a href="https://console.bluemix.net/docs/services/Cloudant/guides/active-active.html#configuring-ibm-cloudant-for-cross-region-disaster-recovery">replication service</a> to set up a &#8221;<a href="https://en.wikipedia.org/wiki/Multi-master_replication">multi-master</a>&#8221; replication between regional database instances.</strong></p>

<p>Once this is enabled, database changes will automatically be synchronised in real-time between all database instances. Serverless applications can use their regional database instance and be confident application state will be consistent globally (for some definition of <a href="https://en.wikipedia.org/wiki/Eventual_consistency">consistent</a>&#8230;). üíØ</p>

<h2>example serverless application - todo backend</h2>

<p>This <a href="https://github.com/IBM/ibm-cloud-functions-refarch-serverless-apis">serverless application</a> implements a <a href="https://www.todobackend.com/">TODO backend</a> using <a href="https://cloud.ibm.com/openwhisk">IBM Cloud Functions</a> and <a href="https://cloud.ibm.com/catalog/services/cloudant">IBM Cloudant</a>.</p>

<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/todo-frontpage.png"></p>

<p>It provides an REST API for interacting with a TODO service. This can be used with the <a href="https://www.todobackend.com/client/index.html">front-end client</a> to add, complete and remove todos from a list.</p>

<p><strong>Let&#8217;s make this <a href="https://github.com/IBM/ibm-cloud-functions-refarch-serverless-apis">example serverless application</a> &#8220;highly available&#8221;. üëç</strong></p>

<p>The application will be deployed to two different IBM Cloud regions (London and Dallas). Separate database instances will be provisioned in each region. Applications will use their regional database instance but share global state via replication.</p>

<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/architecture.png"></p>

<h2>deploy serverless app to multiple regions</h2>

<p>This Github <a href="https://github.com/IBM/ibm-cloud-functions-refarch-serverless-apis">repo</a> has an <a href="https://github.com/IBM/ibm-cloud-functions-refarch-serverless-apis/blob/master/deploy.sh">automatic deployment script</a> to deploy the serverless application (using <code>wskdeploy</code>) and application services (using <code>terraform</code>).</p>

<p><strong><em>Install the prerequisites listed <a href="https://github.com/IBM/ibm-cloud-functions-refarch-serverless-apis#code-and-tools">here</a> before proceeding with these instructions.</em></strong></p>

<h3>download example application</h3>

<ul>
<li>Clone the Git repository to a local directory.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/IBM/ibm-cloud-functions-refarch-serverless-apis</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Enter the source code directory.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd ibm-cloud-functions-refarch-serverless-apis</span></code></pre></td></tr></table></div></figure>


<h3>create IAM key for serverless app</h3>

<p><em>Have you already signed up for an <a href="https://cloud.ibm.com/registration">IBM Cloud account</a> and <a href="https://cloud.ibm.com/docs/cli/reference/ibmcloud/download_cli.html#install_use">installed the CLI</a>? If not, please do that before proceeding.</em></p>

<ul>
<li>Create an IAM key which will be used to deploy the serverless application.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ibmcloud iam api-key-create serverless_api --file serverless_api.apikey</span></code></pre></td></tr></table></div></figure>


<h3>configure deployment variables</h3>

<ul>
<li>Create the <code>local.env</code> file in the current directory will the following contents.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>IBMCLOUD_API_KEY=&lt;IAM_API_KEY&gt;
</span><span class='line'>IBMCLOUD_ORG=&lt;YOUR_ORG&gt;
</span><span class='line'>IBMCLOUD_SPACE=&lt;REGION_SPACE&gt;
</span><span class='line'>IBMCLOUD_REGION=
</span><span class='line'>PROVISION_INFRASTRUCTURE=true
</span><span class='line'>API_USE_APPID=false</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Replace the <code>&lt;IAM_API_KEY&gt;</code> value with the <code>apikey</code> value from the <code>serverless_api.apikey</code> file.</li>
<li>Replace the <code>&lt;IBMCLOUD_ORG&gt;</code> value with an <a href="https://cloud.ibm.com/docs/account/orgs_spaces.html#orgsspacesusers">IBM Cloud organisation</a>.</li>
<li>Replace the <code>&lt;IBMCLOUD_SPACE&gt;</code> value with an <a href="https://cloud.ibm.com/docs/account/orgs_spaces.html#orgsspacesusers">IBM Cloud space</a>.</li>
</ul>


<p>The <code>PROVISION_INFRASTRUCTURE</code> parameter makes the deployment script automatically provision all application resources using Terraform.</p>

<p>Secured API endpoints are not required for this demonstration. Setting the <code>API_USE_APPID</code> parameter to <code>false</code> disables authentication on the endpoints and provisioning the AppID service.</p>

<h3>deploy to london</h3>

<ul>
<li>Set the <code>IBMCLOUD_REGION</code> to <code>eu-gb</code> in the <code>local.env</code> file.</li>
<li>Run the following command to deploy the application and provision all application resources.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./deploy.sh --install</span></code></pre></td></tr></table></div></figure>


<p>If the deployment have succeed, the following message should be printed to the console.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2019-01-08 10:51:51 All done.
</span><span class='line'>ok: APIs
</span><span class='line'>Action                                      Verb  API Name  URL
</span><span class='line'>/&lt;ORG&gt;_&lt;SPACE&gt;/todo_package/todo/get_todo   get   todos     https://&lt;UK_APIGW_URL&gt;/todo
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Use the <a href="https://www.todobackend.com/client/index.html">TODO front-end application</a> with the <a href="https://cloud.ibm.com/openwhisk/apimanagement">APIGW URL</a> shown in the console to interact with the remote TODO service in the London region.</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/testing-app.gif"></p>

<h3>deploy to dallas</h3>

<ul>
<li><p><strong>Rename the <code>terraform.tfstate</code> file in the <code>infra</code> folder to <code>terraform.tfstate.london</code></strong></p></li>
<li><p>Set the <code>IBMCLOUD_REGION</code> to <code>us-south</code> in the <code>local.env</code> file.</p></li>
<li>Run the following command to deploy the application and provision all application resources.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>./deploy.sh --install</span></code></pre></td></tr></table></div></figure>


<p>If the deployment have succeed, the following message should be printed to the console.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2019-01-08 10:51:51 All done.
</span><span class='line'>ok: APIs
</span><span class='line'>Action                                      Verb  API Name  URL
</span><span class='line'>/&lt;ORG&gt;_&lt;SPACE&gt;/todo_package/todo/get_todo   get   todos     https://&lt;US_APIGW_URL&gt;/todo
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Use the <a href="https://www.todobackend.com/client/index.html">TODO front-end application</a> with the <a href="https://cloud.ibm.com/openwhisk/apimanagement">APIGW URL</a> shown in the console to interact with the remote TODO service in the Dallas region.</li>
</ul>


<h2>configure cloudant cross-region replication</h2>

<p>There are now multiple copies of the same serverless application in different regions. Each region has an independent instance of Cloudant provisioned.</p>

<p><a href="https://console.bluemix.net/docs/services/Cloudant/api/replication.html">Cloudant replication</a> is a one-way synchronisation from a source to a destination database. To set up a <a href="https://console.bluemix.net/docs/services/Cloudant/guides/active-active.html#configuring-ibm-cloudant-for-cross-region-disaster-recovery">bi-directional data synchronisation</a>, two different replications will need to be configured.</p>

<h3>create api keys for replication access</h3>

<p>Before configuring replication between the regional databases, API keys need to be created to allow remote access on both hosts. API keys need to be created per regional instance.</p>

<ul>
<li>From the <a href="https://cloud.ibm.com/resources">IBM Cloud Resource List</a>, find the cloudant instances provisioned in London and Dallas.</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/resource-list.png"></p>

<ul>
<li>Open the Cloudant Dashboard for each service instance.</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/opening-cloudant-dashboard.gif"></p>

<p>Follow these instructions on both hosts to generate API keys for replication with the correct permissions.</p>

<ul>
<li>Click the &#8220;Databases&#8221; icon to show all the databases on this instance.</li>
<li>Click the üîí icon in the &#8220;todos&#8221; database row in the table to open the permissions page.</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/databases-list.png"></p>

<p><em>Can&#8217;t find the &#8220;todos&#8221; database in the Cloudant dashboard? Make sure you interact with the TODO backend from the <a href="https://www.todobackend.com/client/index.html">front-end application</a>. This will automatically create the database if it doesn&#8217;t exist.</em></p>

<ul>
<li>Click &#8220;Generate API Key&#8221; on the permissions page.</li>
<li>Make a note of the key identifier and password.</li>
<li>Set the <code>_reader_</code>, <code>_writer</code> and <code>_replicator</code> permissions for the newly created key.</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/db-api-key.png"></p>

<h3>set up cross-region replication</h3>

<p>Replication jobs need to be configured on both database hosts. These can be created from the Cloudant dashboard. <strong>Repeat these instructions on both hosts.</strong></p>

<ul>
<li>Open the Cloudant Dashboard for each service instance.</li>
<li>Click the &#8220;Replication&#8221; icon from the panel menu.</li>
<li>Click the &#8220;New Replication&#8221; button.</li>
<li>Set the following &#8220;Source&#8221; values in the &#8220;Job configuration&#8221; panel.

<ul>
<li>Type: <em>&#8220;Local Database&#8221;</em></li>
<li>Name: <em>&#8220;todos&#8221;</em></li>
<li>Authentication: <em>&#8220;Cloudant username or API Key&#8221;</em></li>
<li>Fill in the API key and password for this local database host in the input fields.</li>
</ul>
</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/task-source.png"></p>

<ul>
<li>Set the following &#8220;Target&#8221; values in the &#8220;Job configuration&#8221; panel.

<ul>
<li>Type: <em>&#8220;Existing Remote Database&#8221;</em></li>
<li>Name: <em>&#8220;https://<REMOTE_CLOUDANT_HOST>/todos&#8221;</em></li>
<li>Authentication: <em>&#8220;Cloudant username or API Key&#8221;</em></li>
<li>Fill in the API key and password for the remote database host in the input fields.</li>
</ul>
</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/task-target.png"></p>

<p><em>Wondering what the REMOTE_CLOUDANT_HOST is? Use hostname from the Cloudant dashboard, e.g. XXXX-bluemix.cloudant.com</em></p>

<ul>
<li>Set the following &#8220;Options&#8221; values in the &#8220;Job configuration&#8221; panel.

<ul>
<li>Replication type: <em>&#8220;Continuous&#8221;</em></li>
</ul>
</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/task-options.png"></p>

<ul>
<li>Click &#8220;Start Replication&#8221;</li>
<li>Verify the replication table shows the new replication task state as &#8221;<em>Running</em>&#8221;. üëç</li>
</ul>


<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/replication-jobs-table.png"></p>

<h2>test it out!</h2>

<p>Use the <a href="https://www.todobackend.com/client/index.html">TODO front-end application</a> with the APIGW URLs for each region simultaneously. Interactions with the todo list in one region should automatically propagate to the other region.</p>

<p><img src="http://jamesthom.as/images/ha-serverless-apps-todo/todo-app.gif"></p>

<p>The &#8220;Active Tasks&#8221; panel on the Cloudant Dashboard shows the documents replicated between instances and pending changes. If there are errors synchronising changes to the replication target, the host uses exponential backoff to re-try the replication tasks.</p>

<p><a href="https://console.bluemix.net/docs/services/Cloudant/guides/conflicts.html#finding-conflicts">Conflicts</a> between document changes are handled using CouchDB&#8217;s <a href="http://guide.couchdb.org/draft/conflicts.html">conflict mechanism</a>. Applications are responsible for detecting and resolving document conflicts in the front-end.</p>

<h2>conclusion</h2>

<p>Running the same serverless application in multiple regions, using the GLB to proxy traffic, allows applications to manage regional outages. But what if all the application instances rely on the same database service? The &#8220;single point of failure&#8221; has shifted from the application runtime to the database host. üëé</p>

<p>Provisioning independent databases in each application regions is one solution. Applications use their regional database instance and are protected from issues in other regions. This strategy relies on database changes being synchronised between instances to keep the application state consistent. üëç</p>

<p>IBM Cloudant has a built-in replication service to synchronised changes between source and host databases. Setting up bi-directional replication tasks between all instances enables a  &#8220;multi-master&#8221; replication strategy. This allows applications to access any database instance and have the same state available globally. üï∫üï∫üï∫</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Custom Domains With IBM Cloud Functions]]></title>
    <link href="http://jamesthom.as/blog/2018/12/03/custom-domains-with-ibm-cloud-functions/"/>
    <updated>2018-12-03T15:11:00+00:00</updated>
    <id>http://jamesthom.as/blog/2018/12/03/custom-domains-with-ibm-cloud-functions</id>
    <content type="html"><![CDATA[<p>In this tutorial, I&#8217;m going to show you how to use a <a href="https://console.bluemix.net/docs//api-management/manage_apis.html#custom_domains">custom domain for serverless functions</a> exposed as APIs on <a href="https://cloud.ibm.com/">IBM Cloud</a>. APIs endpoints use a random sub-domain on IBM Cloud by default. Importing your own domains means endpoints can be accessible through custom URLs.</p>

<p><em>Registering a custom domain with IBM Cloud needs you to complete the following steps&#8230;</em></p>

<ul>
<li>Generate SSL/TLS certificates for your domain</li>
<li>Register domain certificates with <a href="https://console.bluemix.net/catalog/services/certificate-manager">IBM Certificate Manager</a></li>
<li>Bind a custom domain to <a href="https://cloud.ibm.com/openwhisk/apimanagement">Cloud Functions APIs</a> using the <a href="https://cloud.ibm.com/apis/">IBM Cloud APIs</a> console.</li>
</ul>


<p><strong>This tutorial assumes you already have actions on <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a> exposed as HTTP APIs using the built-in <a href="https://console.bluemix.net/openwhisk/apimanagement">API service</a>.</strong> If you haven&#8217;t done that yet, please see the documentation <a href="https://console.bluemix.net/docs/openwhisk/">here</a> before you proceed.</p>

<p>The instructions below set up a sub-domain (<code>api.&lt;YOUR_DOMAIN&gt;</code>) to access serverless functions.</p>

<h2>Generating SSL/TLS Certificates with Let&#8217;s Encrypt</h2>

<p>IBM Cloud APIs only supports HTTPS traffic with custom domains. Users needs to upload valid SSL/TLS certificates for those domains to IBM Cloud before being able to use them.</p>

<p><a href="https://letsencrypt.org/">Let&#8217;s Encrypt</a> is a Certificate Authority which provides free SSL/TLS certificates for domains. Let&#8217;s Encrypt is trusted by all root identify providers. This means certificates generated by this provider will be trusted by all major operating systems, web browsers, and devices.</p>

<p>Using this service, valid certificates can be generated to support custom domains on IBM Cloud.</p>

<h3>domain validation</h3>

<p>Let&#8217;s Encrypt needs to verify you <a href="https://letsencrypt.org/how-it-works/">control the domain</a> before generating certificates.</p>

<p>During the verification process, the user makes an authentication token available through the domain. The service supports <a href="https://certbot.eff.org/docs/challenges.html">numerous methods</a> for exposing the authentication token, including HTTP endpoints, DNS TXT records or TLS SNI.</p>

<p>There is an application (<a href="https://certbot.eff.org/">certbot</a>) which automates generating authentication tokens and certificates.</p>

<p>I&#8217;m going to use the <a href="https://en.wikipedia.org/wiki/TXT_record">DNS TXT record</a> as the challenge mechanism. Using this approach, certbot will provide a random authentication token I need to create as the TXT record value under the <code>_acme-challenge.&lt;YOUR_DOMAIN&gt;</code> sub-domain before validation.</p>

<h3>using certbot with dns txt validation</h3>

<ul>
<li>Install <a href="https://certbot.eff.org/">certbot</a> into your <a href="https://certbot.eff.org/docs/install.html">environment</a>, e.g. using <a href="https://brew.sh/">Homebrew</a>.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>brew install certbot</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Run certbot in <a href="https://certbot.eff.org/docs/using.html#manual">manual mode</a> with the DNS <a href="https://certbot.eff.org/docs/challenges.html">challenge</a> method.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>certbot certonly --manual --preferred-challenges=dns -d *.&lt;YOUR_DOMAIN&gt;</span></code></pre></td></tr></table></div></figure>


<p>I&#8217;m generating a wildcard certificate for any sub-domains under <code>&lt;YOUR_DOMAIN&gt;</code>. This allows me to use the same certificate with different sub-domains on IBM Cloud, rather than generating a certificate per sub-domain.</p>

<p>During the validation process, <code>certbot</code> should display the following message with the challenge token.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Please deploy a DNS TXT record under the name
</span><span class='line'>_acme-challenge.&lt;YOUR_DOMAIN&gt; with the following value:
</span><span class='line'>
</span><span class='line'>&lt;CHALLENGE_TOKEN&gt;
</span><span class='line'>
</span><span class='line'>Before continuing, verify the record is deployed.
</span><span class='line'>- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
</span><span class='line'>Press Enter to Continue</span></code></pre></td></tr></table></div></figure>


<h3>setting challenge token</h3>

<ul>
<li><p>Take the challenge token from <code>certbot</code> and create a new TXT record with this value for the <code>_acme-challenge.&lt;YOUR_DOMAIN&gt;</code> sub-domain.</p></li>
<li><p>Use the <code>dig</code> command to verify the TXT record is available.</p></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dig -t txt _acme-challenge.&lt;YOUR_DOMAIN&gt;</span></code></pre></td></tr></table></div></figure>


<p>The challenge token should be available in the DNS response shown by <code>dig</code>. üëç</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>;; ANSWER SECTION:
</span><span class='line'>_acme-challenge.&lt;YOUR_DOMAIN&gt;. 3599 IN  TXT "&lt;CHALLENGE_TOKEN&gt;"</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Press <kbd>Enter</kbd> in the terminal session running <code>certbot</code> when the challenge token is available.</li>
</ul>


<h3>retrieving domain certificates</h3>

<p><code>certbot</code> will now retrieve the TXT record for the sub-domain and verify it matches the challenge token. If the domain has been validated, <code>certbot</code> will show the directory containing the newly created certificates.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>IMPORTANT NOTES:
</span><span class='line'> - Congratulations! Your certificate and chain have been saved at:
</span><span class='line'>   /etc/letsencrypt/live/&lt;YOUR_DOMAIN&gt;/fullchain.pem
</span><span class='line'>   Your key file has been saved at:
</span><span class='line'>   /etc/letsencrypt/live/&lt;YOUR_DOMAIN&gt;/privkey.pem
</span><span class='line'>   Your cert will expire on 2019-03-03.
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p><code>certbot</code>  creates the following files.</p>

<ul>
<li><code>cert.pem</code> - public domain certificate</li>
<li><code>privkey.pem</code> - private key for domain certificate</li>
<li><code>chain.pem</code> - intermediate domain certificates</li>
<li><code>fullchain.pem</code> - public and intermediate domain certificates in a single file.</li>
</ul>


<p><em>Registering the domain with IBM Cloud will require the public, private and intermediate certificate files.</em></p>

<h2>Registering Custom Domain with IBM Cloud</h2>

<p>Certificates for custom domains in IBM Cloud are managed by the <a href="https://console.bluemix.net/catalog/services/certificate-manager">Certificate Manager</a> service.</p>

<ul>
<li>Create a <a href="https://cloud.ibm.com/catalog/services/certificate-manager">new instance</a> of the service from the <a href="https://cloud.ibm.com/catalog/">IBM Cloud Catalog</a>.</li>
<li>From the service homepage, click the &#8221;<em>Import Certificate</em>&#8221; button.</li>
<li>Fill in the following fields in the import form. Use the generated certificate files in the upload fields.

<ul>
<li>Name</li>
<li>Certificate File (<code>cert.pem</code>)</li>
<li>Private key file (<code>privkey.pem</code>)</li>
<li>Intermediate certificate file (<code>chain.pem</code>)</li>
</ul>
</li>
</ul>


<p>After importing the certificate, check the certificate properties match the expected values</p>

<p><img src="http://jamesthom.as/images/custom-domains/import-certs.gif"></p>

<h2>Binding Domain to IBM Cloud Functions APIs</h2>

<p><a href="https://console.bluemix.net/docs/api-management/manage_apis.html#custom_domains_bind">Custom domains</a> for APIs on IBM Cloud are managed through the IBM Cloud APIs <a href="https://console.bluemix.net/apis/">console</a>.</p>

<ul>
<li>Open the &#8221;<a href="https://console.bluemix.net/apis/domains">Custom Domains</a>&#8221; section on the <a href="https://console.bluemix.net/apis/">IBM Cloud APIs</a> console.</li>
<li>Check the &#8220;Region&#8221; selector matches the region chosen for your actions and APIs.</li>
<li>Click the <code>¬∑¬∑¬∑</code> icon on the row where &#8220;Organisation&#8221; and &#8220;Space&#8221; values match your APIs.</li>
<li>Click &#8221;<em>Change Settings</em>&#8221; from the pop-up menu.</li>
</ul>


<p><img src="http://jamesthom.as/images/custom-domains/open-apis-settings.gif"></p>

<h3>domain validation</h3>

<p>IBM Cloud now <a href="https://console.bluemix.net/docs//api-management/manage_apis.html#custom_domains">needs to verify</a> you control the custom domain being used.</p>

<p><em>Another DNS TXT record needs to be created <strong>before</strong> attempting to bind the domain.</em></p>

<ul>
<li>From the &#8221;<em>Custom Domain Settings</em>&#8221; menu, make a note of the &#8221;<em>Default domain / alias</em>&#8221; value. This should be in the format: <code>&lt;APP_ID&gt;.&lt;REGION&gt;.apiconnect.appdomain.cloud</code>.</li>
<li>Create a new TXT record for the custom sub-domain (<code>api.&lt;YOUR_DOMAIN&gt;</code>) with the default domain alias as the record value (<code>&lt;APP_ID&gt;.&lt;REGION&gt;.apiconnect.appdomain.cloud</code>).</li>
<li>Use the <code>dig</code> command to check the sub-domain TXT record exists and contains the correct value.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dig -t txt api.&lt;YOUR_DOMAIN&gt;</span></code></pre></td></tr></table></div></figure>


<p>The default domain alias value should be available in the DNS response shown by <code>dig</code>. üëç</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>;; ANSWER SECTION:
</span><span class='line'>api.&lt;YOUR_DOMAIN&gt;. 3599 IN  TXT "&lt;APP_ID&gt;.&lt;REGION&gt;.apiconnect.appdomain.cloud"</span></code></pre></td></tr></table></div></figure>


<p>Having created the TXT record, fill in the <em>Custom Domain Settings</em> form.</p>

<h3>custom domain settings</h3>

<ul>
<li>Select the &#8221;<em>Assign custom domain</em>&#8221; checkbox in the &#8221;<em>Custom domain settings</em>&#8221; form.</li>
<li>Fill in the following form fields.

<ul>
<li><em>Domain Name:</em> use the custom sub-domain to bind  (<code>api.&lt;YOUR-DOMAIN&gt;</code>).</li>
<li><em>Certificate Manager service</em>: select the certificate manger instance.</li>
<li><em>Certificate:</em> select the domain certificate from the drop-down menu.</li>
</ul>
</li>
<li>Click the &#8221;<em>Save</em>&#8221; button.</li>
</ul>


<p>Once the domain has been validated, the form will redirect to the custom domains overview. The &#8220;Custom Domain&#8221; field will now show the sub-domain bound to the correct default domain alias.</p>

<p><img src="http://jamesthom.as/images/custom-domains/bind-custom-domain.gif"></p>

<h3>add CNAME record</h3>

<ul>
<li>Remove the existing TXT record for the custom sub-domain  (<code>api.&lt;YOUR-DOMAIN&gt;</code>).</li>
<li>Add a new CNAME record mapping the custom sub-domain (<code>api.&lt;YOUR-DOMAIN&gt;</code>) to the &#8221;<em>Default domain  / alias</em>&#8221; on IBM Cloud (<code>&lt;APP_ID&gt;.&lt;REGION&gt;.apiconnect.appdomain.cloud</code>).</li>
<li>Use the <code>dig</code> command to check the CNAME record is correct.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>dig -t CNAME api.&lt;YOUR_DOMAIN&gt;</span></code></pre></td></tr></table></div></figure>


<p>The default domain alias value should be available in the DNS response shown by <code>dig</code>. üëç</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>;; ANSWER SECTION:
</span><span class='line'>api.&lt;YOUR_DOMAIN&gt;.  3599    IN  CNAME   &lt;APP_ID&gt;.&lt;REGION&gt;.apiconnect.appdomain.cloud.</span></code></pre></td></tr></table></div></figure>


<h2>Testing It Out</h2>

<p>Functions should now be accessible through both the default domain alias and the new custom domain. üëè</p>

<ul>
<li>Invoke the default domain alias API URL for the function.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl https://&lt;APP_ID&gt;.&lt;REGION&gt;.apiconnect.appdomain.cloud/&lt;BASE_PATH&gt;/&lt;SUB_PATH&gt; </span></code></pre></td></tr></table></div></figure>


<p><em>Both the <code>BASE_PATH</code> and <code>SUB_PATH</code> values come from the API definitions configured by the user.</em></p>

<ul>
<li>Invoke the custom domain API URL for the function.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl https://api.&lt;YOUR_DOMAIN&gt;/&lt;BASE_PATH&gt;/&lt;SUB_PATH&gt; </span></code></pre></td></tr></table></div></figure>


<p><em>Make sure you use HTTPS protocol in the URL. IBM Cloud does not support HTTP traffic with custom domains.</em></p>

<p>Both responses for these URLs should the same! Hurrah. üòé</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Finding photos on Twitter using face recognition with TensorFlow.js]]></title>
    <link href="http://jamesthom.as/blog/2018/10/30/finding-photos-on-twitter-using-face-recognition/"/>
    <updated>2018-10-30T09:34:00+00:00</updated>
    <id>http://jamesthom.as/blog/2018/10/30/finding-photos-on-twitter-using-face-recognition</id>
    <content type="html"><![CDATA[<p>As a developer advocate, I spend a lot of time at developer conferences (talking about serverless üòé). Upon returning from each trip, I need to compile a &#8220;trip report&#8221; on the event for my bosses. This helps demonstrate the value in attending events and that I&#8217;m not just accruing air miles and hotel points for fun&#8230; üõ´üè®</p>

<p>I always include any social media content people post about my talks in the trip report. This is usually tweets with photos of me on stage. If people are tweeting about your session, I assume they enjoyed it and wanted to share with their followers.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">&quot;Servers kill your productivity&quot; <a href="https://twitter.com/thomasj?ref_src=twsrc%5Etfw">@thomasj</a> at <a href="https://twitter.com/hashtag/CodeMobileUK?src=hash&amp;ref_src=twsrc%5Etfw">#CodeMobileUK</a> <a href="https://t.co/Y4NsiBBSxT">pic.twitter.com/Y4NsiBBSxT</a></p>&mdash; Mihai C√ÆrlƒÉnaru (@MCirlanaru) <a href="https://twitter.com/MCirlanaru/status/981170555834441729?ref_src=twsrc%5Etfw">April 3, 2018</a></blockquote>


<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<p><strong>Finding tweets with photos about your talk from attendees is surprisingly challenging.</strong></p>

<p>Attendees often forget to include your twitter username in their tweets. This means the only way to find those photos is to manually scroll through all the results from the conference hashtag. This is problematic at conferences with thousands of attendees all tweeting during the event. <em>#devrelproblems</em>.</p>

<p>Having become bored of manually trawling through all the tweets for each conference, I had a thought&#8230;</p>

<blockquote><p><em>&#8220;Can&#8217;t I write some code to do this for me?&#8221;</em></p></blockquote>

<p>This didn&#8217;t seem like too ridiculous an idea. Twitter has <a href="https://developer.twitter.com/en/docs/tweets/search/overview">an API</a>, which would allow me to retrieve all tweets for a conference hashtag. Once I had all the tweet photos, couldn&#8217;t I run some magic AI algorithm over the images to tell me if I was in them? ü§î</p>

<p>After a couple of weeks of hacking around (and overcoming numerous challenges) I had (to my own amazement) managed to <a href="https://github.com/jthomas/findme">build a serverless application</a> which can find unlabelled photos of a person on twitter using machine learning with <a href="https://github.com/tensorflow/tfjs">TensorFlow.js</a>.</p>

<p><img src="http://jamesthom.as/images/face-recog/find-me-demo.gif" alt="FindMe Example" /></p>

<p><em>If you just want to try this application yourself, follow the instructions in the Github repo: <a href="https://github.com/jthomas/findme">https://github.com/jthomas/findme</a></em></p>

<h2>architecture</h2>

<p><img src="http://jamesthom.as/images/face-recog/architecture.png" alt="FindMe Architecture Diagram" /></p>

<p>This application has four <a href="https://github.com/jthomas/findme/blob/master/serverless.yml">serverless functions</a> (two API handlers and two backend services) and a client-side application from a static web page. Users log into the <a href="https://github.com/jthomas/findme/tree/master/public">client-side application</a> using Auth0 with their Twitter account. This provides the backend application with the user&#8217;s profile image and Twitter API credentials.</p>

<p>When the user invokes a search query, the client-side application invokes the API endpoint for the <code>register_search</code> <a href="https://github.com/jthomas/findme/blob/master/schedule_search.js">function</a> with the query terms and twitter credentials. This function registers a new search job in Redis and fires a new <code>search_request</code> trigger event with the query and job id. This job identifier is returned to the client to poll for real-time status updates.</p>

<p>The <code>twitter_search</code> <a href="https://github.com/jthomas/findme/blob/master/twitter_search.js">function</a> is connected to the <code>search_request</code> trigger and invoked for each event. It uses the Twitter Search API to retrieve all tweets for the search terms. If tweets retrieved from the API contain photos, those tweet ids (with photo urls) are fired as new <code>tweet_image</code> trigger events.</p>

<p>The <code>compare_images</code> <a href="https://github.com/jthomas/findme/blob/master/compare_images.js">function</a> is connected to the <code>tweet_image</code> trigger. When invoked, it downloads the user&#8217;s twitter profile image along with the tweet image and runs face detection against both images, using the <code>face-api.js</code> <a href="https://github.com/justadudewhohacks/face-api.js">library</a>. If any faces in the tweet photo match the face in the user&#8217;s profile image, tweet ids are written to Redis before exiting.</p>

<p>The client-side web page polls for real-time search results by polling the API endpoint for the <code>search_status</code>  <a href="https://github.com/jthomas/findme/blob/master/search_status.js">function</a> with the search job id. Tweets with matching faces are displayed on the web page using the <a href="https://developer.twitter.com/en/docs/twitter-for-websites/embedded-tweets/overview">Twitter JS library</a>.</p>

<h2>challenges</h2>

<p>Since I had found an <a href="https://github.com/justadudewhohacks/face-api.js">NPM library to handle face detection</a>, I could just use this on a serverless platform by including the library within the zip file used to create my serverless application? Sounds easy, right?!</p>

<p><strong>ahem - not so faas-t&#8230;. ‚úã</strong></p>

<p>As discussed in <a href="http://jamesthom.as/blog/2018/08/13/serverless-machine-learning-with-tensorflow-dot-js/">previous blog posts</a>, there are numerous challenges in using TF.js-based libraries on serverless platforms. Starting with making the packages available in the runtime and loading model files to converting images for classification, these libraries are not like using normal NPM modules.</p>

<p><em>Here are the main challenges I had to overcome to make this serverless application work&#8230;</em></p>

<h3>using tf.js libraries on a serverless platform</h3>

<p>The <a href="https://github.com/tensorflow/tfjs-node">Node.js backend drivers</a> for TensorFlow.js use a native shared C++ library  (<code>libtensorflow.so</code>) to execute models on the CPU or GPU. This native dependency is compiled for the platform during the <code>npm install</code> process. The shared library file is around 142MB, which is too large to include in the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/reference.md#actions">deployment package</a> for most serverless platforms.</p>

<p>Normal workarounds for this issue store large dependencies in an object store. These files are dynamically retrieved during cold starts and stored in the runtime filesystem, as shown in this pseudo-code. This workaround does add an additional delay to cold start invocations.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kd">let</span> <span class="nx">cold_start</span> <span class="o">=</span> <span class="kc">false</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">library</span> <span class="o">=</span> <span class="s1">&#39;libtensorflow.so&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="p">(</span><span class="nx">cold_start</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">data</span> <span class="o">=</span> <span class="nx">from_object_store</span><span class="p">(</span><span class="nx">library</span><span class="p">)</span>
</span><span class='line'>  <span class="nx">write_to_fs</span><span class="p">(</span><span class="nx">library</span><span class="p">,</span> <span class="nx">data</span><span class="p">)</span>
</span><span class='line'>  <span class="nx">cold_start</span> <span class="o">=</span> <span class="kc">true</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// rest of function code‚Ä¶</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Fortunately, I had a better solution using Apache OpenWhisk&#8217;s support for custom Docker runtimes!</strong></p>

<p>This feature allows serverless applications to use <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md#creating-native-actions">custom Docker images</a> as the runtime environment. Creating custom images with <a href="http://jamesthom.as/blog/2017/08/04/large-applications-on-openwhisk/">large libraries pre-installed</a> means they can be excluded from deployment packages. üíØ</p>

<p>Apache OpenWhisk publishes all existing <a href="https://hub.docker.com/r/openwhisk/">runtime images</a> on Docker Hub. Using existing runtime images as base images means Dockerfiles for custom runtimes are minimal. Here&#8217;s the Dockerfile needed to build a custom runtime with the TensorFlow.js Node.js backend drivers pre-installed.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">FROM</span> <span class="nx">openwhisk</span><span class="o">/</span><span class="nx">action</span><span class="o">-</span><span class="nx">nodejs</span><span class="o">-</span><span class="nx">v8</span><span class="o">:</span><span class="nx">latest</span>
</span><span class='line'>
</span><span class='line'><span class="nx">RUN</span> <span class="nx">npm</span> <span class="nx">install</span> <span class="err">@</span><span class="nx">tensorflow</span><span class="o">/</span><span class="nx">tfjs</span><span class="o">-</span><span class="nx">node</span>
</span></code></pre></td></tr></table></div></figure>


<p>Once this image has been built and published on Dockerhub, you can use it when creating new functions.</p>

<p><em>I used this approach to build a <a href="https://hub.docker.com/r/jamesthomas/action-nodejs-v8/tags/">custom TensorFlow.js runtime</a> which is available on Docker Hub: <code>jamesthomas/action-nodejs-v8:tfjs-faceapi</code></em></p>

<p>OpenWhisk actions created using the <code>wsk</code> command-line use a configuration flag (<code>--docker</code>) to specify custom runtime images.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wsk</span> <span class="nx">action</span> <span class="nx">create</span> <span class="nx">classify</span> <span class="nx">source</span><span class="p">.</span><span class="nx">js</span> <span class="o">--</span><span class="nx">docker</span> <span class="nx">jamesthomas</span><span class="o">/</span><span class="nx">action</span><span class="o">-</span><span class="nx">nodejs</span><span class="o">-</span><span class="nx">v8</span><span class="o">:</span><span class="nx">tfjs</span><span class="o">-</span><span class="nx">faceapi</span>
</span></code></pre></td></tr></table></div></figure>


<p>The OpenWhisk provider plugin for The Serverless Framework also supports <a href="https://github.com/serverless/serverless-openwhisk#custom-runtime-images">custom runtime images</a> through a configuration parameter (<code>image</code>) under the function configuration.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">service</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">machine-learning</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">provider</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">name</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">openwhisk</span>
</span><span class='line'>
</span><span class='line'><span class="l-Scalar-Plain">functions</span><span class="p-Indicator">:</span>
</span><span class='line'>  <span class="l-Scalar-Plain">classify</span><span class="p-Indicator">:</span>
</span><span class='line'>    <span class="l-Scalar-Plain">handler</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">source.main</span>
</span><span class='line'>    <span class="l-Scalar-Plain">image</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">jamesthomas/action-nodejs-v8:tfjs-faceapi</span>
</span></code></pre></td></tr></table></div></figure>


<p>Having fixed the issue of library loading on serverless platforms, I could move onto the next problem, loading the pre-trained models&#8230; üíΩ</p>

<h3>loading pre-trained models</h3>

<p>Running the <a href="https://github.com/justadudewhohacks/face-api.js#usage-loading-models">example code</a> to load the pre-trained models for face recognition gave me this error:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='yaml'><span class='line'><span class="l-Scalar-Plain">ReferenceError</span><span class="p-Indicator">:</span> <span class="l-Scalar-Plain">fetch is not defined</span>
</span></code></pre></td></tr></table></div></figure>


<p>In the <a href="http://jamesthom.as/blog/2018/08/07/machine-learning-in-node-dot-js-with-tensorflow-dot-js/">previous blog post</a>, I discovered how to manually load TensorFlow.js models from the filesystem using the <code>file://</code> URI prefix. Unfortunately, the <code>face-api.js</code> library doesn&#8217;t support this feature. Models are <a href="https://github.com/justadudewhohacks/tfjs-image-recognition-base/blob/4a7d981dbb37e0d3dabc962e1cbfb6122e535263/src/dom/loadWeightMap.ts#L12">automatically loaded</a> using the <code>fetch</code> HTTP client. This HTTP client is available into modern browsers but not in the Node.js runtime.</p>

<p>Overcoming this issue relies on providing an instance of a compatible HTTP client in the runtime. The <code>node-fetch</code> library is a <a href="https://www.npmjs.com/package/node-fetch">implementation of the fetch client</a> API for the Node.js runtime. By manually installing this module and exporting as a global variable, the library can then use the HTTP client as expected.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// Make HTTP client available in runtime</span>
</span><span class='line'><span class="nx">global</span><span class="p">.</span><span class="nx">fetch</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;node-fetch&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Model configuration and weight files can then be loaded from the library&#8217;s Github repository using this URL:</p>

<p>https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights/</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='js'><span class='line'><span class="nx">faceapi</span><span class="p">.</span><span class="nx">loadFaceDetectionModel</span><span class="p">(</span><span class="s1">&#39;&lt;GITHUB_URL&gt;&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>face detection in images</h3>

<p>The <code>face-api.js</code> library has a <a href="https://github.com/justadudewhohacks/face-api.js#detecting-faces">utility function</a> (<code>models.allFaces</code>) to automatically detect and calculate descriptors for all faces found in an image. Descriptors are a feature vector (of 128 32-bit float values) which uniquely describes the characteristics of a persons face.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">results</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">models</span><span class="p">.</span><span class="nx">allFaces</span><span class="p">(</span><span class="nx">input</span><span class="p">,</span> <span class="nx">minConfidence</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p><em>The input to this function is the input tensor with the RGB values from an image. In a <a href="http://jamesthom.as/blog/2018/08/07/machine-learning-in-node-dot-js-with-tensorflow-dot-js/">previous blog post</a>, I explained how to convert an image from the filesystem in Node.js to the input tensor needed by the model.</em></p>

<p>Finding a user by comparing their twitter profile against photos from tweets starts by running face detection against both images. By comparing computed descriptor values, a measure of similarity can be established between faces from the images.</p>

<h3>face comparison</h3>

<p>Once the face descriptors have been calculated the library provides a utility function to compute the euclidian distance between two descriptors vectors. If the difference between two face descriptors is less than a threshold value, this is used to identify the same person in both images.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">distance</span> <span class="o">=</span> <span class="nx">faceapi</span><span class="p">.</span><span class="nx">euclideanDistance</span><span class="p">(</span><span class="nx">descriptor1</span><span class="p">,</span> <span class="nx">descriptor2</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="p">(</span><span class="nx">distance</span> <span class="o">&lt;</span> <span class="mf">0.6</span><span class="p">)</span>
</span><span class='line'>  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s1">&#39;match&#39;</span><span class="p">)</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'>  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s1">&#39;no match&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>I&#8217;ve no idea why 0.6 is chosen as the threshold value but this seemed to work for me! Even small changes to this value dramatically reduced the precision and recall rates for my test data. I&#8217;m calling it the Goldilocks value, just use it&#8230;</p>

<h2>performance</h2>

<p>Once I had the end to end application working, I wanted to make it was fast as possible. By optimising the performance, I could improve the application responsiveness and reduce compute costs for my backend. Time is literally money with serverless platforms.</p>

<h3>baseline performance</h3>

<p>Before attempting to optimise my application, I needed to understand the baseline performance. Setting up experiments to record invocation durations gave me the following average test results.</p>

<ul>
<li><em>Warm invocations</em>: ~5 seconds</li>
<li><em>Cold invocations</em>: ~8 seconds</li>
</ul>


<p>Instrumenting the code with <code>console.time</code> statements revealed execution time was comprised of five main sections.</p>

<table>
<thead>
<tr>
<th></th>
<th> Cold Starts </th>
<th> Warm Starts </th>
</tr>
</thead>
<tbody>
<tr>
<td>Initialisation    </td>
<td>       1200 ms       </td>
<td>        0 ms</td>
</tr>
<tr>
<td>Model Loading     </td>
<td>       3200 ms       </td>
<td>       2000 ms       </td>
</tr>
<tr>
<td>Image Loading     </td>
<td>     500 ms x 2      </td>
<td>     500 ms x 2      </td>
</tr>
<tr>
<td>Face Detection    </td>
<td> 700 ms - 900 ms x 2 </td>
<td> 700 ms - 900 ms x 2</td>
</tr>
<tr>
<td>Everything Else   </td>
<td>       1000 ms       </td>
<td>       500 ms        </td>
</tr>
<tr>
<td><strong>Total Duration</strong></td>
<td>   <strong>~ 8 seconds</strong>   </td>
<td>   <strong>~ 5 seconds</strong>  </td>
</tr>
</tbody>
</table>


<p><em>Initialisation</em> was the delay during cold starts to create the runtime environment and load all the library files and application code. <em>Model Loading</em> recorded the time spent instantiating the TF.js models from the source files. <em>Image Loading</em> was the time spent converting the RGB values from images into input tensors, this happened twice, once for the twitter profile picture and again for the tweet photo. <em>Face Detection</em> is the elapsed time to execute the <code>models.allFaces</code> method and <code>faceapi.euclideanDistance</code> methods for all the detected faces. <em>Everything else</em> is well&#8230; everything else.</p>

<p>Since model loading was the largest section, this seemed like an obvious place to start optimising. üìàüìâ</p>

<h3>loading model files from disk</h3>

<p>Overcoming the initial model loading issue relied on manually exposing the expected HTTP client in the Node.js runtime. This allowed models to be dynamically loaded (over HTTP) from the external Github repository. Models files were about 36MB.</p>

<p>My first idea was to load these model files from the filesystem, which should be much faster than downloading from Github. Since I was already building a custom Docker runtime, it was a one-line change to include the model files within the runtime filesystem.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">FROM</span> <span class="nx">openwhisk</span><span class="o">/</span><span class="nx">action</span><span class="o">-</span><span class="nx">nodejs</span><span class="o">-</span><span class="nx">v8</span><span class="o">:</span><span class="nx">latest</span>
</span><span class='line'>
</span><span class='line'><span class="nx">RUN</span> <span class="nx">npm</span> <span class="nx">install</span> <span class="err">@</span><span class="nx">tensorflow</span><span class="o">/</span><span class="nx">tfjs</span><span class="o">-</span><span class="nx">node</span>
</span><span class='line'>
</span><span class='line'><span class="nx">COPY</span> <span class="nx">weights</span> <span class="nx">weights</span>
</span></code></pre></td></tr></table></div></figure>


<p>Having re-built the image and pushed to Docker Hub, the classification function&#8217;s runtime environment now included models files in the filesystem.</p>

<p><strong>But how do we make the <code>face-api.js</code> library load models files from the filesystem when it is using a HTTP client?</strong></p>

<p>My solution was to write a <code>fetch</code> client that proxied calls to retrieve files from a HTTP endpoint to the local filesystem. üò± I&#8217;d let you decide whether this is a brilliant or terrible idea!</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">global</span><span class="p">.</span><span class="nx">fetch</span> <span class="o">=</span> <span class="nx">async</span> <span class="p">(</span><span class="nx">file</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">json</span><span class="o">:</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="nx">JSON</span><span class="p">.</span><span class="nx">parse</span><span class="p">(</span><span class="nx">fs</span><span class="p">.</span><span class="nx">readFileSync</span><span class="p">(</span><span class="nx">file</span><span class="p">,</span> <span class="s1">&#39;utf8&#39;</span><span class="p">)),</span>
</span><span class='line'>    <span class="nx">arrayBuffer</span><span class="o">:</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="nx">fs</span><span class="p">.</span><span class="nx">readFileSync</span><span class="p">(</span><span class="nx">file</span><span class="p">)</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">model</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">models</span><span class="p">.</span><span class="nx">load</span><span class="p">(</span><span class="s1">&#39;/weights&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The <code>face-api.js</code> library only used two methods (<code>json()</code> &amp; <code>arrayBuffer()</code>) from the HTTP client. Stubbing out these methods to proxy <code>fs.readFileSync</code> meant files paths were loaded from the filesystem. Amazingly, this seemed to just work, hurrah!</p>

<p><strong>Implementing this feature and re-running performance tests revealed this optimisation saved about 500 ms from the Model Loading section.</strong></p>

<table>
<thead>
<tr>
<th></th>
<th> Cold Starts </th>
<th> Warm Starts </th>
</tr>
</thead>
<tbody>
<tr>
<td>Initialisation    </td>
<td>       1200 ms       </td>
<td>        0 ms</td>
</tr>
<tr>
<td>Model Loading     </td>
<td>       2700 ms       </td>
<td>       1500 ms       </td>
</tr>
<tr>
<td>Image Loading     </td>
<td>     500 ms x 2      </td>
<td>     500 ms x 2      </td>
</tr>
<tr>
<td>Face Detection    </td>
<td> 700 ms - 900 ms x 2 </td>
<td> 700 ms - 900 ms x 2</td>
</tr>
<tr>
<td>Everything Else   </td>
<td>       1000 ms       </td>
<td>       500 ms        </td>
</tr>
<tr>
<td><strong>Total Duration</strong></td>
<td>   <strong>~ 7.5 seconds</strong>   </td>
<td>   <strong>~ 4.5 seconds</strong>  </td>
</tr>
</tbody>
</table>


<p>This was less of an improvement than I&#8217;d expected. Parsing all the model files and instantiating the internal objects was more computationally intensive than I realised. This performance improvement did improve both cold and warm invocations, which was a bonus.</p>

<p><em>Despite this optimisation, model loading was still the largest section in the classification function&#8230;</em></p>

<h3>caching loaded models</h3>

<p>There&#8217;s a good strategy to use when optimising serverless functions&#8230;</p>

<p><img src="http://jamesthom.as/images/face-recog/cache-all-the-things.jpg" alt="CACHE ALL THE THINGS" /></p>

<p>Serverless runtimes re-use runtime containers for consecutive requests, known as warm environments. Using local state, like global variables or the runtime filesystem, to cache data between requests can be used to improve performance during those invocations.</p>

<p>Since model loading was such an expensive process, I wanted to cache initialised models. Using a global variable, I could control whether to trigger model loading or return the pre-loaded models. Warm environments would re-use pre-loaded models and remove model loading delay.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">faceapi</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;face-api.js&#39;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="kd">let</span> <span class="nx">LOADED</span> <span class="o">=</span> <span class="kc">false</span>
</span><span class='line'>
</span><span class='line'><span class="nx">exports</span><span class="p">.</span><span class="nx">load</span> <span class="o">=</span> <span class="nx">async</span> <span class="nx">location</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="nx">LOADED</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">await</span> <span class="nx">faceapi</span><span class="p">.</span><span class="nx">loadFaceDetectionModel</span><span class="p">(</span><span class="nx">location</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">await</span> <span class="nx">faceapi</span><span class="p">.</span><span class="nx">loadFaceRecognitionModel</span><span class="p">(</span><span class="nx">location</span><span class="p">)</span>
</span><span class='line'>    <span class="nx">await</span> <span class="nx">faceapi</span><span class="p">.</span><span class="nx">loadFaceLandmarkModel</span><span class="p">(</span><span class="nx">location</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">LOADED</span> <span class="o">=</span> <span class="kc">true</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="nx">faceapi</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>This performance improvement had a significant impact of the performance for warm invocations. Model loading became &#8220;free&#8221;.</strong> üëç</p>

<table>
<thead>
<tr>
<th></th>
<th> Cold Starts </th>
<th> Warm Starts </th>
</tr>
</thead>
<tbody>
<tr>
<td>Initialisation    </td>
<td>       1200 ms       </td>
<td>        0 ms</td>
</tr>
<tr>
<td>Model Loading     </td>
<td>       2700 ms       </td>
<td>       0 ms       </td>
</tr>
<tr>
<td>Image Loading     </td>
<td>     500 ms x 2      </td>
<td>     500 ms x 2      </td>
</tr>
<tr>
<td>Face Detection    </td>
<td> 700 ms - 900 ms x 2 </td>
<td> 700 ms - 900 ms x 2</td>
</tr>
<tr>
<td>Everything Else   </td>
<td>       1000 ms       </td>
<td>       500 ms        </td>
</tr>
<tr>
<td><strong>Total Duration</strong></td>
<td>   <strong>~ 7.5 seconds</strong>   </td>
<td>   <strong>~ 3 seconds</strong>  </td>
</tr>
</tbody>
</table>


<h3>caching face descriptors</h3>

<p>In the initial implementation, the face comparison function was executing face detection against both the user&#8217;s twitter profile image and tweet photo for comparison. Since the twitter profile image was the same in each search request, running face detection against this image would always return the same results.</p>

<p>Rather than having this work being redundantly computed in each function, caching the results of the computed face descriptor for the profile image meant it could re-used across invocations. This would reduce by 50% the work necessary in the Image &amp; Model Loading sections.</p>

<p>The <code>face-api.js</code> library returns the face descriptor as a typed array with 128 32-bit float values. Encoding this values as a hex string allows them to be stored and retrieved from Redis. This code was used to convert float values to hex strings, whilst maintaining the exact precision of those float values.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">encode</span> <span class="o">=</span> <span class="nx">typearr</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">encoded</span> <span class="o">=</span> <span class="nx">Buffer</span><span class="p">.</span><span class="nx">from</span><span class="p">(</span><span class="nx">typearr</span><span class="p">.</span><span class="nx">buffer</span><span class="p">).</span><span class="nx">toString</span><span class="p">(</span><span class="s1">&#39;hex&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="k">return</span> <span class="nx">encoded</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kr">const</span> <span class="nx">decode</span> <span class="o">=</span> <span class="nx">encoded</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">decoded</span> <span class="o">=</span> <span class="nx">Buffer</span><span class="p">.</span><span class="nx">from</span><span class="p">(</span><span class="nx">encoded</span><span class="p">,</span> <span class="s1">&#39;hex&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">uints</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Uint8Array</span><span class="p">(</span><span class="nx">decoded</span><span class="p">)</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">floats</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Float32Array</span><span class="p">(</span><span class="nx">uints</span><span class="p">.</span><span class="nx">buffer</span><span class="p">)</span>
</span><span class='line'>  <span class="k">return</span> <span class="nx">floats</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This optimisation improves the performance of most cold invocations and all warm invocations, removing over 1200 ms of computation time to compute the results.</p>

<table>
<thead>
<tr>
<th></th>
<th>                    </th>
<th align="center"> Cold Starts (Cached) </th>
<th align="center">    Warm Starts    </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td> Initialisation     </td>
<td align="center">       1200 ms        </td>
<td align="center">       0 ms        |</td>
</tr>
<tr>
<td></td>
<td> Model Loading      </td>
<td align="center">       2700 ms        </td>
<td align="center">      1500 ms      |</td>
</tr>
<tr>
<td></td>
<td> Image Loading      </td>
<td align="center">        500 ms        </td>
<td align="center">      500 ms       |</td>
</tr>
<tr>
<td></td>
<td> Face Detection     </td>
<td align="center">   700 ms - 900 ms    </td>
<td align="center">  700 ms - 900 ms  |</td>
</tr>
<tr>
<td></td>
<td> Everything Else    </td>
<td align="center">       1000 ms        </td>
<td align="center">      500 ms       |</td>
</tr>
<tr>
<td></td>
<td> <strong>Total Duration</strong> </td>
<td align="center">   <strong>~ 6 seconds</strong>    </td>
<td align="center"> <strong>~ 2.5 seconds</strong> |</td>
</tr>
</tbody>
</table>


<table>
<thead>
<tr>
<th></th>
<th> Cold Starts </th>
<th> Warm Starts </th>
</tr>
</thead>
<tbody>
<tr>
<td>Initialisation    </td>
<td>       1200 ms       </td>
<td>        0 ms</td>
</tr>
<tr>
<td>Model Loading     </td>
<td>       2700 ms       </td>
<td>       0 ms       </td>
</tr>
<tr>
<td>Image Loading     </td>
<td>     500 ms      </td>
<td>     500 ms       </td>
</tr>
<tr>
<td>Face Detection    </td>
<td> 700 ms - 900 ms  </td>
<td> 700 ms - 900 ms </td>
</tr>
<tr>
<td>Everything Else   </td>
<td>       1000 ms       </td>
<td>       500 ms        </td>
</tr>
<tr>
<td><strong>Total Duration</strong></td>
<td>   <strong>~ 7.5 seconds</strong>   </td>
<td>   <strong>~ 3 seconds</strong>  </td>
</tr>
</tbody>
</table>


<h3>final results + cost</h3>

<p>Application performance was massively improved with all these optimisations. As demonstrated in the video above, the application could process tweets in real-time, returning almost instant results. Average invocation durations were now.</p>

<ul>
<li><em>Warm invocations</em>: ~2.5 seconds</li>
<li><em>Cold invocations (Cached)</em>: ~6 seconds</li>
</ul>


<p>Serverless platforms charge for compute time by the millisecond, so these improvements led to cost savings of 25% for cold invocations (apart the first classification for a user) and 50% for warm invocations.</p>

<p>Classification functions used 512MB of RAM which meant IBM Cloud Functions would provide 320,000 &#8220;warm&#8221; classifications or 133,333 &#8220;cold&#8221; classifications within the free tier each month. Ignoring the free tier, 100,000 &#8220;warm&#8221; classifications would cost $5.10 and 100,000 &#8220;cold&#8221; classifications $2.13.</p>

<h2>conclusion</h2>

<p>Using TensorFlow.js with serverless cloud platforms makes it easy to build scalable machine learning applications in the cloud. Using the horizontal scaling capabilities of serverless platforms, thousands of model classifications can be ran in parallel. This can be more performant than having dedicated hardware with a GPU, especially with compute costs for serverless applications being so cheap.</p>

<p>TensorFlow.js is ideally suited to serverless application due to the JS interface, (relatively) small library size and availability of pre-trained models. Despite having no prior experience in Machine Learning, I was able to use the library to build a face recognition pipeline, processing 100s of images in parallel, for real-time results. This amazing library opens up machine learning to a whole new audience!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Serverless Machine Learning With TensorFlow.js]]></title>
    <link href="http://jamesthom.as/blog/2018/08/13/serverless-machine-learning-with-tensorflow-dot-js/"/>
    <updated>2018-08-13T12:16:00+01:00</updated>
    <id>http://jamesthom.as/blog/2018/08/13/serverless-machine-learning-with-tensorflow-dot-js</id>
    <content type="html"><![CDATA[<p>In a <a href="http://jamesthom.as/blog/2018/08/07/machine-learning-in-node-dot-js-with-tensorflow-dot-js/">previous blog post</a>, I showed how to use <a href="https://js.tensorflow.org/">TensorFlow.js</a> on Node.js to run <a href="https://gist.github.com/jthomas/145610bdeda2638d94fab9a397eb1f1d#file-script-js">visual recognition on images from the local filesystem</a>. TensorFlow.js is a JavaScript version of the open-source machine learning library from Google.</p>

<p>Once I had this working with a local Node.js script, my next idea was to convert it into a serverless function. Running this function on <a href="https://console.bluemix.net/openwhisk/">IBM Cloud Functions</a> (<a href="https://openwhisk.incubator.apache.org/">Apache OpenWhisk</a>) would turn the script into my own visual recognition microservice.</p>

<p><img src="http://jamesthom.as/images/tfjs-serverless/tf-js-example.gif" title="Serverless TensorFlow.js Function" ></p>

<p>Sounds easy, right? It&#8217;s just a JavaScript library? So, zip it up and away we go&#8230; <strong><em>ahem</em></strong> üëä</p>

<p><em>Converting the image classification script to run in a serverless environment had the following challenges&#8230;</em></p>

<ul>
<li><strong>TensorFlow.js libraries need to be available in the runtime.</strong></li>
<li><strong>Native bindings for the library must be compiled against the platform architecture.</strong></li>
<li><strong>Models files need to be loaded from the filesystem.</strong></li>
</ul>


<p>Some of these issues were more challenging than others to fix! Let&#8217;s start by looking at the details of each issue, before explaining how <a href="http://jamesthom.as/blog/2017/01/16/openwhisk-docker-actions/">Docker support</a> in Apache OpenWhisk can be used to resolve them all.</p>

<h2>Challenges</h2>

<h3>TensorFlow.js Libraries</h3>

<p>TensorFlow.js libraries are not included in the <a href="https://github.com/apache/incubator-openwhisk-runtime-nodejs">Node.js runtimes</a> provided by the Apache OpenWhisk.</p>

<p>External libraries <a href="http://jamesthom.as/blog/2016/11/28/npm-modules-in-openwhisk/">can be imported</a> into the runtime by deploying applications from a zip file. Custom <code>node_modules</code> folders included in the zip file will be extracted in the runtime. Zip files are limited to a <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/reference.md#actions">maximum size of 48MB</a>.</p>

<h4>Library Size</h4>

<p>Running <code>npm install</code> for the TensorFlow.js libraries used revealed the first problem&#8230; the resulting <code>node_modules</code> directory was 175MB. üò±</p>

<p>Looking at the contents of this folder, the <code>tfjs-node</code> module compiles a <a href="https://github.com/tensorflow/tfjs-node/tree/master/src">native shared library</a> (<code>libtensorflow.so</code>) that is 135M. This means no amount of JavaScript minification is going to get those external dependencies under the magic 48 MB limit. üëé</p>

<h4>Native Dependencies</h4>

<p>The <code>libtensorflow.so</code> native shared library must be compiled using the platform runtime. Running <code>npm install</code>  locally automatically compiles native dependencies against the host platform. Local environments may use different CPU architectures (Mac vs Linux) or link against shared libraries not available in the serverless runtime.</p>

<h3>MobileNet Model Files</h3>

<p>TensorFlow models files <a href="https://js.tensorflow.org/tutorials/model-save-load.html">need loading from the filesystem</a> in Node.js. Serverless runtimes do provide a temporary filesystem inside the runtime environment. Files from deployment zip files are automatically extracted into this environment before invocations. There is no external access to this filesystem outside the lifecycle of the serverless function.</p>

<p>Models files for the MobileNet model were 16MB. If these files are included in the deployment package, it leaves 32MB for the rest of the application source code. Although the model files are small enough to include in the zip file, what about the TensorFlow.js libraries? Is this the end of the blog post? Not so fast&#8230;.</p>

<p><strong>Apache OpenWhisk&#8217;s support for custom runtimes provides a simple solution to all these issues!</strong></p>

<h2>Custom Runtimes</h2>

<p>Apache OpenWhisk uses Docker containers as the runtime environments for serverless functions (actions). All platform runtime images are <a href="https://hub.docker.com/r/openwhisk/">published on Docker Hub</a>, allowing developers to start these environments locally.</p>

<p>Developers can also <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-docker.md">specify custom runtime images</a> when creating actions. These images must be publicly available on Docker Hub. Custom runtimes have to expose the <a href="https://github.com/apache/incubator-openwhisk/blob/master/docs/actions-new.md#action-interface">same HTTP API</a> used by the platform for invoking actions.</p>

<p>Using platform runtime images as <a href="https://docs.docker.com/glossary/?term=parent%20image">parent images</a> makes it simple to build custom runtimes. Users can run commands during the Docker build to install additional libraries and other dependencies. The parent image already contains source files with the HTTP API service handling platform requests.</p>

<h3>TensorFlow.js Runtime</h3>

<p>Here is the Docker build file for the Node.js action runtime with additional TensorFlow.js dependencies.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM openwhisk/action-nodejs-v8:latest
</span><span class='line'>
</span><span class='line'>RUN npm install @tensorflow/tfjs @tensorflow-models/mobilenet @tensorflow/tfjs-node jpeg-js
</span><span class='line'>
</span><span class='line'>COPY mobilenet mobilenet</span></code></pre></td></tr></table></div></figure>


<p><code>openwhisk/action-nodejs-v8:latest</code> is the Node.js action runtime image <a href="https://hub.docker.com/r/openwhisk/action-nodejs-v8/">published by OpenWhisk</a>.</p>

<p>TensorFlow libraries and other dependencies are installed using <code>npm install</code> in the build process. Native dependencies for the <code>@tensorflow/tfjs-node</code> library are automatically compiled for the correct platform by installing during the build process.</p>

<p>Since I&#8217;m building a new runtime, I&#8217;ve also added the <a href="https://github.com/tensorflow/tfjs-models/tree/master/mobilenet">MobileNet model files</a> to the image. Whilst not strictly necessary, removing them from the action zip file reduces deployment times.</p>

<p><strong><em>Want to skip the next step? Use this image <a href="https://hub.docker.com/r/jamesthomas/action-nodejs-v8/"><code>jamesthomas/action-nodejs-v8:tfjs</code></a> rather than building your own.</em></strong></p>

<h3>Building The Runtime</h3>

<p><em>In the <a href="http://jamesthom.as/blog/2018/08/07/machine-learning-in-node-dot-js-with-tensorflow-dot-js/">previous blog post</a>, I showed how to download model files from the public storage bucket.</em></p>

<ul>
<li>Download a version of the MobileNet model and place all files in the <code>mobilenet</code> directory.</li>
<li>Copy the Docker build file from above to a local file named <code>Dockerfile</code>.</li>
<li>Run the Docker <a href="https://docs.docker.com/engine/reference/commandline/build/">build command</a> to generate a local image.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>docker build -t tfjs .
</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/tag/">Tag the local image</a> with a remote username and repository.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>docker tag tfjs &lt;USERNAME&gt;/action-nodejs-v8:tfjs
</span></code></pre></td></tr></table></div></figure>


<p><em>Replace <code>&lt;USERNAME&gt;</code> with your Docker Hub username.</em></p>

<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/push/">Push the local image</a> to Docker Hub</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'> docker push &lt;USERNAME&gt;/action-nodejs-v8:tfjs
</span></code></pre></td></tr></table></div></figure>


<p>Once the image <a href="https://hub.docker.com/r/jamesthomas/action-nodejs-v8/">is available</a> on Docker Hub, actions can be created using that runtime image. üòé</p>

<h2>Example Code</h2>

<p>This source code implements image classification as an OpenWhisk action. Image files are provided as a Base64 encoded string using the <code>image</code> property on the event parameters. Classification results are returned as the <code>results</code> property in the response.</p>

<script src="https://gist.github.com/jthomas/e7c78bbfe4091ed6ace93d1b53cbf6e5.js"></script>


<h3>Caching Loaded Models</h3>

<p>Serverless platforms initialise runtime environments on-demand to handle invocations. Once a runtime environment has been created, it will be <a href="https://medium.com/openwhisk/squeezing-the-milliseconds-how-to-make-serverless-platforms-blazing-fast-aea0e9951bd0">re-used for further invocations</a> with some limits. This improves performance by removing the initialisation delay (&#8220;cold start&#8221;) from request processing.</p>

<p>Applications can exploit this behaviour by using global variables to maintain state across requests. This is often use to <a href="https://blog.rowanudell.com/database-connections-in-lambda/">cache opened database connections</a> or store initialisation data loaded from external systems.</p>

<p>I have used this pattern to <a href="https://gist.github.com/jthomas/e7c78bbfe4091ed6ace93d1b53cbf6e5#file-index-js-L80-L82">cache the MobileNet model</a> used for classification. During cold invocations, the model is loaded from the filesystem and stored in a global variable. Warm invocations then use the existence of that global variable to skip the model loading process with further requests.</p>

<p>Caching the model reduces the time (and therefore cost) for classifications on warm invocations.</p>

<h3>Memory Leak</h3>

<p>Running the Node.js script from blog post on IBM Cloud Functions was possible with minimal modifications. Unfortunately, performance testing revealed a memory leak in the handler function. üò¢</p>

<p><em>Reading more about <a href="https://js.tensorflow.org/tutorials/core-concepts.html">how TensorFlow.js works</a> on Node.js uncovered the issue&#8230;</em></p>

<p>TensorFlow.js&#8217;s Node.js extensions use a native C++ library to execute the Tensors on a CPU or GPU engine. Memory allocated for Tensor objects in the native library is retained until the application explicitly releases it or the process exits. TensorFlow.js provides a <code>dispose</code> method on the individual objects to free allocated memory. There is also a <code>tf.tidy</code> method to automatically clean up all allocated objects within a frame.</p>

<p>Reviewing the code, tensors were being created as <a href="https://gist.github.com/jthomas/e7c78bbfe4091ed6ace93d1b53cbf6e5#file-index-js-L51-L59">model input from images</a> on each request. These objects were not disposed before returning from the request handler. This meant native memory grew unbounded. Adding an explicit <code>dispose</code> call to free these objects before returning <a href="https://gist.github.com/jthomas/e7c78bbfe4091ed6ace93d1b53cbf6e5#file-index-js-L91">fixed the issue</a>.</p>

<h3>Profiling &amp; Performance</h3>

<p>Action code records memory usage and elapsed time at different stages in classification process.</p>

<p>Recording <a href="https://gist.github.com/jthomas/e7c78bbfe4091ed6ace93d1b53cbf6e5#file-index-js-L12-L20">memory usage</a> allows me to modify the maximum memory allocated to the function for optimal performance and cost. Node.js provides a <a href="https://nodejs.org/docs/v0.4.11/api/all.html#process.memoryUsage">standard library API</a> to retrieve memory usage for the current process. Logging these values allows me to inspect memory usage at different stages.</p>

<p>Timing <a href="https://gist.github.com/jthomas/e7c78bbfe4091ed6ace93d1b53cbf6e5#file-index-js-L71">different tasks</a> in the classification process, i.e. model loading, image classification, gives me an insight into how efficient classification is compared to other methods. Node.js has a <a href="https://nodejs.org/api/console.html#console_console_time_label">standard library API</a> for timers to record and print elapsed time to the console.</p>

<h2>Demo</h2>

<h3>Deploy Action</h3>

<ul>
<li>Run the following command with the <a href="https://console.bluemix.net/openwhisk/learn/cli">IBM Cloud CLI</a> to create the action.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ibmcloud fn action create classify --docker &lt;IMAGE_NAME&gt; index.js
</span></code></pre></td></tr></table></div></figure>


<p><em>Replace <code>&lt;IMAGE_NAME&gt;</code> with the public Docker Hub image identifier for the custom runtime. Use <code>jamesthomas/action-nodejs-v8:tfjs</code> if you haven&#8217;t built this manually.</em></p>

<h3>Testing It Out</h3>

<ul>
<li>Download <a href="https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG">this image</a> of a Panda from Wikipedia.</li>
</ul>


<p><img src="https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG"></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>wget http://bit.ly/2JYSal9 -O panda.jpg
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Invoke the action with the Base64 encoded image as an input parameter.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'> ibmcloud fn action invoke classify -r -p image <span class="k">$(</span>base64 panda.jpg<span class="k">)</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Returned JSON message contains classification probabilities. üêºüêºüêº</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nt">&quot;results&quot;</span><span class="p">:</span>  <span class="p">[{</span>
</span><span class='line'>    <span class="err">className:</span> <span class="err">&#39;giant</span> <span class="err">panda,</span> <span class="err">panda,</span> <span class="err">panda</span> <span class="err">bear,</span> <span class="err">coon</span> <span class="err">bear&#39;,</span>
</span><span class='line'>    <span class="err">probability:</span> <span class="err">0.9993536472320557</span>
</span><span class='line'>  <span class="p">}]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Activation Details</h3>

<ul>
<li>Retrieve logging output for the last activation to show performance data.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ibmcloud fn activation logs --last
</span></code></pre></td></tr></table></div></figure>


<p><strong><em>Profiling and memory usage details are logged to stdout</em></strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>prediction <span class="k">function </span>called.
</span><span class='line'>memory used: <span class="nv">rss</span><span class="o">=</span>150.46 MB, <span class="nv">heapTotal</span><span class="o">=</span>32.83 MB, <span class="nv">heapUsed</span><span class="o">=</span>20.29 MB, <span class="nv">external</span><span class="o">=</span>67.6 MB
</span><span class='line'>loading image and model...
</span><span class='line'>decodeImage: 74.233ms
</span><span class='line'>memory used: <span class="nv">rss</span><span class="o">=</span>141.8 MB, <span class="nv">heapTotal</span><span class="o">=</span>24.33 MB, <span class="nv">heapUsed</span><span class="o">=</span>19.05 MB, <span class="nv">external</span><span class="o">=</span>40.63 MB
</span><span class='line'>imageByteArray: 5.676ms
</span><span class='line'>memory used: <span class="nv">rss</span><span class="o">=</span>141.8 MB, <span class="nv">heapTotal</span><span class="o">=</span>24.33 MB, <span class="nv">heapUsed</span><span class="o">=</span>19.05 MB, <span class="nv">external</span><span class="o">=</span>45.51 MB
</span><span class='line'>imageToInput: 5.952ms
</span><span class='line'>memory used: <span class="nv">rss</span><span class="o">=</span>141.8 MB, <span class="nv">heapTotal</span><span class="o">=</span>24.33 MB, <span class="nv">heapUsed</span><span class="o">=</span>19.06 MB, <span class="nv">external</span><span class="o">=</span>45.51 MB
</span><span class='line'>mn_model.classify: 274.805ms
</span><span class='line'>memory used: <span class="nv">rss</span><span class="o">=</span>149.83 MB, <span class="nv">heapTotal</span><span class="o">=</span>24.33 MB, <span class="nv">heapUsed</span><span class="o">=</span>20.57 MB, <span class="nv">external</span><span class="o">=</span>45.51 MB
</span><span class='line'>classification results: <span class="o">[</span>...<span class="o">]</span>
</span><span class='line'>main: 356.639ms
</span><span class='line'>memory used: <span class="nv">rss</span><span class="o">=</span>144.37 MB, <span class="nv">heapTotal</span><span class="o">=</span>24.33 MB, <span class="nv">heapUsed</span><span class="o">=</span>20.58 MB, <span class="nv">external</span><span class="o">=</span>45.51 MB
</span></code></pre></td></tr></table></div></figure>


<p><code>main</code> is the total elapsed time for the action handler. <code>mn_model.classify</code> is the elapsed time for the image classification. Cold start requests print an extra log message with model loading time, <code>loadModel: 394.547ms</code>.</p>

<h2>Performance Results</h2>

<p>Invoking the <code>classify</code> action 1000 times for both cold and warm activations (using 256MB memory) generated the following performance results.</p>

<h3>warm invocations</h3>

<p><img src="http://jamesthom.as/images/tfjs-serverless/warm-activations.png" title="Warm Activation Performance Results" ></p>

<p>Classifications took an average of <strong>316 milliseconds to process when using warm environments</strong>. Looking at the timing data, converting the Base64 encoded JPEG into the input tensor took around 100 milliseconds. Running the model classification task was in the 200 - 250 milliseconds range.</p>

<h3>cold invocations</h3>

<p><img src="http://jamesthom.as/images/tfjs-serverless/cold-activations.png" title="Cold Activation Performance Results" ></p>

<p>Classifications took an average of <strong>1260 milliseconds to process when using cold environments</strong>. These requests incur penalties for initialising new runtime containers and loading models from the filesystem. Both of these tasks took around 400 milliseconds each.</p>

<p><em>One disadvantage of using custom runtime images in Apache OpenWhisk is the lack of <a href="https://medium.com/openwhisk/squeezing-the-milliseconds-how-to-make-serverless-platforms-blazing-fast-aea0e9951bd0">pre-warmed containers</a>. Pre-warming is used to reduce cold start times by starting runtime containers before they are needed. This is not supported for non-standard runtime images.</em></p>

<h3>classification cost</h3>

<p>IBM Cloud Functions <a href="https://console.bluemix.net/openwhisk/learn/pricing">provides a free tier</a> of 400,000 GB/s per month. Each further second of execution is charged at $0.000017 per GB of memory allocated. Execution time is rounded up to the nearest 100ms.</p>

<p>If all activations were warm, a user could execute <strong>more than 4,000,000 classifications per month in the free tier</strong> using an action with 256MB. Once outside the free tier, around 600,000 further invocations would cost just over $1.</p>

<p>If all activations were cold, a user could execute <strong>more than 1,2000,000 classifications per month in the free tier</strong> using an action with 256MB. Once outside the free tier, around 180,000 further invocations would cost just over $1.</p>

<h2>Conclusion</h2>

<p>TensorFlow.js brings the power of deep learning to JavaScript developers. Using pre-trained models with the TensorFlow.js library makes it simple to extend JavaScript applications with complex machine learning tasks with minimal effort and code.</p>

<p>Getting a local script to run image classification was relatively simple, but converting to a serverless function came with more challenges! Apache OpenWhisk restricts the maximum application size to 50MB and native libraries dependencies were much larger than this limit.</p>

<p>Fortunately, Apache OpenWhisk&#8217;s custom runtime support allowed us to resolve all these issues. By building a custom runtime with native dependencies and models files, those libraries can be used on the platform without including them in the deployment package.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Machine Learning In Node.js With TensorFlow.js]]></title>
    <link href="http://jamesthom.as/blog/2018/08/07/machine-learning-in-node-dot-js-with-tensorflow-dot-js/"/>
    <updated>2018-08-07T09:52:00+01:00</updated>
    <id>http://jamesthom.as/blog/2018/08/07/machine-learning-in-node-dot-js-with-tensorflow-dot-js</id>
    <content type="html"><![CDATA[<p><a href="https://js.tensorflow.org/">TensorFlow.js</a> is a new version of the popular open-source library which brings deep learning to JavaScript. Developers can now define, train, and run machine learning models using the <a href="https://js.tensorflow.org/api/0.12.0/">high-level library API</a>.</p>

<p><a href="https://github.com/tensorflow/tfjs-models/">Pre-trained models</a> mean developers can now easily perform complex tasks like <a href="https://emojiscavengerhunt.withgoogle.com/">visual recognition</a>, <a href="https://magenta.tensorflow.org/demos/performance_rnn/index.html#2|2,0,1,0,1,1,0,1,0,1,0,1|1,1,1,1,1,1,1,1,1,1,1,1|1,1,1,1,1,1,1,1,1,1,1,1|false">generating music</a> or <a href="https://storage.googleapis.com/tfjs-models/demos/posenet/camera.html">detecting human poses</a> with just a few lines of JavaScript.</p>

<p>Having started as a front-end library for web browsers, recent updates added <a href="https://github.com/tensorflow/tfjs-node">experimental support</a> for Node.js. This allows TensorFlow.js to be used in backend JavaScript applications without having to use Python.</p>

<p><em>Reading about the library, I wanted to test it out with a simple task&#8230;</em> üßê</p>

<blockquote><p> <strong>Use TensorFlow.js to perform visual recognition on images using JavaScript from Node.js</strong></p></blockquote>

<p>Unfortunately, most of the <a href="https://js.tensorflow.org/#getting-started">documentation</a> and <a href="https://js.tensorflow.org/tutorials/webcam-transfer-learning.html">example code</a> provided uses the library in a browser. <a href="https://github.com/tensorflow/tfjs-models/tree/master/mobilenet">Project utilities</a> provided to simplify loading and using pre-trained models have not yet been extended with Node.js support. Getting this working did end up with me spending a lot of time reading the Typescript source files for the library. üëé</p>

<p>However, after a few days&#8217; hacking, I managed to get <a href="https://gist.github.com/jthomas/145610bdeda2638d94fab9a397eb1f1d">this completed</a>! Hurrah! ü§©</p>

<p><em>Before we dive into the code, let&#8217;s start with an overview of the different TensorFlow libraries.</em></p>

<h2>TensorFlow</h2>

<p><a href="https://www.tensorflow.org/">TensorFlow</a> is an open-source software library for machine learning applications. TensorFlow can be used to implement neural networks and other deep learning algorithms.</p>

<p>Released by Google in November 2015, TensorFlow was originally a <a href="https://www.tensorflow.org/api_docs/python/">Python library</a>. It used either CPU or GPU-based computation for training and evaluating machine learning models. The library was initially designed to run on high-performance servers with expensive GPUs.</p>

<p>Recent updates have extended the software to run in resource-constrained environments like mobile devices and web browsers.</p>

<h3>TensorFlow Lite</h3>

<p><a href="https://www.tensorflow.org/mobile/tflite/">Tensorflow Lite</a>, a lightweight version of the library for mobile and embedded devices, was released in May 2017. This was accompanied by a new series of pre-trained deep learning models for vision recognition tasks, called <a href="https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html">MobileNet</a>. MobileNet models were designed to work efficiently in resource-constrained environments like mobile devices.</p>

<h3>TensorFlow.js</h3>

<p>Following Tensorflow Lite, <a href="https://medium.com/tensorflow/introducing-tensorflow-js-machine-learning-in-javascript-bf3eab376db">TensorFlow.js</a> was announced in March 2018. This version of the library was designed to run in the browser, building on an earlier project called <a href="https://twitter.com/deeplearnjs">deeplearn.js</a>. WebGL provides GPU access to the library. Developers use a JavaScript API to train, load and run models.</p>

<p>TensorFlow.js was recently extended to run on Node.js, using an <a href="https://github.com/tensorflow/tfjs-node">extension library</a> called <code>tfjs-node</code>.</p>

<p><em>The Node.js extension is an alpha release and still under active development.</em></p>

<h4>Importing Existing Models Into TensorFlow.js</h4>

<p>Existing TensorFlow and Keras models can be executed using the TensorFlow.js library. Models need converting to a new format <a href="https://github.com/tensorflow/tfjs-converter">using this tool</a> before execution. Pre-trained and converted models for image classification, pose detection and k-nearest neighbours are <a href="https://github.com/tensorflow/tfjs-models">available on Github</a>.</p>

<h2>Using TensorFlow.js in Node.js</h2>

<h3>Installing TensorFlow Libraries</h3>

<p>TensorFlow.js can be installed from the <a href="https://www.npmjs.com/">NPM registry</a>.</p>

<ul>
<li><code>@tensorflow/tfjs</code> - <a href="https://www.npmjs.com/package/@tensorflow/tfjs">Core TensorFlow.js library</a></li>
<li><code>@tensorflow/tfjs-node</code> - <a href="https://www.npmjs.com/package/@tensorflow/tfjs-node">TensorFlow.js Node.js extension</a></li>
<li><code>@tensorflow/tfjs-node-gpu</code> - <a href="https://www.npmjs.com/package/@tensorflow/tfjs-node-gpu">TensorFlow.js Node.js extension with GPU support</a></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>npm install @tensorflow/tfjs @tensorflow/tfjs-node
</span><span class='line'>// or...
</span><span class='line'>npm install @tensorflow/tfjs @tensorflow/tfjs-node-gpu</span></code></pre></td></tr></table></div></figure>


<p>Both Node.js extensions use native dependencies which will be compiled on demand.</p>

<h3>Loading TensorFlow Libraries</h3>

<p>TensorFlow&#8217;s <a href="https://js.tensorflow.org/api/0.12.0/">JavaScript API</a> is exposed from the core library. Extension modules to enable Node.js support do not expose additional APIs.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">tf</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="s1">&#39;@tensorflow/tfjs&#39;</span><span class="p">)</span>
</span><span class='line'><span class="c1">// Load the binding (CPU computation)</span>
</span><span class='line'><span class="nx">require</span><span class="p">(</span><span class="s1">&#39;@tensorflow/tfjs-node&#39;</span><span class="p">)</span>
</span><span class='line'><span class="c1">// Or load the binding (GPU computation)</span>
</span><span class='line'><span class="nx">require</span><span class="p">(</span><span class="s1">&#39;@tensorflow/tfjs-node-gpu&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Loading TensorFlow Models</h3>

<p>TensorFlow.js provides an <a href="https://github.com/tensorflow/tfjs-models">NPM library</a> (<code>tfjs-models</code>) to ease loading pre-trained &amp; converted models for <a href="https://github.com/tensorflow/tfjs-models/tree/master/mobilenet">image classification</a>, <a href="https://github.com/tensorflow/tfjs-models/tree/master/posenet">pose detection</a> and <a href="https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier">k-nearest neighbours</a>.</p>

<p>The <a href="https://github.com/tensorflow/tfjs-models/tree/master/mobilenet">MobileNet model</a> used for image classification is a deep neural network trained to <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/imagenet_classes.ts">identify 1000 different classes</a>.</p>

<p>In the project&#8217;s README, the <a href="https://github.com/tensorflow/tfjs-models/tree/master/mobilenet#via-npm">following example code</a> is used to load the model.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">import</span> <span class="o">*</span> <span class="nx">as</span> <span class="nx">mobilenet</span> <span class="nx">from</span> <span class="s1">&#39;@tensorflow-models/mobilenet&#39;</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Load the model.</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">model</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">mobilenet</span><span class="p">.</span><span class="nx">load</span><span class="p">();</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>One of the first challenges I encountered was that this does not work on Node.js.</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nb">Error</span><span class="o">:</span> <span class="nx">browserHTTPRequest</span> <span class="nx">is</span> <span class="nx">not</span> <span class="nx">supported</span> <span class="nx">outside</span> <span class="nx">the</span> <span class="nx">web</span> <span class="nx">browser</span><span class="p">.</span>
</span></code></pre></td></tr></table></div></figure>


<p>Looking at the <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/index.ts#L27">source code</a>, the <code>mobilenet</code> library is a wrapper around the underlying <code>tf.Model</code> class. When the <code>load()</code> method is called, it automatically downloads the correct model files from an external HTTP address and instantiates the TensorFlow model.</p>

<p>The Node.js extension does not yet support HTTP requests to dynamically retrieve models. Instead, models must be manually loaded from the filesystem.</p>

<p><em>After reading the source code for the library, I managed to create a work-around&#8230;</em></p>

<h4>Loading Models From a Filesystem</h4>

<p>Rather than calling the module&#8217;s <code>load</code> method, if the <code>MobileNet</code> class is created manually, the auto-generated <code>path</code> variable which contains the HTTP address of the model can be overwritten with a local filesystem path. Having done this, calling the <code>load</code> method on the class instance will trigger the <a href="https://js.tensorflow.org/tutorials/model-save-load.html">filesystem loader class</a>, rather than trying to use the browser-based HTTP loader.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">path</span> <span class="o">=</span> <span class="s2">&quot;mobilenet/model.json&quot;</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">mn</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">mobilenet</span><span class="p">.</span><span class="nx">MobileNet</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span><span class='line'><span class="nx">mn</span><span class="p">.</span><span class="nx">path</span> <span class="o">=</span> <span class="err">`</span><span class="nx">file</span><span class="o">:</span><span class="c1">//${path}`</span>
</span><span class='line'><span class="nx">await</span> <span class="nx">mn</span><span class="p">.</span><span class="nx">load</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>Awesome, it works!</strong></p>

<p><em>But how where do the models files come from?</em></p>

<h3>MobileNet Models</h3>

<p>Models for TensorFlow.js consist of two file types, a model configuration file stored in JSON and model weights in a binary format. Model weights are often sharded into multiple files for better caching by browsers.</p>

<p>Looking at the <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/index.ts#L68-L76">automatic loading code</a> for MobileNet models, models configuration and weight shards are retrieved from a public storage bucket at this address.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">https</span><span class="o">:</span><span class="c1">//storage.googleapis.com/tfjs-models/tfjs/mobilenet_v${version}_${alpha}_${size}/</span>
</span></code></pre></td></tr></table></div></figure>


<p>The template parameters in the URL refer to the model versions listed <a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md#pre-trained-models">here</a>. Classification accuracy results for each version are also shown on that page.</p>

<p><em>According to the <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/index.ts#L36">source code</a>, only MobileNet v1 models can be loaded using the <code>tensorflow-models/mobilenet</code> library.</em></p>

<p>The HTTP retrieval code loads the <code>model.json</code> file from this location and then recursively fetches all referenced model weights shards. These files are in the format <code>groupX-shard1of1</code>.</p>

<h4>Downloading Models Manually</h4>

<p>Saving all model files to a filesystem can be achieved by retrieving the model configuration file, parsing out the referenced weight files and downloading each weight file manually.</p>

<p><strong>I want to use the MobileNet V1 Module with 1.0 alpha value and image size of 224 pixels.</strong> This gives me the <a href="https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/model.json">following URL</a> for the model configuration file.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">https</span><span class="o">:</span><span class="c1">//storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/model.json</span>
</span></code></pre></td></tr></table></div></figure>


<p>Once this file has been downloaded locally, I can use the <a href="https://stedolan.github.io/jq/"><code>jq</code> tool</a> to parse all the weight file names.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">$</span> <span class="nx">cat</span> <span class="nx">model</span><span class="p">.</span><span class="nx">json</span> <span class="o">|</span> <span class="nx">jq</span> <span class="o">-</span><span class="nx">r</span> <span class="s2">&quot;.weightsManifest[].paths[0]&quot;</span>
</span><span class='line'><span class="nx">group1</span><span class="o">-</span><span class="nx">shard1of1</span>
</span><span class='line'><span class="nx">group2</span><span class="o">-</span><span class="nx">shard1of1</span>
</span><span class='line'><span class="nx">group3</span><span class="o">-</span><span class="nx">shard1of1</span>
</span><span class='line'><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using the <code>sed</code> tool, I can prefix these names with the HTTP URL to generate URLs for each weight file.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">$</span> <span class="nx">cat</span> <span class="nx">model</span><span class="p">.</span><span class="nx">json</span> <span class="o">|</span> <span class="nx">jq</span> <span class="o">-</span><span class="nx">r</span> <span class="s2">&quot;.weightsManifest[].paths[0]&quot;</span> <span class="o">|</span> <span class="nx">sed</span> <span class="s1">&#39;s/^/https:\/\/storage.googleapis.com\/tfjs-models\/tfjs\/mobilenet_v1_1.0_224\//&#39;</span>
</span><span class='line'><span class="nx">https</span><span class="o">:</span><span class="c1">//storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/group1-shard1of1</span>
</span><span class='line'><span class="nx">https</span><span class="o">:</span><span class="c1">//storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/group2-shard1of1</span>
</span><span class='line'><span class="nx">https</span><span class="o">:</span><span class="c1">//storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_1.0_224/group3-shard1of1</span>
</span><span class='line'><span class="p">...</span>
</span></code></pre></td></tr></table></div></figure>


<p>Using the <code>parallel</code> and <code>curl</code> commands, I can then download all of these files to my local directory.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">cat</span> <span class="nx">model</span><span class="p">.</span><span class="nx">json</span> <span class="o">|</span> <span class="nx">jq</span> <span class="o">-</span><span class="nx">r</span> <span class="s2">&quot;.weightsManifest[].paths[0]&quot;</span> <span class="o">|</span> <span class="nx">sed</span> <span class="s1">&#39;s/^/https:\/\/storage.googleapis.com\/tfjs-models\/tfjs\/mobilenet_v1_1.0_224\//&#39;</span> <span class="o">|</span>  <span class="nx">parallel</span> <span class="nx">curl</span> <span class="o">-</span><span class="nx">O</span>
</span></code></pre></td></tr></table></div></figure>


<h3>Classifying Images</h3>

<p><a href="https://github.com/tensorflow/tfjs-models/tree/master/mobilenet#via-npm">This example code</a> is provided by TensorFlow.js to demonstrate returning classifications for an image.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">img</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">getElementById</span><span class="p">(</span><span class="s1">&#39;img&#39;</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// Classify the image.</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">predictions</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">model</span><span class="p">.</span><span class="nx">classify</span><span class="p">(</span><span class="nx">img</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>This does not work on Node.js due to the lack of a DOM.</strong></p>

<p>The <code>classify</code> <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/index.ts#L143-L155">method</a> accepts numerous DOM elements (<code>canvas</code>, <code>video</code>, <code>image</code>) and will automatically retrieve and convert image bytes from these elements into a <a href="https://js.tensorflow.org/api/latest/index.html#tensor3d"><code>tf.Tensor3D</code> class</a> which is used as the input to the model. Alternatively, the <code>tf.Tensor3D</code> input can be passed directly.</p>

<p><strong>Rather than trying to use an external package to simulate a DOM element in Node.js, I found it easier to construct the <code>tf.Tensor3D</code> manually.</strong></p>

<h4>Generating Tensor3D from an Image</h4>

<p>Reading the <a href="https://github.com/tensorflow/tfjs-core/blob/master/src/kernels/backend_cpu.ts#L126-L140">source code</a> for the method used to turn DOM elements into Tensor3D classes, the following input parameters are used to generate the Tensor3D class.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">values</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Int32Array</span><span class="p">(</span><span class="nx">image</span><span class="p">.</span><span class="nx">height</span> <span class="o">*</span> <span class="nx">image</span><span class="p">.</span><span class="nx">width</span> <span class="o">*</span> <span class="nx">numChannels</span><span class="p">);</span>
</span><span class='line'><span class="c1">// fill pixels with pixel channel bytes from image</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">outShape</span> <span class="o">=</span> <span class="p">[</span><span class="nx">image</span><span class="p">.</span><span class="nx">height</span><span class="p">,</span> <span class="nx">image</span><span class="p">.</span><span class="nx">width</span><span class="p">,</span> <span class="nx">numChannels</span><span class="p">];</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">input</span> <span class="o">=</span> <span class="nx">tf</span><span class="p">.</span><span class="nx">tensor3d</span><span class="p">(</span><span class="nx">values</span><span class="p">,</span> <span class="nx">outShape</span><span class="p">,</span> <span class="s1">&#39;int32&#39;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>pixels</code> is a 2D array of type (Int32Array) which contains a sequential list of channel values for each pixel. <code>numChannels</code> is the number of channel values per pixel.</p>

<h4>Creating Input Values For JPEGs</h4>

<p>The <a href="https://www.npmjs.com/package/jpeg-js"><code>jpeg-js</code> library</a> is a pure javascript JPEG encoder and decoder for Node.js. Using this library the RGB values for each pixel can be extracted.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">pixels</span> <span class="o">=</span> <span class="nx">jpeg</span><span class="p">.</span><span class="nx">decode</span><span class="p">(</span><span class="nx">buffer</span><span class="p">,</span> <span class="kc">true</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p>This will return a <code>Uint8Array</code> with four channel values (<code>RGBA</code>) for each pixel (<code>width * height</code>). The MobileNet model only uses the three colour channels (<code>RGB</code>) for classification, ignoring the alpha channel. This code converts the four channel array into the correct three channel version.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">numChannels</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">numPixels</span> <span class="o">=</span> <span class="nx">image</span><span class="p">.</span><span class="nx">width</span> <span class="o">*</span> <span class="nx">image</span><span class="p">.</span><span class="nx">height</span><span class="p">;</span>
</span><span class='line'><span class="kr">const</span> <span class="nx">values</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Int32Array</span><span class="p">(</span><span class="nx">numPixels</span> <span class="o">*</span> <span class="nx">numChannels</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'><span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">numPixels</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">channel</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">channel</span> <span class="o">&lt;</span> <span class="nx">numChannels</span><span class="p">;</span> <span class="o">++</span><span class="nx">channel</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">values</span><span class="p">[</span><span class="nx">i</span> <span class="o">*</span> <span class="nx">numChannels</span> <span class="o">+</span> <span class="nx">channel</span><span class="p">]</span> <span class="o">=</span> <span class="nx">pixels</span><span class="p">[</span><span class="nx">i</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="nx">channel</span><span class="p">];</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h4>MobileNet Models Input Requirements</h4>

<p>The <a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md#mobilenet_v1">MobileNet model</a> being used classifies images of width and height 224 pixels. Input tensors must contain float values, between -1 and 1, for each of the three channels pixel values.</p>

<p>Input values for images of different dimensions needs to be re-sized before classification. Additionally, pixels values from the JPEG decoder are in the range <em>0 - 255</em>, rather than <em>-1 to 1</em>. These values also need converting prior to classification.</p>

<p><strong>TensorFlow.js has library methods to make this process easier but, fortunately for us, the <code>tfjs-models/mobilenet</code> library <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/index.ts#L103-L114">automatically handles</a> this issue!</strong> üëç</p>

<p>Developers can pass in Tensor3D inputs of type <code>int32</code>  and different dimensions to the  <code>classify</code> method and it converts the input to the correct format prior to classification. Which means there&#8217;s nothing to do&#8230; Super üï∫üï∫üï∫.</p>

<h4>Obtaining Predictions</h4>

<p>MobileNet models in Tensorflow are trained to recognise entities from the <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/imagenet_classes.ts">top 1000 classes</a> in the <a href="http://image-net.org/">ImageNet</a> dataset. The models output the probabilities that each of those entities is in the image being classified.</p>

<p><em>The full list of trained classes for the model being used can be found in <a href="https://github.com/tensorflow/tfjs-models/blob/master/mobilenet/src/imagenet_classes.ts">this file</a>.</em></p>

<p>The <code>tfjs-models/mobilenet</code> library exposes a <code>classify</code> method on the <code>MobileNet</code> class to return the top X classes with highest probabilities from an image input.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">predictions</span> <span class="o">=</span> <span class="nx">await</span> <span class="nx">mn_model</span><span class="p">.</span><span class="nx">classify</span><span class="p">(</span><span class="nx">input</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure>


<p><code>predictions</code> is an array of X classes and probabilities in the following format.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="nx">className</span><span class="o">:</span> <span class="s1">&#39;panda&#39;</span><span class="p">,</span>
</span><span class='line'>  <span class="nx">probability</span><span class="o">:</span> <span class="mf">0.9993536472320557</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Example</h2>

<p>Having worked how to use the TensorFlow.js library and MobileNet models on Node.js, <a href="https://gist.github.com/jthomas/145610bdeda2638d94fab9a397eb1f1d">this script</a> will classify an image given as a command-line argument.</p>

<h3>source code</h3>

<ul>
<li>Save this script file and package descriptor to local files.</li>
</ul>


<script src="https://gist.github.com/jthomas/145610bdeda2638d94fab9a397eb1f1d.js"></script>


<h3>testing it out</h3>

<ul>
<li><p>Download the model files to a <code>mobilenet</code> directory using the instructions above.</p></li>
<li><p>Install the project dependencies using NPM</p></li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">npm</span> <span class="nx">install</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Download a sample JPEG file to classify</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">wget</span> <span class="nx">http</span><span class="o">:</span><span class="c1">//bit.ly/2JYSal9 -O panda.jpg</span>
</span></code></pre></td></tr></table></div></figure>


<p><img src="https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG"></p>

<ul>
<li>Run the script with the model file and input image as arguments.</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">node</span> <span class="nx">script</span><span class="p">.</span><span class="nx">js</span> <span class="nx">mobilenet</span><span class="o">/</span><span class="nx">model</span><span class="p">.</span><span class="nx">json</span> <span class="nx">panda</span><span class="p">.</span><span class="nx">jpg</span>
</span></code></pre></td></tr></table></div></figure>


<p><strong>If everything worked, the following output should be printed to the console.</strong></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">classification</span> <span class="nx">results</span><span class="o">:</span> <span class="p">[</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">className</span><span class="o">:</span> <span class="s1">&#39;giant panda, panda, panda bear, coon bear&#39;</span><span class="p">,</span>
</span><span class='line'>    <span class="nx">probability</span><span class="o">:</span> <span class="mf">0.9993536472320557</span>
</span><span class='line'><span class="p">}</span> <span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>The image is correctly classified as containing a Panda with 99.93% probability! üêºüêºüêº</p>

<h2>Conclusion</h2>

<p>TensorFlow.js brings the power of deep learning to JavaScript developers. Using pre-trained models with the TensorFlow.js library makes it simple to extend JavaScript applications with complex machine learning tasks with minimal effort and code.</p>

<p>Having been released as a browser-based library, TensorFlow.js has now been extended to work on Node.js, although not all of the tools and utilities support the new runtime. With a few days&#8217; hacking, I was able to use the library with the MobileNet models for visual recognition on images from a local file.</p>

<p>Getting this working in the Node.js runtime means I now move on to my next idea&#8230; making this run inside a serverless function! Come back soon to read about my next adventure with TensorFlow.js. üëã</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitoring Dashboards With Kibana For IBM Cloud Functions]]></title>
    <link href="http://jamesthom.as/blog/2018/07/18/monitoring-dashboards-with-kibana-for-ibm-cloud-functions/"/>
    <updated>2018-07-18T16:08:00+01:00</updated>
    <id>http://jamesthom.as/blog/2018/07/18/monitoring-dashboards-with-kibana-for-ibm-cloud-functions</id>
    <content type="html"><![CDATA[<p>Following all the events from the World Cup can be hard. So many matches, so many goals. Rather than manually refreshing BBC Football to check the scores, I decided to created a <a href="https://twitter.com/WC2018_Goals">Twitter bot</a> that would automatically tweet out each goal.</p>

<p><img src="http://jamesthom.as/images/monitoring-goalbot/wcgoalbot.png" title="World Cup Goal Bot" ></p>

<p><a href="https://github.com/jthomas/goalbot">The Twitter bot</a> runs on <a href="https://console.bluemix.net/openwhisk">IBM Cloud Functions</a>. It is called once a minute to check for new goals, using the <a href="https://github.com/apache/incubator-openwhisk-package-alarms">alarm trigger feed</a>. If new goals have been scored, it calls another action to send the tweet messages.</p>

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">‚öΩÔ∏è GOAL ‚öΩÔ∏è<br>üë® Harry MAGUIRE (Û†Åøüè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø ) @ 30&#39;. üë®<br>üèü Sweden üá∏üá™ (0) v England Û†Åøüè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø (1) üèü<a href="https://twitter.com/hashtag/WorldCup?src=hash&amp;ref_src=twsrc%5Etfw">#WorldCup</a></p>&mdash; WC 2018 Goal Bot (@WC2018_Goals) <a href="https://twitter.com/WC2018_Goals/status/1015604110006120448?ref_src=twsrc%5Etfw">July 7, 2018</a></blockquote>


<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>Once it was running, I need to ensure it was working correctly for the duration of the tournament. Using the <a href="https://console.bluemix.net/catalog/services/log-analysis">IBM Cloud Logging</a> service, I built a custom monitoring dashboard to help to me recognise and diagnose issues.</p>

<p><img src="http://jamesthom.as/images/monitoring-goalbot/dashboard-overview.png" title="Monitoring Dashboard" ></p>

<p>The dashboard showed counts for successful and failed activations, when they occurred and a list of failed activations. If issues have occurred, I can retrieve the failed activation identifiers and investigate further.</p>

<p><em>Let&#8217;s walk through the steps used to create this dashboard to help you create custom visualisations for serverless applications running on IBM Cloud Functions&#8230;</em></p>

<h2>IBM Cloud Logging</h2>

<p><a href="https://console.bluemix.net/docs/services/CloudLogAnalysis/index.html">IBM Cloud Logging</a> can be accessed <a href="https://console.bluemix.net/docs/openwhisk/openwhisk_logs.html#openwhisk_logs">using the link</a> on the IBM Cloud Functions dashboard. This will open the logging service for the current organisation and space.</p>

<p><img src="http://jamesthom.as/images/monitoring-goalbot/open-logging.gif" title="Opening Logging Service" ></p>

<p>All activation records and application logs are automatically forwarded to the logging service by IBM Cloud Functions.</p>

<p><img src="http://jamesthom.as/images/monitoring-goalbot/discover.png" title="Kibana Discover Screen" ></p>

<h3>Log Message Fields</h3>

<p>Activation records and application log messages have a number of common record fields.</p>

<ul>
<li><code>activationId_str</code> - <em>activation identifier for log message.</em></li>
<li><code>timestamp</code> - <em>log draining time.</em></li>
<li><code>@timestamp</code> - <em>message ingestion time.</em></li>
<li><code>action_str</code> - <em>fully qualified action name</em></li>
</ul>


<p>Log records for different message types are identified using the <code>type</code> field. This is either <code>activation_record</code> or <code>user_logs</code> for IBM Cloud Functions records.</p>

<p>Activation records have the following custom fields.</p>

<ul>
<li><code>duration_int</code> - <em>activation duration in milliseconds</em></li>
<li><code>status_str</code> - <em>activation status response (non-zero for errors)</em></li>
<li><code>message</code> - <em>activation response returned from action</em></li>
<li><code>time_date</code> - <em>activation record start time</em></li>
<li><code>end_date</code> - <em>activation record end time</em></li>
</ul>


<p>Applications log lines, written to stdout or stderr, are forwarded as individual records. One application log line per record. Log message records have the following custom fields.</p>

<ul>
<li><code>message</code> - <em>single application log line output</em></li>
<li><code>stream_str</code> - <em>log message source, either <code>stdout</code> or <code>stderr</code></em></li>
<li><code>time_date</code> - <em>timestamp parsed from application log line</em></li>
</ul>


<h3>Finding Log Messages For One Activation</h3>

<p>Use this query string in the &#8221;<a href="https://www.elastic.co/guide/en/kibana/current/discover.html"><em>Discover</em>&#8221;</a> tab to retrieve all logs messages from a particular activation.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>activationId_str: &lt;ACTIVATION_ID&gt;</span></code></pre></td></tr></table></div></figure>


<p>Search queries are executed against log records within a <a href="https://www.elastic.co/guide/en/kibana/current/set-time-filter.html">configurable time window</a>.</p>

<h2>Monitoring Dashboard</h2>

<p><img src="http://jamesthom.as/images/monitoring-goalbot/dashboard-overview.png" title="Monitoring Dashboard" ></p>

<p>This is the monitoring dashboard I created. It contains visualisations showing counts for successful and failed activations, histograms of when they occurred and a list of the recent failed activation identifiers.</p>

<p>It allows me to quickly review the previous 24 hours activations for issues. If there are notable issues, I can retrieve the failed activation identifiers and investigate further.</p>

<p>Before being able to create the dashboard, I needed to define two resources: <strong><em>saved searches</em></strong> and <strong><em>visualisations</em></strong>.</p>

<h3>Saved Searches</h3>

<p><img src="http://jamesthom.as/images/monitoring-goalbot/saved-searches.png" title="Saving Search Queries" ></p>

<p>Kibana supports saving and referring to search queries from visualisations using explicit names.</p>

<p>Using <a href="https://www.elastic.co/guide/en/kibana/current/managing-saved-objects.html">saved searches</a> with visualisations, rather than explicit queries, removes the need to manually update visualisations&#8217; configuration when queries change.</p>

<p>This dashboard uses two custom queries in visualisations. Queries are needed to find activation records from both successful and failed invocations.</p>

<ul>
<li>Create a new <em>&#8220;Saved Search&#8221;</em> named <em>&#8220;activation records (success)&#8221;</em> using the following search query.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>type: activation_record AND status_str: 0</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Create a new <em>&#8220;Saved Search&#8221;</em> named <em>&#8220;activation records (failed)&#8221;</em> using the following search query.</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>type: activation_record AND NOT status_str: 0</span></code></pre></td></tr></table></div></figure>


<p><em>The <code>status_str</code> field is set to a non-zero value for failures. Using the <code>type</code> field ensures log messages from other sources are excluded from the results.</em></p>

<h3>Indexed Fields</h3>

<p>Before referencing log record fields in visualisations, those fields <a href="https://www.elastic.co/guide/en/kibana/current/index-patterns.html#reload-fields">need to be indexed</a> correctly. Use these instructions to verify activation records fields are available.</p>

<ul>
<li>Check IBM Cloud Functions logs are available in IBM Cloud Logging using the &#8221;<em>Discover</em>&#8221; tab.</li>
<li>Click the &#8220;‚öôÔ∏è <em>(Management)</em>&#8221; menu item on the left-hand drop-down menu in IBM Cloud Logging.</li>
<li>Click the &#8221;<em>Index Patterns</em>&#8221; link.</li>
<li>Click the üîÑ button to refresh the field list.</li>
</ul>


<p><img src="http://jamesthom.as/images/monitoring-goalbot/refresh-fields.gif" title="Refresh field index" ></p>

<h3>Visualisations</h3>

<p>Three types of <a href="https://www.elastic.co/guide/en/kibana/current/visualize.html">visualisation</a> are used on the monitoring dashboard. Metric displays are used for the activation counts, vertical bar charts for the activation times and a data table to list failed activations.</p>

<p><em>Visualisations <a href="https://www.elastic.co/guide/en/kibana/current/createvis.html">can be created</a> by opening the &#8220;Visualize&#8221; menu item and select a new visualisation type under the &#8220;Create New Visualization&#8221; menu.</em></p>

<p>Create five different visualisations, using the instructions below, before moving on to create the dashboard.</p>

<h4>Activation Counts</h4>

<p>Counts for successful and failed activations are displayed as singular <a href="https://www.elastic.co/guide/en/kibana/current/metric-chart.html">metric values</a>.</p>

<ul>
<li>Select the &#8220;Metric&#8221; visualisation from the visualisation type list.</li>
<li>Use the &#8220;activation records (success)&#8221; saved search as the data source.</li>
<li>Ensure the Metric Aggregation is set to &#8220;Count&#8221;</li>
<li>Set the &#8220;Font Size&#8221; under the Options menu to 120pt.</li>
<li>Save the visualisation as &#8220;Activation Counts (Success)&#8221;</li>
</ul>


<p><img src="http://jamesthom.as/images/monitoring-goalbot/metrics-success.png" title="Activation success metric" ></p>

<ul>
<li>Repeat this process to create the failed activation count visualisation.</li>
<li>Use the &#8220;activation records (failed)&#8221; saved search as the data source.</li>
<li>Save the visualisation as &#8220;Activation Counts (Failed)&#8221;.</li>
</ul>


<p><img src="http://jamesthom.as/images/monitoring-goalbot/metrics-fail.png" title="Activation failed metric" ></p>

<h4>Activation Times</h4>

<p>Activation counts over time, for successful and failed invocations, are displayed in <a href="https://www.elastic.co/guide/en/kibana/current/xy-chart.html">vertical bar charts</a>.</p>

<ul>
<li>Select the &#8220;Vertical bar chart&#8221; visualisation from the visualisation type list.</li>
<li>Use the &#8220;activation records (success)&#8221; saved search as the data source.</li>
<li>Set the &#8220;Custom Label&#8221; to Invocations</li>
<li>Add an &#8220;X-Axis&#8221; bucket type under the Buckets section.</li>
<li>Choose &#8220;Date Histogram&#8221; for the aggregation, &#8220;@timestamp&#8221; for the field and &#8220;Minute&#8221; for the interval.</li>
<li>Save the visualisation as &#8220;Activation Times (Success)&#8221;</li>
</ul>


<p><img src="http://jamesthom.as/images/monitoring-goalbot/activation-times.png" title="Activation times chart" ></p>

<ul>
<li>Repeat this process to create the failed activation times visualisation.</li>
<li>Use the &#8220;activation records (failed)&#8221; saved search as the data source.</li>
<li>Save the visualisation as &#8220;Activation Times (Failed)&#8221;</li>
</ul>


<h4>Failed Activations List</h4>

<p>Activation identifiers for failed invocations are shown using a <a href="https://www.elastic.co/guide/en/kibana/current/data-table.html">data table</a>.</p>

<ul>
<li>Select the &#8220;Data table&#8221; visualisation from the visualisation type list.</li>
<li>Use the &#8220;activation records (failed)&#8221; saved search as the data source.</li>
<li>Add a &#8220;Split Rows&#8221; bucket type under the Buckets section.</li>
<li>Choose &#8220;Date Histogram&#8221; for the aggregation, &#8220;@timestamp&#8221; for the field and &#8220;Second&#8221; for the interval.</li>
<li>Add a &#8220;sub-bucket&#8221; with the &#8220;Split Rows&#8221; type.</li>
<li>Set sub aggregation to &#8220;Terms&#8221;, field to &#8220;activationId_str&#8221; and order by &#8220;Term&#8221;.</li>
<li>Save the visualisation as &#8220;Errors Table&#8221;</li>
</ul>


<p><img src="http://jamesthom.as/images/monitoring-goalbot/activations-table.png" title="Failed activation table" ></p>

<h3>Creating the dashboard</h3>

<p>Having created the individual visualisations components, the <a href="https://www.elastic.co/guide/en/kibana/current/dashboard.html">monitoring dashboard</a> can be constructed.</p>

<ul>
<li>Click the &#8220;Dashboard&#8221; menu item from the left-and menu panel.</li>
<li>Click the &#8220;Add&#8221; button to import visualisations into the current dashboard.</li>
<li>Add each of the five visualisations created above.</li>
</ul>


<p><em>Hovering the mouse cursor over visualisations will reveal icons for moving and re-sizing.</em></p>

<ul>
<li>Re-order the visualisations into the following rows:

<ul>
<li>Activations Metrics</li>
<li>Activation Times</li>
<li>Failed Activations List</li>
</ul>
</li>
<li>Select the &#8220;Last 24 hours&#8221; time window, available from the relative time ranges menu.</li>
<li>Save the dashboard as &#8221;<em>Cloud Functions Monitoring</em>&#8221;. Tick the &#8221;<em>store time with dashboard</em>&#8221; option.</li>
</ul>


<p><img src="http://jamesthom.as/images/monitoring-goalbot/dashboard-overview.png" title="Monitoring Dashboard" ></p>

<p>Having saved the dashboard with time window, re-opening the dashboard will show our visualisations with data for the previous 24 hours. This dashboard can be used to quickly review recent application issues.</p>

<h2>Conclusion</h2>

<p>Monitoring serverless applications is crucial to diagnosing issues on serverless platforms.</p>

<p><a href="https://console.bluemix.net/openwhisk/dashboard">IBM Cloud Functions</a> provides automatic integration with the <a href="https://console.bluemix.net/catalog/services/log-analysis">IBM Cloud Logging</a> service. All activation records and application logs from serverless applications are automatically forwarded as log records. This makes it simple to build custom monitoring dashboards using these records for serverless applications running on IBM Cloud Functions.</p>

<p>Using this service with World Cup Twitter bot allowed me to easily monitor the application for issues. This was much easier than manually retrieving and reviewing activation records using the CLI!</p>
]]></content>
  </entry>
  
</feed>
